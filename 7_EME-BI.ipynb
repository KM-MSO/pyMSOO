{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyMSOO.utils.Crossover import *\n",
    "from pyMSOO.utils.Mutation import *\n",
    "from pyMSOO.utils.Selection import *\n",
    "from pyMSOO.utils.DimensionAwareStrategy import *\n",
    "from pyMSOO.MFEA.benchmark.continous import *\n",
    "from pyMSOO.utils.MultiRun.RunMultiTime import * \n",
    "from pyMSOO.utils.MultiRun.RunMultiBenchmark import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tasks, IndClass = CEC17_benchmark.get_2tasks_benchmark(1)\n",
    "# tasks, IndClass = WCCI22_benchmark.get_complex_benchmark(1)\n",
    "tasks, IndClass = CEC17_benchmark.get_10tasks_benchmark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from numba import jit, njit\n",
    "\n",
    "from pyMSOO.MFEA.model import AbstractModel\n",
    "from pyMSOO.utils import Crossover, Mutation, Selection, DimensionAwareStrategy\n",
    "from pyMSOO.utils.EA import *\n",
    "from pyMSOO.utils.numba_utils import numba_randomchoice, numba_random_gauss, numba_random_cauchy, numba_random_uniform\n",
    "from pyMSOO.utils.Search import *\n",
    "\n",
    "class model(AbstractModel.model):\n",
    "    TOLERANCE = 1e-6\n",
    "    def compile(self, \n",
    "        IndClass: Type[Individual],\n",
    "        tasks: List[AbstractTask], \n",
    "        crossover: Crossover.SBX_Crossover, \n",
    "        mutation: Mutation.PolynomialMutation, \n",
    "        selection: Selection.ElitismSelection,\n",
    "        dimension_strategy: DimensionAwareStrategy.AbstractDaS = DimensionAwareStrategy.NoDaS(),\n",
    "        *args, **kwargs):\n",
    "        super().compile(IndClass, tasks, crossover, mutation,dimension_strategy, selection, *args, **kwargs)\n",
    "    \n",
    "    def fit(self, nb_generations, \n",
    "            nb_inds_each_task = 100, \n",
    "            nb_inds_max = 100,\n",
    "            nb_inds_min = 20,\n",
    "            evaluate_initial_skillFactor = True, \n",
    "            c = 0.06,\n",
    "            *args, \n",
    "            **kwargs) -> List[Individual]:\n",
    "        super().fit(*args, **kwargs)\n",
    "\n",
    "        # nb_inds_min\n",
    "        if nb_inds_min is not None:\n",
    "            assert nb_inds_each_task >= nb_inds_min\n",
    "        else: \n",
    "            nb_inds_min = nb_inds_each_task\n",
    "\n",
    "        self.rmp = np.full((len(self.tasks), len(self.tasks)), 0.3)\n",
    "        # np.fill_diagonal(self.rmp, 0)\n",
    "\n",
    "        # self.delta = [[[] for _ in range(len(self.tasks))] for _ in range(len(self.tasks))]\n",
    "\n",
    "        # self.s_rmp = [[[] for _ in range(len(self.tasks))] for _ in range(len(self.tasks))]\n",
    "\n",
    "        self.learningPhase = [LearningPhase(self.IndClass, self.tasks, t) for t in self.tasks]\n",
    "        \n",
    "        # initialize population\n",
    "        self.population = Population(\n",
    "            self.IndClass,\n",
    "            nb_inds_tasks = [nb_inds_each_task] * len(self.tasks), \n",
    "            dim = self.dim_uss,\n",
    "            list_tasks= self.tasks,\n",
    "            evaluate_initial_skillFactor = evaluate_initial_skillFactor\n",
    "        )\n",
    "\n",
    "        self.nb_inds_tasks = [nb_inds_each_task] * len(self.tasks)\n",
    "\n",
    "        MAXEVALS = nb_generations * nb_inds_each_task * len(self.tasks)\n",
    "        self.eval_k = [0] * len(self.tasks)\n",
    "        epoch = 1\n",
    "        \n",
    "        D0 = self.calculateD(population = np.array([[ind.genes for ind in sub.ls_inds] for sub in self.population]), \n",
    "                            population_fitness = np.array([sub.getFitness() for sub in self.population]),\n",
    "                            best = np.array([sub.__getBestIndividual__.genes for sub in self.population]),)\n",
    "\n",
    "        while sum(self.eval_k) < MAXEVALS:\n",
    "            self.population.update_rank()\n",
    "\n",
    "            if sum(self.eval_k) >= epoch * nb_inds_each_task * len(self.tasks):\n",
    "                # save history\n",
    "                self.history_cost.append([ind.fcost for ind in self.population.get_solves()])\n",
    "                self.render_process(epoch/nb_generations, ['Pop_size', 'Cost'], [[sum(self.nb_inds_tasks)], self.history_cost[-1]], use_sys= True)\n",
    "                epoch += 1\n",
    "            \n",
    "            self.delta = [[[] for _ in range(len(self.tasks))] for _ in range(len(self.tasks))]\n",
    "\n",
    "            self.s_rmp = [[[] for _ in range(len(self.tasks))] for _ in range(len(self.tasks))]\n",
    "\n",
    "            # offsprings = self.reproduction(sum(self.nb_inds_tasks), self.population)\n",
    "\n",
    "            # self.population = self.population + offsprings\n",
    "\n",
    "            matingPool = Population(\n",
    "                self.IndClass,\n",
    "                nb_inds_tasks = [0] * len(self.tasks), \n",
    "                dim = self.dim_uss,\n",
    "                list_tasks= self.tasks,\n",
    "                evaluate_initial_skillFactor = False\n",
    "            )\n",
    "\n",
    "            for idx in range(len(self.tasks)):\n",
    "                \n",
    "                idx_inds = np.argsort([ind.fcost for ind in self.population[idx].ls_inds])\n",
    "                \n",
    "                for i in idx_inds[:int(len(self.population[idx])/2)]:\n",
    "                    matingPool.__addIndividual__(self.population[idx].ls_inds[i])\n",
    "\n",
    "            offsprings = self.reproduction(len(self.population), matingPool)\n",
    "            \n",
    "            # merge and update rank\n",
    "            self.population = matingPool + offsprings\n",
    "            self.population.update_rank()\n",
    "            \n",
    "            # selection\n",
    "            self.nb_inds_tasks = [int(\n",
    "                int(max((nb_inds_min - nb_inds_max) * (sum(self.eval_k)/MAXEVALS) + nb_inds_max, nb_inds_min))\n",
    "            )] * len(self.tasks)\n",
    "            self.selection(self.population, self.nb_inds_tasks)\n",
    "\n",
    "            # update operators\n",
    "            self.crossover.update(population = self.population)\n",
    "            self.mutation.update(population = self.population)\n",
    "            self.dimension_strategy.update(population = self.population)\n",
    "\n",
    "            self.updateRMP(c)\n",
    "\n",
    "            self.phaseTwo(D0)\n",
    "\n",
    "        # self.phaseTwo(D0)\n",
    "        print('\\nEND!')\n",
    "\n",
    "        #solve \n",
    "        self.render_process(epoch/nb_generations, ['Pop_size', 'Cost'], [[sum(self.nb_inds_tasks)], self.history_cost[-1]], use_sys= True)\n",
    "        self.population.update_rank()\n",
    "        self.last_pop = self.population\n",
    "        return self.last_pop.get_solves()\n",
    "    \n",
    "    def reproduction(self, size: int, mating_pool: Population,) -> Population:\n",
    "        sub_size = int(size/len(self.tasks))\n",
    "       \n",
    "        offsprings = Population(self.IndClass,\n",
    "                                nb_inds_tasks = [0] * len(self.tasks), \n",
    "                                dim = self.dim_uss,\n",
    "                                list_tasks= self.tasks)\n",
    "        counter = np.zeros((len(self.tasks)))\n",
    "        \n",
    "        stopping = False\n",
    "        while not stopping:\n",
    "            pa, pb = mating_pool.__getRandomInds__(2)\n",
    "            ta = pa.skill_factor\n",
    "            tb = pb.skill_factor\n",
    "\n",
    "            if counter[ta] >= sub_size and counter[tb] >= sub_size:\n",
    "                continue\n",
    "\n",
    "            rmpValue = numba_random_gauss(mean = max(self.rmp[ta][tb], self.rmp[tb][ta]), sigma = 0.1)\n",
    "\n",
    "            if ta == tb:\n",
    "                self.eval_k[ta] += 2\n",
    "\n",
    "                oa, ob = self.crossover(pa, pb)\n",
    "\n",
    "                oa.skill_factor = ta\n",
    "                ob.skill_factor = ta\n",
    "                \n",
    "                offsprings.__addIndividual__(oa)\n",
    "                offsprings.__addIndividual__(ob)\n",
    "\n",
    "                counter[ta] += 2\n",
    "\n",
    "            elif random.random() <= rmpValue:\n",
    "                off = self.crossover(pa, pb)\n",
    "\n",
    "                for o in off:\n",
    "                    if counter[ta] < sub_size and random.random() < self.rmp[ta][tb]/(self.rmp[ta][tb] + self.rmp[tb][ta]):\n",
    "                        o.skill_factor = ta\n",
    "                        o = self.dimension_strategy(o, tb, pa)\n",
    "                        o.fcost = self.tasks[ta](o)\n",
    "\n",
    "                        offsprings.__addIndividual__(o)\n",
    "                        \n",
    "                        counter[ta] += 1\n",
    "                        self.eval_k[ta] += 1\n",
    "                        \n",
    "                        if pa.fcost > o.fcost:\n",
    "                            self.delta[ta][tb].append(pa.fcost - o.fcost)\n",
    "                            self.s_rmp[ta][tb].append(rmpValue)\n",
    "                    \n",
    "                    elif counter[tb] < sub_size:\n",
    "                        o.skill_factor = tb\n",
    "                        o = self.dimension_strategy(o, ta, pb)\n",
    "                        o.fcost = self.tasks[tb](o)\n",
    "\n",
    "                        offsprings.__addIndividual__(o)\n",
    "                        \n",
    "                        counter[tb] += 1\n",
    "                        self.eval_k[tb] += 1\n",
    "\n",
    "                        if pb.fcost > o.fcost:\n",
    "                            self.delta[tb][ta].append(pb.fcost - o.fcost)\n",
    "                            self.s_rmp[tb][ta].append(rmpValue)\n",
    "\n",
    "            else:\n",
    "                if counter[ta] < sub_size:\n",
    "                    paa: Individual = self.population[ta].__getRandomItems__()\n",
    "\n",
    "                    # while np.array_equal(paa.genes, pa.genes):\n",
    "                    #     paa: Individual = self.population[ta].__getRandomItems__()\n",
    "                    \n",
    "                    oa, _ = self.crossover(pa, paa)\n",
    "                    oa.skill_factor = ta\n",
    "\n",
    "                    offsprings.__addIndividual__(oa)\n",
    "\n",
    "                    counter[ta] += 1\n",
    "                    self.eval_k[ta] += 1\n",
    "\n",
    "                if counter[tb] < sub_size:\n",
    "                    pbb: Individual = self.population[tb].__getRandomItems__()\n",
    "\n",
    "                    # while np.array_equal(pbb.genes, pb.genes):\n",
    "                    #     pbb: Individual = self.population[tb].__getRandomItems__()\n",
    "                    \n",
    "                    ob, _ = self.crossover(pb, pbb)\n",
    "                    ob.skill_factor = tb\n",
    "                    \n",
    "                    offsprings.__addIndividual__(ob)\n",
    "                    \n",
    "                    counter[tb] += 1\n",
    "                    self.eval_k[tb] += 1\n",
    "                    \n",
    "            stopping = sum(counter >= sub_size) == len(self.tasks)\n",
    "\n",
    "        return offsprings\n",
    "\n",
    "    def phaseTwo(self, D0):\n",
    "        fcosts = [sub.getFitness() for sub in self.population]\n",
    "\n",
    "        D = self.calculateD(population = np.array([[ind.genes for ind in sub.ls_inds]for sub in self.population]), \n",
    "                            population_fitness = np.array(fcosts),\n",
    "                            best = np.array([sub.__getBestIndividual__.genes for sub in self.population]),\n",
    "                            )\n",
    "        \n",
    "        maxFit = np.max(fcosts, axis=1)\n",
    "        minFit = np.min(fcosts, axis=1)\n",
    "        maxDelta = maxFit - minFit + 1e-99\n",
    "\n",
    "        assert len(D) == len(maxDelta), \"Wrong shape. Got {} and {}\".format(D.shape, maxDelta.shape)\n",
    "        assert len(D) == len(self.tasks), \"Got wrong shape\"\n",
    "\n",
    "        sigma = np.where(D > D0, 0, 1 - D/D0)\n",
    "        nextPop = Population(IndClass = self.IndClass,\n",
    "                            dim = self.dim_uss,\n",
    "                            nb_inds_tasks=[0] * len(self.tasks),\n",
    "                            list_tasks=self.tasks)\n",
    "            \n",
    "        for i in range(len(self.tasks)):\n",
    "            self.eval_k[i] += self.learningPhase[i].evolve(self.population[i], nextPop, sigma[i], maxDelta[i])\n",
    "        \n",
    "        self.population = nextPop\n",
    "\n",
    "    def calculateD(self, population: np.array, population_fitness: np.array, best: np.array) -> np.array:\n",
    "        '''\n",
    "        Arguments include:\\n\n",
    "        + `population`: genes of the current population\n",
    "        + `population_fitness`: fitness of the current population\n",
    "        + `best`: the best gene of each subpop\n",
    "        + `nb_tasks`: number of tasks\n",
    "        '''\n",
    "        \n",
    "        D = np.empty((len(self.tasks)))\n",
    "        for i in range(len(self.tasks)):\n",
    "            gene_max = [np.max(population[i], axis = 1).tolist()] * 50\n",
    "            gene_min = [np.min(population[i], axis = 1).tolist()] * 50\n",
    "\n",
    "            D[i] = self.__class__._calculateD(np.array(gene_max).T, np.array(gene_min).T, population[i], population_fitness[i], best[i], model.TOLERANCE)\n",
    "        return D\n",
    "    \n",
    "    @jit(nopython = True, parallel = True, cache=True)\n",
    "    def _calculateD(gene_max: np.array, gene_min: np.array, subPop: np.array, subPop_fitness: np.array, best: np.array, TOLERANCE: float) -> float:\n",
    "            # gene_max = gene_max.flatten()\n",
    "            # gene_max = np.broadcast_to(gene_max, (subPop.shape[-1], subPop.shape[0])).T\n",
    "            # gene_min = gene_min.flatten()\n",
    "            # gene_min = np.broadcast_to(gene_min, (subPop.shape[-1], subPop.shape[0])).T\n",
    "            \n",
    "            w = np.where(subPop_fitness > TOLERANCE, 1/(subPop_fitness), 1/TOLERANCE)\n",
    "            # w = [1/ind if ind > TOLERANCE else 1/TOLERANCE for ind in population[i]]\n",
    "            # print(subPop.shape)\n",
    "            sum_w = sum(w)\n",
    "            d = (subPop - gene_min)/(gene_max - gene_min)\n",
    "            best = (best - gene_min)/(gene_max - gene_min)\n",
    "            d = np.sum((d - best) ** 2, axis=1)\n",
    "            d = np.sqrt(d)\n",
    "            assert d.shape == w.shape\n",
    "            # d = np.sqrt(np.sum(d, axis=0))\n",
    "            # d = np.sum([np.sqrt(np.sum((d[i] - best) * (d[i] - best))) for i in range(len(subPop))])\n",
    "\n",
    "            return np.sum(w * d/sum_w)\n",
    "    \n",
    "    def updateRMP(self, c: int):\n",
    "        for i in range(len(self.tasks)):\n",
    "            for j in range(len(self.tasks)):\n",
    "                if i == j:\n",
    "                    continue\n",
    "                if len(self.delta[i][j]) > 0:\n",
    "                    self.rmp[i][j] += self.__class__._updateRMP(self.delta[i][j], self.s_rmp[i][j], c)\n",
    "                else:\n",
    "                    self.rmp[i][j] = (1 - c) * self.rmp[i][j]\n",
    "                \n",
    "                self.rmp[i][j] = max(0.1, min(1, self.rmp[i][j]))\n",
    "\n",
    "    @jit(nopython = True, parallel = True, cache= True)\n",
    "    def _updateRMP(delta: List, s_rmp: List, c: float) -> float:\n",
    "        delta = np.array(delta)\n",
    "        s_rmp = np.array(s_rmp)\n",
    "        sum_delta = sum(delta)\n",
    "        tmp = (delta/sum_delta) * s_rmp\n",
    "        meanS = sum(tmp * s_rmp)\n",
    "        \n",
    "        return c * meanS/sum(tmp)\n",
    "    \n",
    "class LearningPhase():\n",
    "    M = 2\n",
    "    H = 10\n",
    "    def __init__(self, IndClass, list_tasks, task) -> None:\n",
    "        self.IndClass = IndClass\n",
    "        self.list_tasks = list_tasks\n",
    "        self.task = task\n",
    "        self.sum_improv = [0.0] * LearningPhase.M\n",
    "        self.consume_fes = [0.0] * LearningPhase.M\n",
    "        self.mem_cr = [0.5] * LearningPhase.H\n",
    "        self.mem_f = [0.5] * LearningPhase.H\n",
    "        self.s_cr = []\n",
    "        self.s_f = []\n",
    "        self.diff_f = []\n",
    "        self.mem_pos = 0\n",
    "        self.gen = 0\n",
    "        self.best_opcode = 1\n",
    "        self.searcher = [self.pbest1, PolynomialMutation(nm = 5).getInforTasks(self.IndClass, self.list_tasks)]\n",
    "\n",
    "    def evolve(self, subPop: SubPopulation, nextPop: Population, sigma: float, max_delta: float) -> SubPopulation:\n",
    "        self.gen += 1\n",
    "\n",
    "        if self.gen > 1:\n",
    "            self.best_opcode = self.__class__.updateOperator(sum_improve = self.sum_improv, \n",
    "                                                             consume_fes = self.consume_fes, \n",
    "                                                             M = LearningPhase.M)\n",
    "\n",
    "            self.sum_improv = [0.0] * LearningPhase.M\n",
    "            self.consume_fes = [1.0] * LearningPhase.M\n",
    "\n",
    "        # self.updateMemory()\n",
    "        \n",
    "        pbest_size = max(5, int(0.15 * len(subPop)))\n",
    "        # pbest = subPop.__getRandomItems__(size = pbest_size)\n",
    "        idx_inds = np.argsort([ind.fcost for ind in subPop.ls_inds])\n",
    "        pbest =  [subPop.ls_inds[i] for i in idx_inds[:pbest_size]] \n",
    "\n",
    "        for ind in subPop:\n",
    "            r = random.randint(0, LearningPhase.M - 1)\n",
    "            cr = numba_random_gauss(self.mem_cr[r], 0.1)\n",
    "            f = numba_random_cauchy(self.mem_f[r], 0.1)\n",
    "\n",
    "            opcode = random.randint(0, LearningPhase.M)\n",
    "            if opcode == LearningPhase.M:\n",
    "                opcode = self.best_opcode\n",
    "\n",
    "            self.consume_fes[opcode] += 1\n",
    "            \n",
    "            if opcode == 0:\n",
    "                child = self.searcher[opcode](ind, subPop, pbest, cr, f)\n",
    "            elif opcode == 1:\n",
    "                child = self.searcher[opcode](ind, return_newInd=True)\n",
    "\n",
    "            child.skill_factor = ind.skill_factor\n",
    "            child.fcost = self.task(child)\n",
    "            \n",
    "            diff = ind.fcost - child.fcost\n",
    "            if diff > 0:\n",
    "                survival = child\n",
    "\n",
    "                self.sum_improv[opcode] += diff\n",
    "\n",
    "                if opcode == 0:\n",
    "                    self.diff_f.append(diff)\n",
    "                    # self.s_cr.append(cr)\n",
    "                    # self.s_f.append(f)\n",
    "                \n",
    "            elif diff == 0 or random.random() <= sigma * np.exp(diff/max_delta):\n",
    "                survival = child\n",
    "            else:\n",
    "                survival = ind\n",
    "            \n",
    "            nextPop.__addIndividual__(survival)\n",
    "        \n",
    "        return pbest_size\n",
    "    \n",
    "    def pbest1(self, ind: Individual, subPop: SubPopulation, best: List[Individual], cr: float, f: float) -> Individual:\n",
    "        pbest = best[random.randint(0, len(best) - 1)]\n",
    "        \n",
    "        ind_ran1, ind_ran2 = subPop.__getRandomItems__(size = 2, replace= False)\n",
    "        \n",
    "        u = (numba_random_uniform(len(ind.genes)) < cr)\n",
    "        if np.sum(u) == 0:\n",
    "            u = np.zeros(shape= (subPop.dim,))\n",
    "            u[numba_randomchoice(subPop.dim)] = 1\n",
    "\n",
    "        # new_genes = np.where(u, \n",
    "        #     pbest.genes + f * (ind_ran1.genes - ind_ran2.genes),\n",
    "        #     ind.genes\n",
    "        # )\n",
    "        # # new_genes = np.clip(new_genes, ind.genes/2, (ind.genes + 1)/2)\n",
    "        # new_genes = np.where(new_genes < 0, ind.genes/2, np.where(new_genes > 1, (ind.genes + 1)/2, new_genes))\n",
    "\n",
    "        new_genes = self.__class__.produce_inds(ind.genes, pbest.genes, ind_ran1.genes, ind_ran2.genes, f, u)\n",
    "        new_ind = self.IndClass(new_genes)\n",
    "\n",
    "        return new_ind\n",
    "\n",
    "    @jit(nopython=True, parallel = True)\n",
    "    def produce_inds(ind_genes: np.array, best_genes: np.array, ind1_genes: np.array, ind2_genes: np.array, F: float, u: np.array) -> np.array:\n",
    "        new_genes = np.where(u,\n",
    "            best_genes + F * (ind1_genes - ind2_genes),\n",
    "            ind_genes\n",
    "        )\n",
    "        new_genes = np.where(new_genes > 1, (ind_genes + 1)/2, new_genes) \n",
    "        new_genes = np.where(new_genes < 0, (ind_genes + 0)/2, new_genes)\n",
    "\n",
    "        return new_genes\n",
    "\n",
    "    # def updateMemory(self):\n",
    "    #     if len(self.s_cr) > 0:\n",
    "    #         # self.diff_f = np.array(self.diff_f)\n",
    "    #         # self.s_cr = np.array(self.s_cr)\n",
    "    #         # self.s_f = np.array(self.s_f)\n",
    "\n",
    "    #         self.mem_cr[self.mem_pos] = self.__class__.updateMemoryCR(self.diff_f, self.s_cr)\n",
    "    #         self.mem_f[self.mem_pos] = self.__class__.updateMemoryF(self.diff_f, self.s_f)\n",
    "            \n",
    "    #         self.mem_pos = (self.mem_pos + 1) % LearningPhase.H\n",
    "\n",
    "    #         self.s_cr = []\n",
    "    #         self.s_f = []\n",
    "    #         self.diff_f = []\n",
    "\n",
    "    # @jit(nopython = True, parallel = True, cache=True)\n",
    "    # def updateMemoryCR(diff_f: List, s_cr: List) -> float:\n",
    "    #     diff_f = np.array(diff_f)\n",
    "    #     s_cr = np.array(s_cr)\n",
    "\n",
    "    #     sum_diff = sum(diff_f)\n",
    "    #     weight = diff_f/sum_diff\n",
    "    #     tmp_sum_cr = sum(weight * s_cr)\n",
    "    #     mem_cr = sum(weight * s_cr * s_cr)\n",
    "        \n",
    "    #     if tmp_sum_cr == 0 or mem_cr == -1:\n",
    "    #         return -1\n",
    "    #     else:\n",
    "    #         return mem_cr/tmp_sum_cr\n",
    "        \n",
    "    # @jit(nopython = True, parallel = True, cache = True)\n",
    "    # def updateMemoryF(diff_f: List, s_f: List) -> float:\n",
    "    #     diff_f = np.array(diff_f)\n",
    "    #     s_f = np.array(s_f)\n",
    "\n",
    "    #     sum_diff = sum(diff_f)\n",
    "    #     weight = diff_f/sum_diff\n",
    "    #     tmp_sum_f = sum(weight * s_f)\n",
    "    #     return sum(weight * (s_f ** 2)) / tmp_sum_f\n",
    "\n",
    "    @jit(nopython = True, parallel = True)\n",
    "    def updateOperator(sum_improve: List, consume_fes: List, M: int) -> int:\n",
    "        sum_improve = np.array(sum_improve)\n",
    "        consume_fes = np.array(consume_fes)\n",
    "        eta = sum_improve / consume_fes\n",
    "        best_rate = max(eta)\n",
    "        best_op = np.argmax(eta)\n",
    "        if best_rate > 0:\n",
    "            return best_op\n",
    "        else:\n",
    "            return random.randint(0, M - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: None -- Time: 03m 48.67s   99 % [===================>]  Pop_size: 2.00E+02  ,  Cost: 0.00E+00  2.26E-26  0.00E+00  0.00E+00  0.00E+00  4.31E-14  0.00E+00  6.36E-04  0.00E+00  7.96E+00  ,  \n",
      "END!\n",
      "Seed: None -- Time: 03m 50.91s  100 % [====================>]  Pop_size: 2.00E+02  ,  Cost: 0.00E+00  1.62E-26  0.00E+00  0.00E+00  0.00E+00  3.95E-14  0.00E+00  6.36E-04  0.00E+00  7.96E+00  ,  "
     ]
    }
   ],
   "source": [
    "baseModel = model()\n",
    "# from pyMSOO.MFEA.model import EME_BI\n",
    "# baseModel = EME_BI.model()\n",
    "baseModel.compile(\n",
    "    IndClass= IndClass,\n",
    "    tasks= tasks,\n",
    "    # crossover = KL_SBXCrossover(nc= 2, k= 100, conf_thres= 1),\n",
    "    crossover= SBX_Crossover(nc = 2),\n",
    "    mutation= PolynomialMutation(nm = 5),\n",
    "    selection= ElitismSelection(),\n",
    "    # dimension_strategy= DimensionAwareStrategy.DaS_strategy()\n",
    ")\n",
    "solve = baseModel.fit(\n",
    "    nb_generations = 1000, nb_inds_each_task= 100, \n",
    "    bound_pop= [0, 1], evaluate_initial_skillFactor= True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[100015, 100010, 99998, 100002, 99994, 99999, 99997, 99998, 100000, 99999]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print([lp.best_opcode for lp in baseModel.learningPhase])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: None -- Time: 03m 6.15s   99 % [===================>]  Pop_size: 2.00E+02  ,  Cost: 0.00E+00  1.70E-26  0.00E+00  0.00E+00  0.00E+00  3.60E-14  0.00E+00  6.36E-04  0.00E+00  0.00E+00  ,   \n",
      "END!\n",
      "Seed: None -- Time: 03m 7.76s  100 % [====================>]  Pop_size: 2.00E+02  ,  Cost: 0.00E+00  1.70E-26  0.00E+00  0.00E+00  0.00E+00  3.24E-14  0.00E+00  6.36E-04  0.00E+00  0.00E+00  ,  "
     ]
    }
   ],
   "source": [
    "\n",
    "baseModel = model()\n",
    "baseModel.compile(\n",
    "    IndClass= IndClass,\n",
    "    tasks= tasks,\n",
    "    # crossover = KL_SBXCrossover(nc= 2, k= 100, conf_thres= 1),\n",
    "    crossover= SBX_Crossover(nc = 2),\n",
    "    mutation= PolynomialMutation(nm = 5),\n",
    "    selection= ElitismSelection(),\n",
    "    dimension_strategy= DaS_strategy()\n",
    ")\n",
    "solve = baseModel.fit(\n",
    "    nb_generations = 1000, nb_inds_each_task= 100, \n",
    "    bound_pop= [0, 1], evaluate_initial_skillFactor= True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r\"F:\\BTVN\\DSAI\\Optimization Lab\\Paper\\Efficient knowledge transfer\\history_cost_summaries_EME_BI_woDaS.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>EME-BI</th>\n",
       "      <th>EME_BI_wo_DaS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>450</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.649250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>451</td>\n",
       "      <td>153.862380</td>\n",
       "      <td>140.877084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>452</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>453</td>\n",
       "      <td>10.890937</td>\n",
       "      <td>23.687499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>454</td>\n",
       "      <td>5022.383910</td>\n",
       "      <td>6610.532774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>455</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.183991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>456</td>\n",
       "      <td>112.875490</td>\n",
       "      <td>159.721696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>457</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>458</td>\n",
       "      <td>12.390112</td>\n",
       "      <td>21.295734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>459</td>\n",
       "      <td>4979.867545</td>\n",
       "      <td>6728.074941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>460</td>\n",
       "      <td>0.029993</td>\n",
       "      <td>16.883884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>461</td>\n",
       "      <td>128.012455</td>\n",
       "      <td>158.884861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>462</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>463</td>\n",
       "      <td>12.684814</td>\n",
       "      <td>21.087148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>464</td>\n",
       "      <td>5050.060552</td>\n",
       "      <td>5754.026860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>465</td>\n",
       "      <td>2.065367</td>\n",
       "      <td>15.545684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>466</td>\n",
       "      <td>136.240922</td>\n",
       "      <td>152.131004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>467</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>468</td>\n",
       "      <td>13.519725</td>\n",
       "      <td>20.299626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>469</td>\n",
       "      <td>4481.177414</td>\n",
       "      <td>6285.306503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>470</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.651320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>471</td>\n",
       "      <td>134.383059</td>\n",
       "      <td>162.881150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>472</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>473</td>\n",
       "      <td>9.980170</td>\n",
       "      <td>19.615759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>474</td>\n",
       "      <td>4404.093869</td>\n",
       "      <td>5303.187592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>475</td>\n",
       "      <td>0.685091</td>\n",
       "      <td>9.460654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>476</td>\n",
       "      <td>132.202483</td>\n",
       "      <td>166.484685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>477</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>478</td>\n",
       "      <td>11.444059</td>\n",
       "      <td>20.868381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>479</td>\n",
       "      <td>4755.577797</td>\n",
       "      <td>6082.033661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>480</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.058803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>481</td>\n",
       "      <td>152.043308</td>\n",
       "      <td>159.299178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>482</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>483</td>\n",
       "      <td>11.106148</td>\n",
       "      <td>24.428280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>484</td>\n",
       "      <td>4991.372559</td>\n",
       "      <td>6248.724829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>485</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.896160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>486</td>\n",
       "      <td>136.426152</td>\n",
       "      <td>169.301769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>487</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>488</td>\n",
       "      <td>10.483358</td>\n",
       "      <td>23.299838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>489</td>\n",
       "      <td>5397.686649</td>\n",
       "      <td>6405.145432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>490</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.494818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>491</td>\n",
       "      <td>147.769146</td>\n",
       "      <td>143.050375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>492</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.000493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>493</td>\n",
       "      <td>10.471335</td>\n",
       "      <td>20.319466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>494</td>\n",
       "      <td>5181.970735</td>\n",
       "      <td>6202.968885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>495</td>\n",
       "      <td>0.686529</td>\n",
       "      <td>15.653057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>496</td>\n",
       "      <td>113.118472</td>\n",
       "      <td>179.197397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>497</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>498</td>\n",
       "      <td>10.452321</td>\n",
       "      <td>21.174398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>499</td>\n",
       "      <td>4659.249712</td>\n",
       "      <td>5410.368813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0       EME-BI  EME_BI_wo_DaS\n",
       "450         450     0.000000       0.649250\n",
       "451         451   153.862380     140.877084\n",
       "452         452     0.000000       0.000329\n",
       "453         453    10.890937      23.687499\n",
       "454         454  5022.383910    6610.532774\n",
       "455         455     0.000000       8.183991\n",
       "456         456   112.875490     159.721696\n",
       "457         457     0.000000       0.000000\n",
       "458         458    12.390112      21.295734\n",
       "459         459  4979.867545    6728.074941\n",
       "460         460     0.029993      16.883884\n",
       "461         461   128.012455     158.884861\n",
       "462         462     0.000000       0.000904\n",
       "463         463    12.684814      21.087148\n",
       "464         464  5050.060552    5754.026860\n",
       "465         465     2.065367      15.545684\n",
       "466         466   136.240922     152.131004\n",
       "467         467     0.000000       0.000000\n",
       "468         468    13.519725      20.299626\n",
       "469         469  4481.177414    6285.306503\n",
       "470         470     0.000000       0.651320\n",
       "471         471   134.383059     162.881150\n",
       "472         472     0.000000       0.000247\n",
       "473         473     9.980170      19.615759\n",
       "474         474  4404.093869    5303.187592\n",
       "475         475     0.685091       9.460654\n",
       "476         476   132.202483     166.484685\n",
       "477         477     0.000000       0.000000\n",
       "478         478    11.444059      20.868381\n",
       "479         479  4755.577797    6082.033661\n",
       "480         480     0.000000       4.058803\n",
       "481         481   152.043308     159.299178\n",
       "482         482     0.000000       0.000493\n",
       "483         483    11.106148      24.428280\n",
       "484         484  4991.372559    6248.724829\n",
       "485         485     0.000000      10.896160\n",
       "486         486   136.426152     169.301769\n",
       "487         487     0.000000       0.000000\n",
       "488         488    10.483358      23.299838\n",
       "489         489  5397.686649    6405.145432\n",
       "490         490     0.000000      11.494818\n",
       "491         491   147.769146     143.050375\n",
       "492         492     0.000247       0.000493\n",
       "493         493    10.471335      20.319466\n",
       "494         494  5181.970735    6202.968885\n",
       "495         495     0.686529      15.653057\n",
       "496         496   113.118472     179.197397\n",
       "497         497     0.000000       0.000000\n",
       "498         498    10.452321      21.174398\n",
       "499         499  4659.249712    5410.368813"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyMSOO.MFEA.model import EME_BI\n",
    "\n",
    "# ls_benchmark = []\n",
    "# ls_IndClass = []\n",
    "# name_benchmark = []\n",
    "# ls_tasks = [10]\n",
    "\n",
    "# for i in ls_tasks:\n",
    "#     # t, ic = WCCI22_benchmark.get_complex_benchmark(i)\n",
    "#     t, ic = WCCI22_benchmark.get_50tasks_benchmark(i)\n",
    "#     ls_benchmark.append(t)\n",
    "#     ls_IndClass.append(ic)\n",
    "#     name_benchmark.append(str(i))\n",
    "\n",
    "\n",
    "\n",
    "# smpModel = MultiBenchmark(\n",
    "#     ls_benchmark= ls_benchmark,\n",
    "#     name_benchmark= name_benchmark,\n",
    "#     ls_IndClass= ls_IndClass,\n",
    "#     model= EME_BI\n",
    "# )\n",
    "\n",
    "# smpModel.compile(\n",
    "#     crossover= SBX_Crossover(nc = 2),\n",
    "#     mutation= PolynomialMutation(nm = 5),\n",
    "#     selection= ElitismSelection(),\n",
    "#     # dimension_strategy = DaS_strategy(eta = 3)\n",
    "# )\n",
    "# smpModel.fit(\n",
    "#     nb_generations = 1000,nb_inds_each_task= 100, \n",
    "#     bound_pop= [0, 1], evaluate_initial_skillFactor= True\n",
    "# )\n",
    "# a = smpModel.run(\n",
    "#     nb_run= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: None -- Time: 24m 52.38s   99 % [===================>]  Pop_size: 1.00E+03  ,  Cost: 1.99E+01  8.47E+01  0.00E+00  8.18E-02  5.69E+03  2.00E+01  5.28E+01  0.00E+00  7.67E+00  7.61E+03  2.53E-14  6.87E+01  0.00E+00  1.66E+00  5.69E+03  2.53E-14  8.83E+01  0.00E+00  1.30E+01  7.32E+03  2.89E-14  8.81E+01  0.00E+00  2.59E-01  4.86E+03  2.00E+01  4.88E+01  1.11E-16  6.98E+00  7.25E+03  1.99E+01  6.53E+01  1.11E-16  1.09E+01  4.46E+03  2.00E+01  8.13E+01  0.00E+00  1.58E+00  6.76E+03  2.89E-14  9.96E+01  0.00E+00  1.97E+00  6.21E+03  2.00E+01  6.24E+01  0.00E+00  6.19E-02  4.94E+03  ,  \n",
      "END!\n",
      "Seed: None -- Time: 25m 5.04s  100 % [====================>]  Pop_size: 1.00E+03  ,  Cost: 1.99E+01  8.44E+01  0.00E+00  8.18E-02  5.69E+03  2.00E+01  5.25E+01  0.00E+00  7.67E+00  7.61E+03  2.89E-14  6.87E+01  0.00E+00  1.66E+00  5.69E+03  2.89E-14  8.82E+01  0.00E+00  1.30E+01  7.32E+03  2.89E-14  8.54E+01  0.00E+00  2.59E-01  4.86E+03  2.00E+01  4.88E+01  1.11E-16  6.98E+00  7.25E+03  1.99E+01  6.53E+01  1.11E-16  1.09E+01  4.46E+03  2.00E+01  8.13E+01  0.00E+00  1.58E+00  6.76E+03  2.89E-14  9.92E+01  0.00E+00  1.97E+00  6.21E+03  2.00E+01  6.24E+01  0.00E+00  6.19E-02  4.94E+03  ,  "
     ]
    }
   ],
   "source": [
    "res = []\n",
    "# for i in range(1, 11):\n",
    "t, ic = WCCI22_benchmark.get_50tasks_benchmark(10)\n",
    "baseModel = model()\n",
    "baseModel.compile(\n",
    "    IndClass= ic,\n",
    "    tasks= t,\n",
    "    # crossover = KL_SBXCrossover(nc= 2, k= 100, conf_thres= 1),\n",
    "    crossover= SBX_Crossover(nc = 2),\n",
    "    mutation= PolynomialMutation(nm = 5),\n",
    "    selection= ElitismSelection(),\n",
    "    # dimension_strategy= DaS_strategy()\n",
    ")\n",
    "solve = baseModel.fit(\n",
    "    nb_generations = 1000, nb_inds_each_task= 100, \n",
    "    bound_pop= [0, 1], evaluate_initial_skillFactor= True\n",
    ")\n",
    "\n",
    "# res.append([subpop.getSolveInd().fcost for subpop in baseModel.last_pop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = np.array([subpop.getSolveInd().fcost for subpop in baseModel.last_pop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = np.where(h < 1e-6, 0, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.99465199e+01 8.43881889e+01 0.00000000e+00 8.18242387e-02\n",
      " 5.68618259e+03 1.99714880e+01 5.24616162e+01 0.00000000e+00\n",
      " 7.67451108e+00 7.61248528e+03 0.00000000e+00 6.86824019e+01\n",
      " 0.00000000e+00 1.66300205e+00 5.69074145e+03 0.00000000e+00\n",
      " 8.82043227e+01 0.00000000e+00 1.30255117e+01 7.31935204e+03\n",
      " 0.00000000e+00 8.52809900e+01 0.00000000e+00 2.59298663e-01\n",
      " 4.85861752e+03 1.99765960e+01 4.88456755e+01 0.00000000e+00\n",
      " 6.98306116e+00 7.24676037e+03 1.99238871e+01 6.52713702e+01\n",
      " 0.00000000e+00 1.09407466e+01 4.46212616e+03 1.99816756e+01\n",
      " 8.12682932e+01 0.00000000e+00 1.58228123e+00 6.75956456e+03\n",
      " 0.00000000e+00 9.92276683e+01 0.00000000e+00 1.96977725e+00\n",
      " 6.20852231e+03 1.99561195e+01 6.23440343e+01 0.00000000e+00\n",
      " 6.19344617e-02 4.94269582e+03]\n",
      "[0.00000000e+00 1.53862380e+02 0.00000000e+00 1.08909369e+01\n",
      " 5.02238391e+03 0.00000000e+00 1.12875490e+02 0.00000000e+00\n",
      " 1.23901121e+01 4.97986754e+03 2.99928333e-02 1.28012455e+02\n",
      " 0.00000000e+00 1.26848136e+01 5.05006055e+03 2.06536650e+00\n",
      " 1.36240922e+02 0.00000000e+00 1.35197252e+01 4.48117741e+03\n",
      " 0.00000000e+00 1.34383059e+02 0.00000000e+00 9.98016957e+00\n",
      " 4.40409387e+03 6.85090900e-01 1.32202483e+02 0.00000000e+00\n",
      " 1.14440587e+01 4.75557780e+03 0.00000000e+00 1.52043308e+02\n",
      " 0.00000000e+00 1.11061484e+01 4.99137256e+03 0.00000000e+00\n",
      " 1.36426152e+02 0.00000000e+00 1.04833584e+01 5.39768665e+03\n",
      " 0.00000000e+00 1.47769146e+02 2.46533333e-04 1.04713353e+01\n",
      " 5.18197074e+03 6.86528867e-01 1.13118472e+02 0.00000000e+00\n",
      " 1.04523205e+01 4.65924971e+03]\n"
     ]
    }
   ],
   "source": [
    "print(h)\n",
    "print(np.array(df[\"EME-BI\"][-50:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(h > df[\"EME-BI\"][-50:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(h < df[\"EME-BI\"][-50:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(h < f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(h > f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: None -- Time: 26m 45.56s   99 % [===================>]  Pop_size: 1.00E+03  ,  Cost: 2.89E-14  7.86E+01  0.00E+00  4.19E+00  6.45E+03  2.00E+01  6.53E+01  1.67E-15  3.14E+00  5.60E+03  1.99E+01  6.65E+01  0.00E+00  6.58E+00  7.72E+03  2.00E+01  7.61E+01  0.00E+00  8.31E+00  6.24E+03  1.99E+01  9.50E+01  1.11E-16  1.55E-01  5.08E+03  2.89E-14  1.12E+02  0.00E+00  1.21E+01  4.96E+03  2.89E-14  6.34E+01  0.00E+00  3.82E+00  7.41E+03  1.99E+01  5.82E+01  0.00E+00  9.44E+00  5.25E+03  2.00E+01  6.90E+01  0.00E+00  3.47E+00  8.15E+03  2.00E+01  6.28E+01  0.00E+00  3.52E+00  6.84E+03  ,  \n",
      "END!\n",
      "Seed: None -- Time: 26m 58.97s  100 % [====================>]  Pop_size: 1.00E+03  ,  Cost: 2.89E-14  7.86E+01  0.00E+00  4.19E+00  6.45E+03  2.00E+01  6.53E+01  1.67E-15  3.14E+00  5.60E+03  1.99E+01  6.64E+01  0.00E+00  6.58E+00  7.72E+03  2.00E+01  7.48E+01  0.00E+00  8.31E+00  6.24E+03  1.99E+01  9.40E+01  1.11E-16  1.55E-01  5.08E+03  3.24E-14  1.12E+02  0.00E+00  1.21E+01  4.96E+03  2.89E-14  4.39E+01  0.00E+00  3.82E+00  7.41E+03  1.99E+01  5.82E+01  0.00E+00  9.44E+00  5.25E+03  2.00E+01  6.90E+01  0.00E+00  3.47E+00  8.15E+03  2.00E+01  6.27E+01  0.00E+00  3.52E+00  6.84E+03  ,  "
     ]
    }
   ],
   "source": [
    "res = []\n",
    "# for i in range(1, 11):\n",
    "t, ic = WCCI22_benchmark.get_50tasks_benchmark(10)\n",
    "baseModel = model()\n",
    "baseModel.compile(\n",
    "    IndClass= ic,\n",
    "    tasks= t,\n",
    "    # crossover = KL_SBXCrossover(nc= 2, k= 100, conf_thres= 1),\n",
    "    crossover= SBX_Crossover(nc = 2),\n",
    "    mutation= PolynomialMutation(nm = 5),\n",
    "    selection= ElitismSelection(),\n",
    "    dimension_strategy= DaS_strategy()\n",
    ")\n",
    "solve = baseModel.fit(\n",
    "    nb_generations = 1000, nb_inds_each_task= 100, \n",
    "    bound_pop= [0, 1], evaluate_initial_skillFactor= True\n",
    ")\n",
    "\n",
    "# res.append([subpop.getSolveInd().fcost for subpop in baseModel.last_pop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = np.array([subpop.getSolveInd().fcost for subpop in baseModel.last_pop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.88657986e-14 7.86213722e+01 0.00000000e+00 4.19149613e+00\n",
      " 6.44892467e+03 1.99815250e+01 6.52893227e+01 1.66533454e-15\n",
      " 3.14240182e+00 5.59822794e+03 1.99448631e+01 6.64177645e+01\n",
      " 0.00000000e+00 6.58146619e+00 7.72265685e+03 1.99675411e+01\n",
      " 7.47662851e+01 0.00000000e+00 8.31223049e+00 6.24413039e+03\n",
      " 1.99320109e+01 9.39396401e+01 1.11022302e-16 1.54717625e-01\n",
      " 5.07698397e+03 2.88657986e-14 1.11911718e+02 0.00000000e+00\n",
      " 1.20604467e+01 4.95923053e+03 2.88657986e-14 4.38322588e+01\n",
      " 0.00000000e+00 3.81593582e+00 7.40915177e+03 1.99358046e+01\n",
      " 5.82412989e+01 0.00000000e+00 9.44232361e+00 5.24641177e+03\n",
      " 1.99903940e+01 6.89739982e+01 0.00000000e+00 3.46751251e+00\n",
      " 8.14606994e+03 1.99709921e+01 6.27447499e+01 0.00000000e+00\n",
      " 3.52363522e+00 6.83571201e+03]\n",
      "[0.00000000e+00 1.53862380e+02 0.00000000e+00 1.08909369e+01\n",
      " 5.02238391e+03 0.00000000e+00 1.12875490e+02 0.00000000e+00\n",
      " 1.23901121e+01 4.97986754e+03 2.99928333e-02 1.28012455e+02\n",
      " 0.00000000e+00 1.26848136e+01 5.05006055e+03 2.06536650e+00\n",
      " 1.36240922e+02 0.00000000e+00 1.35197252e+01 4.48117741e+03\n",
      " 0.00000000e+00 1.34383059e+02 0.00000000e+00 9.98016957e+00\n",
      " 4.40409387e+03 6.85090900e-01 1.32202483e+02 0.00000000e+00\n",
      " 1.14440587e+01 4.75557780e+03 0.00000000e+00 1.52043308e+02\n",
      " 0.00000000e+00 1.11061484e+01 4.99137256e+03 0.00000000e+00\n",
      " 1.36426152e+02 0.00000000e+00 1.04833584e+01 5.39768665e+03\n",
      " 0.00000000e+00 1.47769146e+02 2.46533333e-04 1.04713353e+01\n",
      " 5.18197074e+03 6.86528867e-01 1.13118472e+02 0.00000000e+00\n",
      " 1.04523205e+01 4.65924971e+03]\n"
     ]
    }
   ],
   "source": [
    "print(f)\n",
    "print(np.array(df[\"EME-BI\"][-50:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = np.where(f < 1e-6, 0, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(f < df[\"EME-BI\"][-50:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(f > df[\"EME-BI\"][-50:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(f < df[\"EME_BI_wo_DaS\"][-50:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df[\"EME_BI_wo_DaS\"][-50:] < df[\"EME-BI\"][-50:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df[\"EME_BI_wo_DaS\"][-50:] > df[\"EME-BI\"][-50:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MFEA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
