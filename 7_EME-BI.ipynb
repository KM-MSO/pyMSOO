{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyMSOO.utils.Crossover import *\n",
    "from pyMSOO.utils.Mutation import *\n",
    "from pyMSOO.utils.Selection import *\n",
    "from pyMSOO.utils.DimensionAwareStrategy import *\n",
    "from pyMSOO.MFEA.benchmark.continous import *\n",
    "from pyMSOO.utils.MultiRun.RunMultiTime import * \n",
    "from pyMSOO.utils.MultiRun.RunMultiBenchmark import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tasks, IndClass = CEC17_benchmark.get_2tasks_benchmark(1)\n",
    "# tasks, IndClass = WCCI22_benchmark.get_complex_benchmark(1)\n",
    "tasks, IndClass = CEC17_benchmark.get_10tasks_benchmark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from numba import jit, njit\n",
    "from numba import typed\n",
    "from numba.core import types\n",
    "from typing import Dict\n",
    "\n",
    "from pyMSOO.MFEA.model import AbstractModel\n",
    "from pyMSOO.utils import Crossover, Mutation, Selection, DimensionAwareStrategy\n",
    "from pyMSOO.utils.EA import *\n",
    "from pyMSOO.utils.numba_utils import numba_randomchoice, numba_random_gauss, numba_random_cauchy, numba_argsort\n",
    "from pyMSOO.utils.Search import *\n",
    "\n",
    "class model(AbstractModel.model):\n",
    "    TOLERANCE = 1e-6\n",
    "    INF = 1e8\n",
    "    def compile(self, \n",
    "        IndClass: Type[Individual],\n",
    "        tasks: List[AbstractTask], \n",
    "        crossover: Crossover.SBX_Crossover, \n",
    "        mutation: Mutation.PolynomialMutation, \n",
    "        selection: Selection.ElitismSelection,\n",
    "        dimension_strategy: DimensionAwareStrategy.AbstractDaS = DimensionAwareStrategy.NoDaS(),\n",
    "        *args, **kwargs):\n",
    "        super().compile(IndClass, tasks, crossover, mutation,dimension_strategy, selection, *args, **kwargs)\n",
    "    \n",
    "    def fit(self, nb_generations, \n",
    "            nb_inds_each_task = 100, \n",
    "            nb_inds_max = 100,\n",
    "            nb_inds_min = 20,\n",
    "            evaluate_initial_skillFactor = True, \n",
    "            c = 0.06,\n",
    "            *args, \n",
    "            **kwargs) -> List[Individual]:\n",
    "        super().fit(*args, **kwargs)\n",
    "\n",
    "        # nb_inds_min\n",
    "        if nb_inds_min is not None:\n",
    "            assert nb_inds_each_task >= nb_inds_min\n",
    "        else: \n",
    "            nb_inds_min = nb_inds_each_task\n",
    "\n",
    "        self.rmp = np.full((len(self.tasks), len(self.tasks)), 0.3)\n",
    "        self.learningPhase = [LearningPhase(self.IndClass, self.tasks, t) for t in self.tasks]\n",
    "        \n",
    "        # initialize population\n",
    "        self.population = Population(\n",
    "            self.IndClass,\n",
    "            nb_inds_tasks = [nb_inds_each_task] * len(self.tasks), \n",
    "            dim = self.dim_uss,\n",
    "            list_tasks= self.tasks,\n",
    "            evaluate_initial_skillFactor = evaluate_initial_skillFactor\n",
    "        )\n",
    "\n",
    "        self.nb_inds_tasks = [nb_inds_each_task] * len(self.tasks)\n",
    "\n",
    "        MAXEVALS = nb_generations * nb_inds_each_task * len(self.tasks)\n",
    "        self.max_eval_k = [nb_generations * nb_inds_each_task] * len(self.tasks)\n",
    "        self.eval_k = [0] * len(self.tasks)\n",
    "        epoch = 1\n",
    "        \n",
    "        D0 = self.calculateD(population = np.array([[ind.genes for ind in sub.ls_inds] for sub in self.population]), \n",
    "                            population_fitness = np.array([sub.getFitness() for sub in self.population]),\n",
    "                            best = np.array([sub.__getBestIndividual__.genes for sub in self.population]),)\n",
    "\n",
    "        while sum(self.eval_k) < MAXEVALS:\n",
    "            self.delta = [[[] for _ in range(len(self.tasks))] for _ in range(len(self.tasks))]\n",
    "\n",
    "            self.s_rmp = [[[] for _ in range(len(self.tasks))] for _ in range(len(self.tasks))]\n",
    "\n",
    "            self.population.update_rank()\n",
    "            # print(self.eval_k)\n",
    "            if sum(self.eval_k) >= epoch * nb_inds_each_task * len(self.tasks):\n",
    "                # save history\n",
    "                self.history_cost.append([ind.fcost for ind in self.population.get_solves()])\n",
    "                self.render_process(epoch/nb_generations, ['Pop_size', 'Cost'], [[sum(self.nb_inds_tasks)], self.history_cost[-1]], use_sys= True)\n",
    "                epoch += 1\n",
    "\n",
    "            # offsprings = self.reproduction(sum(self.nb_inds_tasks), self.population)\n",
    "\n",
    "            # self.population = self.population + offsprings\n",
    "            # start = time.time()\n",
    "            # matingPool = Population(\n",
    "            #     self.IndClass,\n",
    "            #     nb_inds_tasks = [0] * len(self.tasks), \n",
    "            #     dim = self.dim_uss,\n",
    "            #     list_tasks= self.tasks,\n",
    "            #     evaluate_initial_skillFactor = False\n",
    "            # )\n",
    "\n",
    "            # for idx in range(len(self.tasks)):\n",
    "                \n",
    "            #     idx_inds = numba_argsort([ind.fcost for ind in self.population[idx].ls_inds])\n",
    "                \n",
    "            #     for i in idx_inds[:int(len(self.population[idx])/2)]:\n",
    "            #         matingPool.__addIndividual__(self.population[idx].ls_inds[i])\n",
    "\n",
    "            self.selection(self.population, [int(x/2) for x in self.nb_inds_tasks])\n",
    "\n",
    "            offsprings = self.reproduction(sum(self.nb_inds_tasks), self.population)\n",
    "        \n",
    "            # # merge and update rank\n",
    "            self.population = self.population + offsprings\n",
    "            self.population.update_rank()\n",
    "            # end = time.time()\n",
    "            # print(\"E: \", end - start)\n",
    "            # selection\n",
    "            self.nb_inds_tasks = [int(\n",
    "                int(max((nb_inds_min - nb_inds_max) * (sum(self.eval_k)/MAXEVALS) + nb_inds_max, nb_inds_min))\n",
    "            )] * len(self.tasks)\n",
    "            self.selection(self.population, self.nb_inds_tasks)\n",
    "\n",
    "            # update operators\n",
    "            self.crossover.update(population = self.population)\n",
    "            self.mutation.update(population = self.population)\n",
    "            self.dimension_strategy.update(population = self.population)\n",
    "            # start = time.time()\n",
    "            self.updateRMP(c)\n",
    "            # end = time.time()\n",
    "            # print(\"G: \", end - start)\n",
    "            # start = time.time()\n",
    "            self.phaseTwo(D0)\n",
    "            # end = time.time()\n",
    "            # print(\"Phase two: \", end - start)\n",
    "        # self.phaseTwo(D0)\n",
    "        print('\\nEND!')\n",
    "\n",
    "        #solve \n",
    "        self.render_process(epoch/nb_generations, ['Pop_size', 'Cost'], [[sum(self.nb_inds_tasks)], self.history_cost[-1]], use_sys= True)\n",
    "        self.population.update_rank()\n",
    "        self.last_pop = self.population\n",
    "        return self.last_pop.get_solves()\n",
    "    \n",
    "    def reproduction(self, size: int, mating_pool: Population,) -> Population:\n",
    "        sub_size = int(size/len(self.tasks))\n",
    "       \n",
    "        offsprings = Population(self.IndClass,\n",
    "                                nb_inds_tasks = [0] * len(self.tasks), \n",
    "                                dim = self.dim_uss,\n",
    "                                list_tasks= self.tasks)\n",
    "        counter = np.zeros((len(self.tasks)))  \n",
    "\n",
    "        stopping = False\n",
    "        while not stopping:\n",
    "            pa, pb = mating_pool.__getRandomInds__(2)\n",
    "            ta = pa.skill_factor\n",
    "            tb = pb.skill_factor\n",
    "\n",
    "            if counter[ta] >= sub_size and counter[tb] >= sub_size:\n",
    "                continue\n",
    "\n",
    "            rmpValue = numba_random_gauss(mean = max(self.rmp[ta][tb], self.rmp[tb][ta]), sigma = 0.1)\n",
    "\n",
    "            if ta == tb:\n",
    "                # self.eval_k[ta] += 2\n",
    "\n",
    "                oa, ob = self.crossover(pa, pb)\n",
    "\n",
    "                oa.skill_factor = ta\n",
    "                ob.skill_factor = ta\n",
    "\n",
    "                if self.eval_k[ta] >= self.max_eval_k[ta]:\n",
    "                    oa.fcost = model.INF\n",
    "                else:\n",
    "                    self.eval_k[ta] += 1\n",
    "\n",
    "                offsprings.__addIndividual__(oa)\n",
    "\n",
    "                if self.eval_k[tb] >= self.max_eval_k[tb]:\n",
    "                    ob.fcost = model.INF\n",
    "                else:\n",
    "                    self.eval_k[tb] += 1\n",
    "\n",
    "                offsprings.__addIndividual__(ob)\n",
    "\n",
    "                counter[ta] += 2\n",
    "\n",
    "            elif random.random() <= rmpValue:\n",
    "                off = self.crossover(pa, pb)\n",
    "\n",
    "                for o in off:\n",
    "                    if counter[ta] < sub_size and random.random() < self.rmp[ta][tb]/(self.rmp[ta][tb] + self.rmp[tb][ta]):\n",
    "                        o.skill_factor = ta\n",
    "                        o = self.dimension_strategy(o, tb, pa)\n",
    "                        if self.eval_k[ta] >= self.max_eval_k[ta]:\n",
    "                            o.fcost = model.INF\n",
    "                        else:\n",
    "                            self.eval_k[ta] += 1\n",
    "                            o.fcost = self.tasks[ta](o)\n",
    "\n",
    "                        offsprings.__addIndividual__(o)\n",
    "                        \n",
    "                        counter[ta] += 1\n",
    "                        # self.eval_k[ta] += 1\n",
    "                        \n",
    "                        if pa.fcost > o.fcost:\n",
    "                            self.delta[ta][tb].append(pa.fcost - o.fcost)\n",
    "                            self.s_rmp[ta][tb].append(rmpValue)\n",
    "                    \n",
    "                    elif counter[tb] < sub_size:\n",
    "                        o.skill_factor = tb\n",
    "                        o = self.dimension_strategy(o, ta, pb)\n",
    "        \n",
    "                        if self.eval_k[tb] >= self.max_eval_k[tb]:\n",
    "                            o.fcost = model.INF\n",
    "                        else:\n",
    "                            self.eval_k[tb] += 1\n",
    "                            o.fcost = self.tasks[tb](o)\n",
    "\n",
    "                        offsprings.__addIndividual__(o)\n",
    "                        \n",
    "                        counter[tb] += 1\n",
    "                        # self.eval_k[tb] += 1\n",
    "\n",
    "                        if pb.fcost > o.fcost:\n",
    "                            self.delta[tb][ta].append(pb.fcost - o.fcost)\n",
    "                            self.s_rmp[tb][ta].append(rmpValue)\n",
    "\n",
    "            else:\n",
    "                if counter[ta] < sub_size:\n",
    "                    paa: Individual = self.population[ta].__getRandomItems__()\n",
    "\n",
    "                    # while np.array_equal(paa.genes, pa.genes):\n",
    "                    #     paa: Individual = self.population[ta].__getRandomItems__()\n",
    "                    \n",
    "                    oa, _ = self.crossover(pa, paa)\n",
    "                    oa.skill_factor = ta\n",
    "                    \n",
    "                    if self.eval_k[ta] >= self.max_eval_k[ta]:\n",
    "                        oa.fcost = model.INF\n",
    "                    else:\n",
    "                        self.eval_k[ta] += 1\n",
    "                        oa.fcost = self.tasks[ta](oa)\n",
    "\n",
    "                    offsprings.__addIndividual__(oa)\n",
    "\n",
    "                    counter[ta] += 1\n",
    "                    # self.eval_k[ta] += 1\n",
    "\n",
    "                if counter[tb] < sub_size:\n",
    "                    pbb: Individual = self.population[tb].__getRandomItems__()\n",
    "                    \n",
    "                    ob, _ = self.crossover(pb, pbb)\n",
    "                    ob.skill_factor = tb\n",
    "\n",
    "                    if self.eval_k[tb] >= self.max_eval_k[tb]:\n",
    "                        ob.fcost = model.INF\n",
    "                    else:\n",
    "                        self.eval_k[tb] += 1\n",
    "                        ob.fcost = self.tasks[tb](ob)\n",
    "\n",
    "                    offsprings.__addIndividual__(ob)\n",
    "                    \n",
    "                    counter[tb] += 1\n",
    "                    # self.eval_k[tb] += 1\n",
    "                    \n",
    "            stopping = sum(counter >= sub_size) == len(self.tasks)\n",
    "\n",
    "        return offsprings\n",
    "\n",
    "    def phaseTwo(self, D0):\n",
    "        fcosts = [sub.getFitness() for sub in self.population]\n",
    "        # start = time.time()\n",
    "        D = self.calculateD(population = np.array([[ind.genes for ind in sub.ls_inds]for sub in self.population]), \n",
    "                            population_fitness = np.array(fcosts),\n",
    "                            best = np.array([sub.__getBestIndividual__.genes for sub in self.population]),\n",
    "                            )\n",
    "        # end = time.time()\n",
    "        # print(\"A: \", end - start)\n",
    "        maxFit = np.max(fcosts, axis=1)\n",
    "        minFit = np.min(fcosts, axis=1)\n",
    "        maxDelta = maxFit - minFit + 1e-99\n",
    "\n",
    "        assert len(D) == len(maxDelta), \"Wrong shape. Got {} and {}\".format(D.shape, maxDelta.shape)\n",
    "        assert len(D) == len(self.tasks), \"Got wrong shape\"\n",
    "\n",
    "        sigma = np.where(D > D0, 0, 1 - D/D0)\n",
    "        nextPop = Population(IndClass = self.IndClass,\n",
    "                            dim = self.dim_uss,\n",
    "                            nb_inds_tasks=[0] * len(self.tasks),\n",
    "                            list_tasks=self.tasks)\n",
    "        # start = time.time()\n",
    "        for i in range(len(self.tasks)):\n",
    "            self.eval_k[i] += self.learningPhase[i].evolve(self.population[i], nextPop, sigma[i], maxDelta[i])\n",
    "        # end = time.time()\n",
    "        # print(\"B: \", end - start)\n",
    "        self.population = nextPop\n",
    "\n",
    "    def calculateD(self, population: np.array, population_fitness: np.array, best: np.array) -> np.array:\n",
    "        '''\n",
    "        Arguments include:\\n\n",
    "        + `population`: genes of the current population\n",
    "        + `population_fitness`: fitness of the current population\n",
    "        + `best`: the best gene of each subpop\n",
    "        + `nb_tasks`: number of tasks\n",
    "        '''\n",
    "        \n",
    "        D = np.empty((len(self.tasks)))\n",
    "        for i in range(len(self.tasks)):\n",
    "            gene_max = [np.max(population[i], axis = 1).tolist()] * self.dim_uss\n",
    "            gene_min = [np.min(population[i], axis = 1).tolist()] * self.dim_uss\n",
    "\n",
    "            D[i] = self.__class__._calculateD(np.array(gene_max).T, np.array(gene_min).T, population[i], population_fitness[i], best[i], model.TOLERANCE)\n",
    "        return D\n",
    "    \n",
    "    @njit\n",
    "    def _calculateD(gene_max: np.array, gene_min: np.array, subPop: np.array, subPop_fitness: np.array, best: np.array, TOLERANCE: float) -> float:\n",
    "            # gene_max = gene_max.flatten()\n",
    "            # gene_max = np.broadcast_to(gene_max, (subPop.shape[-1], subPop.shape[0])).T\n",
    "            # gene_min = gene_min.flatten()\n",
    "            # gene_min = np.broadcast_to(gene_min, (subPop.shape[-1], subPop.shape[0])).T\n",
    "            \n",
    "            w = np.where(subPop_fitness > TOLERANCE, 1/(subPop_fitness), 1/TOLERANCE)\n",
    "            # w = [1/ind if ind > TOLERANCE else 1/TOLERANCE for ind in population[i]]\n",
    "            # print(subPop.shape)\n",
    "            sum_w = sum(w)\n",
    "            d = (subPop - gene_min)/(gene_max - gene_min)\n",
    "            best = (best - gene_min)/(gene_max - gene_min)\n",
    "            d = np.sum((d - best) ** 2, axis=1)\n",
    "            d = np.sqrt(d)\n",
    "            assert d.shape == w.shape\n",
    "            # d = np.sqrt(np.sum(d, axis=0))\n",
    "            # d = np.sum([np.sqrt(np.sum((d[i] - best) * (d[i] - best))) for i in range(len(subPop))])\n",
    "\n",
    "            return np.sum(w * d/sum_w)\n",
    "    \n",
    "    def updateRMP(self, c: int):\n",
    "        for i in range(len(self.tasks)):\n",
    "            for j in range(len(self.tasks)):\n",
    "                if i == j:\n",
    "                    continue\n",
    "                if len(self.delta[i][j]) > 0:\n",
    "                    self.rmp[i][j] += self.__class__._updateRMP(np.array(self.delta[i][j]), np.array(self.s_rmp[i][j]), c)\n",
    "                else:\n",
    "                    self.rmp[i][j] = (1 - c) * self.rmp[i][j]\n",
    "                \n",
    "                self.rmp[i][j] = max(0.1, min(1, self.rmp[i][j]))\n",
    "\n",
    "    @njit\n",
    "    def _updateRMP(delta: np.array, s_rmp: np.array, c: float) -> float:\n",
    "        sum_delta = sum(delta)\n",
    "        tmp = (delta/sum_delta) * s_rmp\n",
    "        meanS = sum(tmp * s_rmp)\n",
    "        \n",
    "        return c * meanS/sum(tmp)\n",
    "    \n",
    "class LearningPhase():\n",
    "    M = 2\n",
    "    H = 10\n",
    "    def __init__(self, IndClass, list_tasks, task) -> None:\n",
    "        self.IndClass = IndClass\n",
    "        self.list_tasks = list_tasks\n",
    "        self.task = task\n",
    "        self.sum_improv = [0.0] * LearningPhase.M\n",
    "        self.consume_fes = [1.0] * LearningPhase.M\n",
    "        self.mem_cr = [0.5] * LearningPhase.H\n",
    "        self.mem_f = [0.5] * LearningPhase.H\n",
    "        self.s_cr = []\n",
    "        self.s_f = []\n",
    "        self.diff_f = []\n",
    "        self.mem_pos = 0\n",
    "        self.gen = 0\n",
    "        self.best_opcode = 1\n",
    "        self.searcher = [self.pbest1, PolynomialMutation(nm = 5).getInforTasks(self.IndClass, self.list_tasks)]\n",
    "\n",
    "    def evolve(self, subPop: SubPopulation, nextPop: Population, sigma: float, max_delta: float) -> SubPopulation:\n",
    "        self.gen += 1\n",
    "\n",
    "        if self.gen > 1:\n",
    "            # start = time.time()\n",
    "            self.best_opcode = self.__class__.updateOperator(sum_improve = np.array(self.sum_improv), \n",
    "                                                             consume_fes = np.array(self.consume_fes), \n",
    "                                                             M = LearningPhase.M)\n",
    "\n",
    "            self.sum_improv = [0.0] * LearningPhase.M\n",
    "            self.consume_fes = [1.0] * LearningPhase.M\n",
    "\n",
    "            # end = time.time()\n",
    "            # print(\"C: \", end - start)\n",
    "\n",
    "        # self.updateMemory()\n",
    "        \n",
    "        pbest_size = max(5, int(0.15 * len(subPop)))\n",
    "        # pbest = subPop.__getRandomItems__(size = pbest_size)\n",
    "        idx_inds = numba_argsort([ind.fcost for ind in subPop.ls_inds])\n",
    "        pbest =  [subPop.ls_inds[i] for i in idx_inds[:pbest_size]] \n",
    "        # start1 = time.time()\n",
    "        for ind in subPop:\n",
    "            # start1 = time.time()\n",
    "            # start = time.time()\n",
    "            r = random.randint(0, LearningPhase.M - 1)\n",
    "            cr = numba_random_gauss(self.mem_cr[r], 0.1)\n",
    "            f = numba_random_cauchy(self.mem_f[r], 0.1)\n",
    "            opcode = random.randint(0, LearningPhase.M)\n",
    "            if opcode == LearningPhase.M:\n",
    "                opcode = self.best_opcode\n",
    "\n",
    "            self.consume_fes[opcode] += 1\n",
    "            # end = time.time()\n",
    "            # print(\"Opcode: \", end - start)\n",
    "            if opcode == 0:\n",
    "                # start = time.time()\n",
    "                child = self.searcher[opcode](ind, subPop, pbest, cr, f)\n",
    "                # end = time.time()\n",
    "                # print(\"gauss: \", end - start)\n",
    "            elif opcode == 1:\n",
    "                # start = time.time()\n",
    "                child = self.searcher[opcode](ind, return_newInd=True)\n",
    "                # end = time.time()\n",
    "                # print(\"pbest: \", end - start)\n",
    "\n",
    "            # start = time.time()\n",
    "            child.skill_factor = ind.skill_factor\n",
    "            child.fcost = self.task(child)\n",
    "            \n",
    "            diff = ind.fcost - child.fcost\n",
    "            if diff > 0:\n",
    "                survival = child\n",
    "\n",
    "                self.sum_improv[opcode] += diff\n",
    "\n",
    "                if opcode == 0:\n",
    "                    self.diff_f.append(diff)\n",
    "                    # self.s_cr.append(cr)\n",
    "                    # self.s_f.append(f)\n",
    "                \n",
    "            elif diff == 0 or random.random() <= sigma * np.exp(diff/max_delta):\n",
    "                survival = child\n",
    "            else:\n",
    "                survival = ind\n",
    "            \n",
    "            nextPop.__addIndividual__(survival)\n",
    "            # end = time.time()\n",
    "            # print(\"searcher add: \", end - start)\n",
    "        # end = time.time()\n",
    "        # print(\"F: \", end - start1)\n",
    "        return len(subPop)\n",
    "    \n",
    "    def pbest1(self, ind: Individual, subPop: SubPopulation, best: List[Individual], cr: float, f: float) -> Individual:\n",
    "        pbest = best[random.randint(0, len(best) - 1)]\n",
    "        \n",
    "        ind_ran1, ind_ran2 = subPop.__getRandomItems__(size = 2, replace= False)\n",
    "        \n",
    "        # u = (numba_random_uniform(len(ind.genes)) < cr)\n",
    "        # if np.sum(u) == 0:\n",
    "        #     u = np.zeros(shape= (subPop.dim,))\n",
    "        #     u[numba_randomchoice(subPop.dim)] = 1\n",
    "        # new_genes = np.where(u,\n",
    "        #     pbest.genes + f * (ind_ran1.genes - ind_ran2.genes),\n",
    "        #     ind.genes\n",
    "        # )\n",
    "        # new_genes = np.where(new_genes > 1, (ind.genes + 1)/2, new_genes) \n",
    "        # new_genes = np.where(new_genes < 0, (ind.genes + 0)/2, new_genes)\n",
    "\n",
    "        new_genes = self.__class__.produce_inds(ind.genes, pbest.genes, ind_ran1.genes, ind_ran2.genes, subPop.dim, f, cr)\n",
    "        new_ind = self.IndClass(new_genes)\n",
    "\n",
    "        return new_ind\n",
    "\n",
    "    @njit\n",
    "    def produce_inds(ind_genes: np.array, \n",
    "                     best_genes: np.array, \n",
    "                     ind1_genes: np.array, \n",
    "                     ind2_genes: np.array,\n",
    "                     dim: int,\n",
    "                     F: float, \n",
    "                     cr: float) -> np.array:\n",
    "        \n",
    "        u = (np.random.rand(len(ind_genes)) < cr)\n",
    "        u = np.array([1.0 if v == True else 0.0 for v in u])\n",
    "        if np.sum(u) == 0:\n",
    "            u = np.zeros(shape= (dim,))\n",
    "            u[np.random.choice(dim)] = 1\n",
    "\n",
    "        new_genes = np.where(u,\n",
    "            best_genes + F * (ind1_genes - ind2_genes),\n",
    "            ind_genes\n",
    "        )\n",
    "        new_genes = np.where(new_genes > 1, (ind_genes + 1)/2, new_genes) \n",
    "        new_genes = np.where(new_genes < 0, (ind_genes + 0)/2, new_genes)\n",
    "\n",
    "        return new_genes\n",
    "\n",
    "    # def updateMemory(self):\n",
    "    #     if len(self.s_cr) > 0:\n",
    "    #         # self.diff_f = np.array(self.diff_f)\n",
    "    #         # self.s_cr = np.array(self.s_cr)\n",
    "    #         # self.s_f = np.array(self.s_f)\n",
    "\n",
    "    #         self.mem_cr[self.mem_pos] = self.__class__.updateMemoryCR(self.diff_f, self.s_cr)\n",
    "    #         self.mem_f[self.mem_pos] = self.__class__.updateMemoryF(self.diff_f, self.s_f)\n",
    "            \n",
    "    #         self.mem_pos = (self.mem_pos + 1) % LearningPhase.H\n",
    "\n",
    "    #         self.s_cr = []\n",
    "    #         self.s_f = []\n",
    "    #         self.diff_f = []\n",
    "\n",
    "    # @jit(nopython = True, parallel = True, cache=True)\n",
    "    # def updateMemoryCR(diff_f: List, s_cr: List) -> float:\n",
    "    #     diff_f = np.array(diff_f)\n",
    "    #     s_cr = np.array(s_cr)\n",
    "\n",
    "    #     sum_diff = sum(diff_f)\n",
    "    #     weight = diff_f/sum_diff\n",
    "    #     tmp_sum_cr = sum(weight * s_cr)\n",
    "    #     mem_cr = sum(weight * s_cr * s_cr)\n",
    "        \n",
    "    #     if tmp_sum_cr == 0 or mem_cr == -1:\n",
    "    #         return -1\n",
    "    #     else:\n",
    "    #         return mem_cr/tmp_sum_cr\n",
    "        \n",
    "    # @jit(nopython = True, parallel = True, cache = True)\n",
    "    # def updateMemoryF(diff_f: List, s_f: List) -> float:\n",
    "    #     diff_f = np.array(diff_f)\n",
    "    #     s_f = np.array(s_f)\n",
    "\n",
    "    #     sum_diff = sum(diff_f)\n",
    "    #     weight = diff_f/sum_diff\n",
    "    #     tmp_sum_f = sum(weight * s_f)\n",
    "    #     return sum(weight * (s_f ** 2)) / tmp_sum_f\n",
    "\n",
    "    @njit\n",
    "    def updateOperator(sum_improve: np.array, consume_fes: np.array, M: int) -> int:\n",
    "        # sum_improve = np.array(sum_improve)\n",
    "        # consume_fes = np.array(consume_fes)\n",
    "        eta = sum_improve / consume_fes\n",
    "        best_rate = max(eta)\n",
    "        best_op = np.argmax(eta)\n",
    "        if best_rate > 0:\n",
    "            return best_op\n",
    "        else:\n",
    "            return random.randint(0, M - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from numba import jit, njit\n",
    "from numba import typed\n",
    "from numba.core import types\n",
    "from typing import Dict\n",
    "\n",
    "from pyMSOO.MFEA.model import AbstractModel\n",
    "from pyMSOO.utils import Crossover, Mutation, Selection, DimensionAwareStrategy\n",
    "from pyMSOO.utils.EA import *\n",
    "from pyMSOO.utils.numba_utils import numba_randomchoice, numba_random_gauss, numba_random_cauchy, numba_argsort\n",
    "from pyMSOO.utils.Search import *\n",
    "\n",
    "class model(AbstractModel.model):\n",
    "    TOLERANCE = 1e-6\n",
    "    INF = 1e8\n",
    "    def compile(self, \n",
    "        IndClass: Type[Individual],\n",
    "        tasks: List[AbstractTask], \n",
    "        crossover: Crossover.SBX_Crossover, \n",
    "        mutation: Mutation.PolynomialMutation, \n",
    "        selection: Selection.ElitismSelection,\n",
    "        dimension_strategy: DimensionAwareStrategy.AbstractDaS = DimensionAwareStrategy.NoDaS(),\n",
    "        *args, **kwargs):\n",
    "        super().compile(IndClass, tasks, crossover, mutation,dimension_strategy, selection, *args, **kwargs)\n",
    "    \n",
    "    def fit(self, nb_generations, \n",
    "            nb_inds_each_task = 100, \n",
    "            nb_inds_max = 100,\n",
    "            nb_inds_min = 20,\n",
    "            evaluate_initial_skillFactor = True, \n",
    "            c = 0.06,\n",
    "            *args, \n",
    "            **kwargs) -> List[Individual]:\n",
    "        super().fit(*args, **kwargs)\n",
    "\n",
    "        # nb_inds_min\n",
    "        if nb_inds_min is not None:\n",
    "            assert nb_inds_each_task >= nb_inds_min\n",
    "        else: \n",
    "            nb_inds_min = nb_inds_each_task\n",
    "\n",
    "        self.rmp = np.full((len(self.tasks), len(self.tasks)), 0.3)\n",
    "        self.learningPhase = [LearningPhase(self.IndClass, self.tasks, t) for t in self.tasks]\n",
    "        \n",
    "        # initialize population\n",
    "        self.population = Population(\n",
    "            self.IndClass,\n",
    "            nb_inds_tasks = [nb_inds_each_task] * len(self.tasks), \n",
    "            dim = self.dim_uss,\n",
    "            list_tasks= self.tasks,\n",
    "            evaluate_initial_skillFactor = evaluate_initial_skillFactor\n",
    "        )\n",
    "\n",
    "        self.nb_inds_tasks = [nb_inds_each_task] * len(self.tasks)\n",
    "\n",
    "        MAXEVALS = nb_generations * nb_inds_each_task * len(self.tasks)\n",
    "        self.max_eval_k = [nb_generations * nb_inds_each_task] * len(self.tasks)\n",
    "        self.eval_k = [0] * len(self.tasks)\n",
    "        epoch = 1\n",
    "        \n",
    "        D0 = self.calculateD(population = np.array([[ind.genes for ind in sub.ls_inds] for sub in self.population]), \n",
    "                            population_fitness = np.array([sub.getFitness() for sub in self.population]),\n",
    "                            best = np.array([sub.__getBestIndividual__.genes for sub in self.population]),)\n",
    "\n",
    "        while sum(self.eval_k) < MAXEVALS:\n",
    "            self.delta = [[[] for _ in range(len(self.tasks))] for _ in range(len(self.tasks))]\n",
    "\n",
    "            self.s_rmp = [[[] for _ in range(len(self.tasks))] for _ in range(len(self.tasks))]\n",
    "\n",
    "            self.population.update_rank()\n",
    "            # print(self.eval_k)\n",
    "            if sum(self.eval_k) >= epoch * nb_inds_each_task * len(self.tasks):\n",
    "                # save history\n",
    "                self.history_cost.append([ind.fcost for ind in self.population.get_solves()])\n",
    "                self.render_process(epoch/nb_generations, ['Pop_size', 'Cost'], [[sum(self.nb_inds_tasks)], self.history_cost[-1]], use_sys= True)\n",
    "                epoch += 1\n",
    "\n",
    "            # offsprings = self.reproduction(sum(self.nb_inds_tasks), self.population)\n",
    "\n",
    "            # self.population = self.population + offsprings\n",
    "            # start = time.time()\n",
    "            # matingPool = Population(\n",
    "            #     self.IndClass,\n",
    "            #     nb_inds_tasks = [0] * len(self.tasks), \n",
    "            #     dim = self.dim_uss,\n",
    "            #     list_tasks= self.tasks,\n",
    "            #     evaluate_initial_skillFactor = False\n",
    "            # )\n",
    "\n",
    "            # for idx in range(len(self.tasks)):\n",
    "                \n",
    "            #     idx_inds = numba_argsort([ind.fcost for ind in self.population[idx].ls_inds])\n",
    "                \n",
    "            #     for i in idx_inds[:int(len(self.population[idx])/2)]:\n",
    "            #         matingPool.__addIndividual__(self.population[idx].ls_inds[i])\n",
    "\n",
    "            self.selection(self.population, [int(x/2) for x in self.nb_inds_tasks])\n",
    "\n",
    "            offsprings = self.reproduction(sum(self.nb_inds_tasks), self.population)\n",
    "        \n",
    "            # # merge and update rank\n",
    "            self.population = self.population + offsprings\n",
    "            self.population.update_rank()\n",
    "            # end = time.time()\n",
    "            # print(\"E: \", end - start)\n",
    "            # selection\n",
    "            self.nb_inds_tasks = [int(\n",
    "                int(max((nb_inds_min - nb_inds_max) * (sum(self.eval_k)/MAXEVALS) + nb_inds_max, nb_inds_min))\n",
    "            )] * len(self.tasks)\n",
    "            self.selection(self.population, self.nb_inds_tasks)\n",
    "\n",
    "            # update operators\n",
    "            self.crossover.update(population = self.population)\n",
    "            self.mutation.update(population = self.population)\n",
    "            self.dimension_strategy.update(population = self.population)\n",
    "            # start = time.time()\n",
    "            # self.updateRMP(c)\n",
    "            # self.rmp = self.__class__.updateRMP(np.array(self.rmp), np.array(self.delta), np.array(self.s_rmp), c, len(self.tasks))\n",
    "            # end = time.time()\n",
    "            # print(\"G: \", end - start)\n",
    "            # start = time.time()\n",
    "            self.phaseTwo(D0)\n",
    "            # end = time.time()\n",
    "            # print(\"Phase two: \", end - start)\n",
    "        # self.phaseTwo(D0)\n",
    "        print('\\nEND!')\n",
    "\n",
    "        #solve \n",
    "        self.render_process(epoch/nb_generations, ['Pop_size', 'Cost'], [[sum(self.nb_inds_tasks)], self.history_cost[-1]], use_sys= True)\n",
    "        self.population.update_rank()\n",
    "        self.last_pop = self.population\n",
    "        return self.last_pop.get_solves()\n",
    "    \n",
    "    def reproduction(self, size: int, mating_pool: Population,) -> Population:\n",
    "        sub_size = int(size/len(self.tasks))\n",
    "       \n",
    "        offsprings = Population(self.IndClass,\n",
    "                                nb_inds_tasks = [0] * len(self.tasks), \n",
    "                                dim = self.dim_uss,\n",
    "                                list_tasks= self.tasks)\n",
    "        counter = np.zeros((len(self.tasks)))  \n",
    "\n",
    "        stopping = False\n",
    "        while not stopping:\n",
    "            pa, pb = mating_pool.__getRandomInds__(2)\n",
    "            ta = pa.skill_factor\n",
    "            tb = pb.skill_factor\n",
    "\n",
    "            if counter[ta] >= sub_size and counter[tb] >= sub_size:\n",
    "                continue\n",
    "\n",
    "            rmpValue = numba_random_gauss(mean = max(self.rmp[ta][tb], self.rmp[tb][ta]), sigma = 0.1)\n",
    "\n",
    "            if ta == tb:\n",
    "                # self.eval_k[ta] += 2\n",
    "\n",
    "                oa, ob = self.crossover(pa, pb)\n",
    "\n",
    "                oa.skill_factor = ta\n",
    "                ob.skill_factor = ta\n",
    "\n",
    "                if self.eval_k[ta] >= self.max_eval_k[ta]:\n",
    "                    oa.fcost = model.INF\n",
    "                else:\n",
    "                    self.eval_k[ta] += 1\n",
    "\n",
    "                offsprings.__addIndividual__(oa)\n",
    "\n",
    "                if self.eval_k[tb] >= self.max_eval_k[tb]:\n",
    "                    ob.fcost = model.INF\n",
    "                else:\n",
    "                    self.eval_k[tb] += 1\n",
    "\n",
    "                offsprings.__addIndividual__(ob)\n",
    "\n",
    "                counter[ta] += 2\n",
    "\n",
    "            elif random.random() <= rmpValue:\n",
    "                off = self.crossover(pa, pb)\n",
    "\n",
    "                for o in off:\n",
    "                    if counter[ta] < sub_size and random.random() < self.rmp[ta][tb]/(self.rmp[ta][tb] + self.rmp[tb][ta]):\n",
    "                        o.skill_factor = ta\n",
    "                        o = self.dimension_strategy(o, tb, pa)\n",
    "                        if self.eval_k[ta] >= self.max_eval_k[ta]:\n",
    "                            o.fcost = model.INF\n",
    "                        else:\n",
    "                            self.eval_k[ta] += 1\n",
    "                            o.fcost = self.tasks[ta](o)\n",
    "\n",
    "                        offsprings.__addIndividual__(o)\n",
    "                        \n",
    "                        counter[ta] += 1\n",
    "                        # self.eval_k[ta] += 1\n",
    "                        \n",
    "                        if pa.fcost > o.fcost:\n",
    "                            self.delta[ta][tb].append(pa.fcost - o.fcost)\n",
    "                            self.s_rmp[ta][tb].append(rmpValue)\n",
    "                    \n",
    "                    elif counter[tb] < sub_size:\n",
    "                        o.skill_factor = tb\n",
    "                        o = self.dimension_strategy(o, ta, pb)\n",
    "        \n",
    "                        if self.eval_k[tb] >= self.max_eval_k[tb]:\n",
    "                            o.fcost = model.INF\n",
    "                        else:\n",
    "                            self.eval_k[tb] += 1\n",
    "                            o.fcost = self.tasks[tb](o)\n",
    "\n",
    "                        offsprings.__addIndividual__(o)\n",
    "                        \n",
    "                        counter[tb] += 1\n",
    "                        # self.eval_k[tb] += 1\n",
    "\n",
    "                        if pb.fcost > o.fcost:\n",
    "                            self.delta[tb][ta].append(pb.fcost - o.fcost)\n",
    "                            self.s_rmp[tb][ta].append(rmpValue)\n",
    "\n",
    "            else:\n",
    "                if counter[ta] < sub_size:\n",
    "                    paa: Individual = self.population[ta].__getRandomItems__()\n",
    "\n",
    "                    # while np.array_equal(paa.genes, pa.genes):\n",
    "                    #     paa: Individual = self.population[ta].__getRandomItems__()\n",
    "                    \n",
    "                    oa, _ = self.crossover(pa, paa)\n",
    "                    oa.skill_factor = ta\n",
    "                    \n",
    "                    if self.eval_k[ta] >= self.max_eval_k[ta]:\n",
    "                        oa.fcost = model.INF\n",
    "                    else:\n",
    "                        self.eval_k[ta] += 1\n",
    "                        oa.fcost = self.tasks[ta](oa)\n",
    "\n",
    "                    offsprings.__addIndividual__(oa)\n",
    "\n",
    "                    counter[ta] += 1\n",
    "                    # self.eval_k[ta] += 1\n",
    "\n",
    "                if counter[tb] < sub_size:\n",
    "                    pbb: Individual = self.population[tb].__getRandomItems__()\n",
    "                    \n",
    "                    ob, _ = self.crossover(pb, pbb)\n",
    "                    ob.skill_factor = tb\n",
    "\n",
    "                    if self.eval_k[tb] >= self.max_eval_k[tb]:\n",
    "                        ob.fcost = model.INF\n",
    "                    else:\n",
    "                        self.eval_k[tb] += 1\n",
    "                        ob.fcost = self.tasks[tb](ob)\n",
    "\n",
    "                    offsprings.__addIndividual__(ob)\n",
    "                    \n",
    "                    counter[tb] += 1\n",
    "                    # self.eval_k[tb] += 1\n",
    "                    \n",
    "            stopping = sum(counter >= sub_size) == len(self.tasks)\n",
    "\n",
    "        return offsprings\n",
    "\n",
    "    def phaseTwo(self, D0):\n",
    "        fcosts = [sub.getFitness() for sub in self.population]\n",
    "        # start = time.time()\n",
    "        D = self.calculateD(population = np.array([[ind.genes for ind in sub.ls_inds]for sub in self.population]), \n",
    "                            population_fitness = np.array(fcosts),\n",
    "                            best = np.array([sub.__getBestIndividual__.genes for sub in self.population]),\n",
    "                            )\n",
    "        # end = time.time()\n",
    "        # print(\"A: \", end - start)\n",
    "        maxFit = np.max(fcosts, axis=1)\n",
    "        minFit = np.min(fcosts, axis=1)\n",
    "        maxDelta = maxFit - minFit + 1e-99\n",
    "\n",
    "        assert len(D) == len(maxDelta), \"Wrong shape. Got {} and {}\".format(D.shape, maxDelta.shape)\n",
    "        assert len(D) == len(self.tasks), \"Got wrong shape\"\n",
    "\n",
    "        sigma = np.where(D > D0, 0, 1 - D/D0)\n",
    "        nextPop = Population(IndClass = self.IndClass,\n",
    "                            dim = self.dim_uss,\n",
    "                            nb_inds_tasks=[0] * len(self.tasks),\n",
    "                            list_tasks=self.tasks)\n",
    "        # start = time.time()\n",
    "        for i in range(len(self.tasks)):\n",
    "            self.eval_k[i] += self.learningPhase[i].evolve(self.population[i], nextPop, sigma[i], maxDelta[i])\n",
    "        # end = time.time()\n",
    "        # print(\"B: \", end - start)\n",
    "        self.population = nextPop\n",
    "\n",
    "    def calculateD(self, population: np.array, population_fitness: np.array, best: np.array) -> np.array:\n",
    "        '''\n",
    "        Arguments include:\\n\n",
    "        + `population`: genes of the current population\n",
    "        + `population_fitness`: fitness of the current population\n",
    "        + `best`: the best gene of each subpop\n",
    "        + `nb_tasks`: number of tasks\n",
    "        '''\n",
    "        \n",
    "        D = np.empty((len(self.tasks)))\n",
    "        for i in range(len(self.tasks)):\n",
    "            gene_max = [np.max(population[i], axis = 1).tolist()] * self.dim_uss\n",
    "            gene_min = [np.min(population[i], axis = 1).tolist()] * self.dim_uss\n",
    "\n",
    "            D[i] = self.__class__._calculateD(np.array(gene_max).T, np.array(gene_min).T, population[i], population_fitness[i], best[i], model.TOLERANCE)\n",
    "        return D\n",
    "    \n",
    "    @njit\n",
    "    def _calculateD(gene_max: np.array, gene_min: np.array, subPop: np.array, subPop_fitness: np.array, best: np.array, TOLERANCE: float) -> float:\n",
    "            # gene_max = gene_max.flatten()\n",
    "            # gene_max = np.broadcast_to(gene_max, (subPop.shape[-1], subPop.shape[0])).T\n",
    "            # gene_min = gene_min.flatten()\n",
    "            # gene_min = np.broadcast_to(gene_min, (subPop.shape[-1], subPop.shape[0])).T\n",
    "            \n",
    "            w = np.where(subPop_fitness > TOLERANCE, 1/(subPop_fitness), 1/TOLERANCE)\n",
    "            # w = [1/ind if ind > TOLERANCE else 1/TOLERANCE for ind in population[i]]\n",
    "            # print(subPop.shape)\n",
    "            sum_w = sum(w)\n",
    "            d = (subPop - gene_min)/(gene_max - gene_min)\n",
    "            best = (best - gene_min)/(gene_max - gene_min)\n",
    "            d = np.sum((d - best) ** 2, axis=1)\n",
    "            d = np.sqrt(d)\n",
    "            assert d.shape == w.shape\n",
    "            # d = np.sqrt(np.sum(d, axis=0))\n",
    "            # d = np.sum([np.sqrt(np.sum((d[i] - best) * (d[i] - best))) for i in range(len(subPop))])\n",
    "\n",
    "            return np.sum(w * d/sum_w)\n",
    "\n",
    "    @njit\n",
    "    def updateRMP(rmp: np.array, delta: np.array, s_rmp: np.array, c: int, len_tasks):\n",
    "        def _updateRMP(delta: np.array, s_rmp: np.array, c: float) -> float:\n",
    "            sum_delta = sum(delta)\n",
    "            tmp = (delta/sum_delta) * s_rmp\n",
    "            meanS = sum(tmp * s_rmp)\n",
    "            \n",
    "            return c * meanS/sum(tmp)\n",
    "        \n",
    "\n",
    "        for i in range(len_tasks):\n",
    "            for j in range(len_tasks):\n",
    "                if i == j:\n",
    "                    continue\n",
    "                if len(delta[i][j]) > 0:\n",
    "                    rmp[i][j] += _updateRMP(delta[i][j], s_rmp[i][j], c)\n",
    "                else:\n",
    "                    rmp[i][j] = (1 - c) * rmp[i][j]\n",
    "\n",
    "                rmp[i][j] = max(0.1, min(1, rmp[i][j]))\n",
    "        \n",
    "        return rmp\n",
    "\n",
    "    \n",
    "    # def updateRMP(self, c: int):\n",
    "    #     for i in range(len(self.tasks)):\n",
    "    #         for j in range(len(self.tasks)):\n",
    "    #             if i == j:\n",
    "    #                 continue\n",
    "    #             if len(self.delta[i][j]) > 0:\n",
    "    #                 self.rmp[i][j] += self.__class__._updateRMP(np.array(self.delta[i][j]), np.array(self.s_rmp[i][j]), c)\n",
    "    #             else:\n",
    "    #                 self.rmp[i][j] = (1 - c) * self.rmp[i][j]\n",
    "                \n",
    "    #             self.rmp[i][j] = max(0.1, min(1, self.rmp[i][j]))\n",
    "\n",
    "    # @njit\n",
    "    # def _updateRMP(delta: np.array, s_rmp: np.array, c: float) -> float:\n",
    "    #     sum_delta = sum(delta)\n",
    "    #     tmp = (delta/sum_delta) * s_rmp\n",
    "    #     meanS = sum(tmp * s_rmp)\n",
    "        \n",
    "    #     return c * meanS/sum(tmp)\n",
    "    \n",
    "class LearningPhase():\n",
    "    M = 2\n",
    "    H = 10\n",
    "    def __init__(self, IndClass, list_tasks, task) -> None:\n",
    "        self.IndClass = IndClass\n",
    "        self.list_tasks = list_tasks\n",
    "        self.task = task\n",
    "        self.sum_improv = [0.0] * LearningPhase.M\n",
    "        self.consume_fes = [1.0] * LearningPhase.M\n",
    "        self.mem_cr = [0.5] * LearningPhase.H\n",
    "        self.mem_f = [0.5] * LearningPhase.H\n",
    "        self.s_cr = []\n",
    "        self.s_f = []\n",
    "        self.diff_f = []\n",
    "        self.mem_pos = 0\n",
    "        self.gen = 0\n",
    "        self.best_opcode = 1\n",
    "        self.searcher = [self.pbest1, PolynomialMutation(nm = 5).getInforTasks(self.IndClass, self.list_tasks)]\n",
    "\n",
    "    def evolve(self, subPop: SubPopulation, nextPop: Population, sigma: float, max_delta: float) -> SubPopulation:\n",
    "        self.gen += 1\n",
    "\n",
    "        if self.gen > 1:\n",
    "            # start = time.time()\n",
    "            self.best_opcode = self.__class__.updateOperator(sum_improve = np.array(self.sum_improv), \n",
    "                                                             consume_fes = np.array(self.consume_fes), \n",
    "                                                             M = LearningPhase.M)\n",
    "\n",
    "            self.sum_improv = [0.0] * LearningPhase.M\n",
    "            self.consume_fes = [1.0] * LearningPhase.M\n",
    "\n",
    "            # end = time.time()\n",
    "            # print(\"C: \", end - start)\n",
    "\n",
    "        # self.updateMemory()\n",
    "        \n",
    "        pbest_size = max(5, int(0.15 * len(subPop)))\n",
    "        # pbest = subPop.__getRandomItems__(size = pbest_size)\n",
    "        idx_inds = numba_argsort([ind.fcost for ind in subPop.ls_inds])\n",
    "        pbest =  [subPop.ls_inds[i] for i in idx_inds[:pbest_size]] \n",
    "        # start1 = time.time()\n",
    "        for ind in subPop:\n",
    "            # start1 = time.time()\n",
    "            # start = time.time()\n",
    "            r = random.randint(0, LearningPhase.M - 1)\n",
    "            cr = numba_random_gauss(self.mem_cr[r], 0.1)\n",
    "            f = numba_random_cauchy(self.mem_f[r], 0.1)\n",
    "            opcode = random.randint(0, LearningPhase.M)\n",
    "            if opcode == LearningPhase.M:\n",
    "                opcode = self.best_opcode\n",
    "\n",
    "            self.consume_fes[opcode] += 1\n",
    "            # end = time.time()\n",
    "            # print(\"Opcode: \", end - start)\n",
    "            if opcode == 0:\n",
    "                # start = time.time()\n",
    "                child = self.searcher[opcode](ind, subPop, pbest, cr, f)\n",
    "                # end = time.time()\n",
    "                # print(\"gauss: \", end - start)\n",
    "            elif opcode == 1:\n",
    "                # start = time.time()\n",
    "                child = self.searcher[opcode](ind, return_newInd=True)\n",
    "                # end = time.time()\n",
    "                # print(\"pbest: \", end - start)\n",
    "\n",
    "            # start = time.time()\n",
    "            child.skill_factor = ind.skill_factor\n",
    "            child.fcost = self.task(child)\n",
    "            \n",
    "            diff = ind.fcost - child.fcost\n",
    "            if diff > 0:\n",
    "                survival = child\n",
    "\n",
    "                self.sum_improv[opcode] += diff\n",
    "\n",
    "                if opcode == 0:\n",
    "                    self.diff_f.append(diff)\n",
    "                    # self.s_cr.append(cr)\n",
    "                    # self.s_f.append(f)\n",
    "                \n",
    "            elif diff == 0 or random.random() <= sigma * np.exp(diff/max_delta):\n",
    "                survival = child\n",
    "            else:\n",
    "                survival = ind\n",
    "            \n",
    "            nextPop.__addIndividual__(survival)\n",
    "            # end = time.time()\n",
    "            # print(\"searcher add: \", end - start)\n",
    "        # end = time.time()\n",
    "        # print(\"F: \", end - start1)\n",
    "        return len(subPop)\n",
    "    \n",
    "    def pbest1(self, ind: Individual, subPop: SubPopulation, best: List[Individual], cr: float, f: float) -> Individual:\n",
    "        pbest = best[random.randint(0, len(best) - 1)]\n",
    "        \n",
    "        ind_ran1, ind_ran2 = subPop.__getRandomItems__(size = 2, replace= False)\n",
    "        \n",
    "        # u = (numba_random_uniform(len(ind.genes)) < cr)\n",
    "        # if np.sum(u) == 0:\n",
    "        #     u = np.zeros(shape= (subPop.dim,))\n",
    "        #     u[numba_randomchoice(subPop.dim)] = 1\n",
    "        # new_genes = np.where(u,\n",
    "        #     pbest.genes + f * (ind_ran1.genes - ind_ran2.genes),\n",
    "        #     ind.genes\n",
    "        # )\n",
    "        # new_genes = np.where(new_genes > 1, (ind.genes + 1)/2, new_genes) \n",
    "        # new_genes = np.where(new_genes < 0, (ind.genes + 0)/2, new_genes)\n",
    "\n",
    "        new_genes = self.__class__.produce_inds(ind.genes, pbest.genes, ind_ran1.genes, ind_ran2.genes, subPop.dim, f, cr)\n",
    "        new_ind = self.IndClass(new_genes)\n",
    "\n",
    "        return new_ind\n",
    "\n",
    "    @njit\n",
    "    def produce_inds(ind_genes: np.array, \n",
    "                     best_genes: np.array, \n",
    "                     ind1_genes: np.array, \n",
    "                     ind2_genes: np.array,\n",
    "                     dim: int,\n",
    "                     F: float, \n",
    "                     cr: float) -> np.array:\n",
    "        \n",
    "        u = (np.random.rand(len(ind_genes)) < cr)\n",
    "        u = np.array([1.0 if v == True else 0.0 for v in u])\n",
    "        if np.sum(u) == 0:\n",
    "            u = np.zeros(shape= (dim,))\n",
    "            u[np.random.choice(dim)] = 1\n",
    "\n",
    "        new_genes = np.where(u,\n",
    "            best_genes + F * (ind1_genes - ind2_genes),\n",
    "            ind_genes\n",
    "        )\n",
    "        new_genes = np.where(new_genes > 1, (ind_genes + 1)/2, new_genes) \n",
    "        new_genes = np.where(new_genes < 0, (ind_genes + 0)/2, new_genes)\n",
    "\n",
    "        return new_genes\n",
    "\n",
    "    # def updateMemory(self):\n",
    "    #     if len(self.s_cr) > 0:\n",
    "    #         # self.diff_f = np.array(self.diff_f)\n",
    "    #         # self.s_cr = np.array(self.s_cr)\n",
    "    #         # self.s_f = np.array(self.s_f)\n",
    "\n",
    "    #         self.mem_cr[self.mem_pos] = self.__class__.updateMemoryCR(self.diff_f, self.s_cr)\n",
    "    #         self.mem_f[self.mem_pos] = self.__class__.updateMemoryF(self.diff_f, self.s_f)\n",
    "            \n",
    "    #         self.mem_pos = (self.mem_pos + 1) % LearningPhase.H\n",
    "\n",
    "    #         self.s_cr = []\n",
    "    #         self.s_f = []\n",
    "    #         self.diff_f = []\n",
    "\n",
    "    # @jit(nopython = True, parallel = True, cache=True)\n",
    "    # def updateMemoryCR(diff_f: List, s_cr: List) -> float:\n",
    "    #     diff_f = np.array(diff_f)\n",
    "    #     s_cr = np.array(s_cr)\n",
    "\n",
    "    #     sum_diff = sum(diff_f)\n",
    "    #     weight = diff_f/sum_diff\n",
    "    #     tmp_sum_cr = sum(weight * s_cr)\n",
    "    #     mem_cr = sum(weight * s_cr * s_cr)\n",
    "        \n",
    "    #     if tmp_sum_cr == 0 or mem_cr == -1:\n",
    "    #         return -1\n",
    "    #     else:\n",
    "    #         return mem_cr/tmp_sum_cr\n",
    "        \n",
    "    # @jit(nopython = True, parallel = True, cache = True)\n",
    "    # def updateMemoryF(diff_f: List, s_f: List) -> float:\n",
    "    #     diff_f = np.array(diff_f)\n",
    "    #     s_f = np.array(s_f)\n",
    "\n",
    "    #     sum_diff = sum(diff_f)\n",
    "    #     weight = diff_f/sum_diff\n",
    "    #     tmp_sum_f = sum(weight * s_f)\n",
    "    #     return sum(weight * (s_f ** 2)) / tmp_sum_f\n",
    "\n",
    "    @njit\n",
    "    def updateOperator(sum_improve: np.array, consume_fes: np.array, M: int) -> int:\n",
    "        # sum_improve = np.array(sum_improve)\n",
    "        # consume_fes = np.array(consume_fes)\n",
    "        eta = sum_improve / consume_fes\n",
    "        best_rate = max(eta)\n",
    "        best_op = np.argmax(eta)\n",
    "        if best_rate > 0:\n",
    "            return best_op\n",
    "        else:\n",
    "            return random.randint(0, M - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking...\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Acer\\AppData\\Local\\Temp\\ipykernel_9744\\2184204337.py:119: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  self.rmp = self.__class__.updateRMP(np.array(self.rmp), np.array(self.delta), np.array(self.s_rmp), c, len(self.tasks))\n"
     ]
    },
    {
     "ename": "TypingError",
     "evalue": "Failed in nopython mode pipeline (step: nopython frontend)\n\u001b[1m\u001b[1mnon-precise type array(pyobject, 2d, C)\u001b[0m\n\u001b[0m\u001b[1mDuring: typing of argument at C:\\Users\\Acer\\AppData\\Local\\Temp\\ipykernel_9744\\2184204337.py (328)\u001b[0m\n\u001b[1m\nFile \"C:\\Users\\Acer\\AppData\\Local\\Temp\\ipykernel_9744\\2184204337.py\", line 328:\u001b[0m\n\u001b[1m    def _calculateD(gene_max: np.array, gene_min: np.array, subPop: np.array, subPop_fitness: np.array, best: np.array, TOLERANCE: float) -> float:\n        <source elided>\n\n\u001b[1m    @njit\n\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypingError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 13\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39m# from pyMSOO.MFEA.model import EME_BI\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m# baseModel = EME_BI.model()\u001b[39;00m\n\u001b[0;32m      4\u001b[0m baseModel\u001b[39m.\u001b[39mcompile(\n\u001b[0;32m      5\u001b[0m     IndClass\u001b[39m=\u001b[39m IndClass,\n\u001b[0;32m      6\u001b[0m     tasks\u001b[39m=\u001b[39m tasks,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[39m# dimension_strategy= DimensionAwareStrategy.DaS_strategy()\u001b[39;00m\n\u001b[0;32m     12\u001b[0m )\n\u001b[1;32m---> 13\u001b[0m solve \u001b[39m=\u001b[39m baseModel\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m     14\u001b[0m     nb_generations \u001b[39m=\u001b[39;49m \u001b[39m1000\u001b[39;49m, nb_inds_each_task\u001b[39m=\u001b[39;49m \u001b[39m100\u001b[39;49m, \n\u001b[0;32m     15\u001b[0m     bound_pop\u001b[39m=\u001b[39;49m [\u001b[39m0\u001b[39;49m, \u001b[39m1\u001b[39;49m], evaluate_initial_skillFactor\u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m\n\u001b[0;32m     16\u001b[0m )\n",
      "Cell \u001b[1;32mIn[18], line 119\u001b[0m, in \u001b[0;36mmodel.fit\u001b[1;34m(self, nb_generations, nb_inds_each_task, nb_inds_max, nb_inds_min, evaluate_initial_skillFactor, c, *args, **kwargs)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdimension_strategy\u001b[39m.\u001b[39mupdate(population \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpopulation)\n\u001b[0;32m    117\u001b[0m \u001b[39m# start = time.time()\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \u001b[39m# self.updateRMP(c)\u001b[39;00m\n\u001b[1;32m--> 119\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrmp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__class__\u001b[39;49m\u001b[39m.\u001b[39;49mupdateRMP(np\u001b[39m.\u001b[39;49marray(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrmp), np\u001b[39m.\u001b[39;49marray(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdelta), np\u001b[39m.\u001b[39;49marray(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49ms_rmp), c, \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtasks))\n\u001b[0;32m    120\u001b[0m \u001b[39m# end = time.time()\u001b[39;00m\n\u001b[0;32m    121\u001b[0m \u001b[39m# print(\"G: \", end - start)\u001b[39;00m\n\u001b[0;32m    122\u001b[0m \u001b[39m# start = time.time()\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mphaseTwo(D0)\n",
      "File \u001b[1;32mf:\\Anaconda\\Anaconda\\envs\\MFEA\\lib\\site-packages\\numba\\core\\dispatcher.py:468\u001b[0m, in \u001b[0;36m_DispatcherBase._compile_for_args\u001b[1;34m(self, *args, **kws)\u001b[0m\n\u001b[0;32m    464\u001b[0m         msg \u001b[39m=\u001b[39m (\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mstr\u001b[39m(e)\u001b[39m.\u001b[39mrstrip()\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mThis error may have been caused \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    465\u001b[0m                \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mby the following argument(s):\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00margs_str\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    466\u001b[0m         e\u001b[39m.\u001b[39mpatch_message(msg)\n\u001b[1;32m--> 468\u001b[0m     error_rewrite(e, \u001b[39m'\u001b[39;49m\u001b[39mtyping\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m    469\u001b[0m \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mUnsupportedError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    470\u001b[0m     \u001b[39m# Something unsupported is present in the user code, add help info\u001b[39;00m\n\u001b[0;32m    471\u001b[0m     error_rewrite(e, \u001b[39m'\u001b[39m\u001b[39munsupported_error\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mf:\\Anaconda\\Anaconda\\envs\\MFEA\\lib\\site-packages\\numba\\core\\dispatcher.py:409\u001b[0m, in \u001b[0;36m_DispatcherBase._compile_for_args.<locals>.error_rewrite\u001b[1;34m(e, issue_type)\u001b[0m\n\u001b[0;32m    407\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m    408\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 409\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(\u001b[39mNone\u001b[39;00m)\n",
      "\u001b[1;31mTypingError\u001b[0m: Failed in nopython mode pipeline (step: nopython frontend)\n\u001b[1m\u001b[1mnon-precise type array(pyobject, 2d, C)\u001b[0m\n\u001b[0m\u001b[1mDuring: typing of argument at C:\\Users\\Acer\\AppData\\Local\\Temp\\ipykernel_9744\\2184204337.py (328)\u001b[0m\n\u001b[1m\nFile \"C:\\Users\\Acer\\AppData\\Local\\Temp\\ipykernel_9744\\2184204337.py\", line 328:\u001b[0m\n\u001b[1m    def _calculateD(gene_max: np.array, gene_min: np.array, subPop: np.array, subPop_fitness: np.array, best: np.array, TOLERANCE: float) -> float:\n        <source elided>\n\n\u001b[1m    @njit\n\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "baseModel = model()\n",
    "# from pyMSOO.MFEA.model import EME_BI\n",
    "# baseModel = EME_BI.model()\n",
    "baseModel.compile(\n",
    "    IndClass= IndClass,\n",
    "    tasks= tasks,\n",
    "    # crossover = KL_SBXCrossover(nc= 2, k= 100, conf_thres= 1),\n",
    "    crossover= SBX_Crossover(nc = 2),\n",
    "    mutation= PolynomialMutation(nm = 5),\n",
    "    selection= ElitismSelection(),\n",
    "    # dimension_strategy= DimensionAwareStrategy.DaS_strategy()\n",
    ")\n",
    "solve = baseModel.fit(\n",
    "    nb_generations = 1000, nb_inds_each_task= 100, \n",
    "    bound_pop= [0, 1], evaluate_initial_skillFactor= True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "baseModel = model()\n",
    "baseModel.compile(\n",
    "    IndClass= IndClass,\n",
    "    tasks= tasks,\n",
    "    # crossover = KL_SBXCrossover(nc= 2, k= 100, conf_thres= 1),\n",
    "    crossover= SBX_Crossover(nc = 2),\n",
    "    mutation= PolynomialMutation(nm = 5),\n",
    "    selection= ElitismSelection(),\n",
    "    dimension_strategy= DaS_strategy()\n",
    ")\n",
    "solve = baseModel.fit(\n",
    "    nb_generations = 1000, nb_inds_each_task= 100, \n",
    "    bound_pop= [0, 1], evaluate_initial_skillFactor= True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r\"F:\\BTVN\\DSAI\\Optimization Lab\\Paper\\Efficient knowledge transfer\\history_cost_summaries_EME_BI_woDaS.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "x=\"4.75E+01  4.92E+01  4.86E+01  4.05E+02  4.21E+02  3.99E+02  4.89E+01  4.72E+01  4.80E+01  1.54E+02  1.22E+02  4.83E+01  3.82E+03  1.28E+02  1.09E+02  4.69E+01  4.88E+01  4.56E+01  4.67E+01  4.77E+01  1.21E+02  4.72E+01  4.86E+01  1.73E+02  4.92E+01  4.22E+02  4.74E+01  4.71E+01  4.71E+01  4.86E+01  4.69E+01  4.92E+01  4.50E+01  1.58E+03  3.23E+02  1.09E+02  4.52E+01  4.56E+01  2.00E+02  4.73E+01  4.65E+01  4.73E+01  4.76E+01  1.81E+02  4.85E+01  4.90E+01  1.69E+02  4.69E+01  1.22E+02  4.82E+01\"\n",
    "x = x.split(\"  \")\n",
    "x = np.array(x, dtype=float)\n",
    "x = np.where(x <= 1e-6, 0, x)\n",
    "print(sum(x < df[\"EME-BI\"][50:100]))\n",
    "print(sum(x > df[\"EME-BI\"][50:100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "x=\"4.47E-25  4.73E+01  3.13E-13  7.09E-24  4.86E+01  1.62E-11  7.57E-19  1.09E+02  1.34E-12  7.03E-18  4.67E+01  6.10E-11  1.33E-26  4.79E+01  7.41E-12  5.13E-18  4.82E+01  3.51E-09  1.45E-21  4.65E+01  6.08E-14  5.58E-24  4.66E+01  1.37E-11  1.19E-26  7.23E+02  3.39E-11  1.26E-17  3.34E+02  4.69E-13  2.41E-20  4.75E+01  2.49E-11  4.51E-20  4.66E+01  2.18E-11  1.01E-21  5.87E+02  7.87E-12  7.97E-23  4.82E+01  3.37E-12  1.31E-22  4.70E+01  1.28E-10  1.76E-23  4.90E+01  1.46E-13  1.30E-21  3.03E+02\"\n",
    "x = x.split(\"  \")\n",
    "x = np.array(x, dtype=float)\n",
    "x = np.where(x <= 1e-6, 0, x)\n",
    "print(sum(x < df[\"EME-BI\"][150:200]))\n",
    "print(sum(x > df[\"EME-BI\"][150:200]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "x= \"9.52E+01  1.52E-11  1.57E+00  7.43E+01  1.61E-11  2.58E+00  7.85E+01  7.42E-11  4.17E-01  1.02E+02  6.28E-09  1.66E+00  8.89E+01  2.91E-12  7.18E-01  7.86E+01  7.41E-12  2.15E+00  7.41E+01  4.11E-11  3.38E+00  8.61E+01  1.57E-11  8.27E-01  6.42E+01  1.68E-12  5.01E+00  1.49E+02  2.22E-11  4.46E-02  7.68E+01  1.12E-11  1.97E-01  9.12E+01  1.72E-12  7.91E-01  8.55E+01  9.98E-11  3.40E-01  9.58E+01  1.74E-12  9.69E-02  7.41E+01  8.05E-13  2.03E+00  7.23E+01  5.51E-12  1.59E-01  1.00E+02  3.95E-11\"\n",
    "x = x.split(\"  \")\n",
    "x = np.array(x, dtype=float)\n",
    "x = np.where(x <= 1e-6, 0, x)\n",
    "print(sum(x < df[\"EME-BI\"][200:250]))\n",
    "print(sum(x > df[\"EME-BI\"][200:250]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = \"2.29E+03  2.93E-12  7.85E+03  5.02E+03  6.46E-12  6.00E+03  1.44E+02  7.24E-13  6.73E+03  4.66E+01  6.26E-12  8.64E+03  4.88E+01  9.31E-12  8.73E+03  5.27E+02  5.08E-09  8.03E+03  4.75E+01  4.47E-11  7.83E+03  4.74E+01  1.60E-12  8.02E+03  4.86E+01  5.00E-11  8.13E+03  4.83E+01  1.06E-11  7.15E+03  4.85E+01  5.88E-09  7.07E+03  1.20E+02  4.79E-11  8.94E+03  1.11E+02  1.47E-12  8.41E+03  1.84E+02  4.48E-11  9.56E+03  1.68E+03  3.83E-12  6.09E+03  4.92E+01  3.13E-11  9.78E+03  4.76E+01  3.10E-12\"\n",
    "x = x.split(\"  \")\n",
    "x = np.array(x, dtype=float)\n",
    "x = np.where(x <= 1e-6, 0, x)\n",
    "print(sum(x < df[\"EME-BI\"][250:300]))\n",
    "print(sum(x > df[\"EME-BI\"][250:300]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "x = \"1.63E-12  1.10E+02  3.41E+00  2.50E-11  1.09E+02  2.53E-01  2.06E-12  1.30E+02  4.12E-01  1.98E-11  7.28E+01  1.46E-01  1.46E-10  1.13E+02  1.92E+00  2.93E-12  5.27E+01  4.06E-01  5.62E-13  7.93E+01  9.71E-02  4.05E-12  1.15E+02  2.91E+00  4.33E-11  1.11E+02  6.98E-01  1.12E-11  8.53E+01  3.32E+00  1.83E-12  1.16E+02  2.47E+00  5.28E-11  9.38E+01  2.44E-01  1.14E-10  8.70E+01  2.80E+00  1.43E-12  7.08E+01  1.85E+00  2.02E-11  5.95E+01  2.17E-01  1.46E-13  7.51E+01  5.84E+00  8.11E-11  1.00E+02\"\n",
    "x = x.split(\"  \")\n",
    "x = np.array(x, dtype=float)\n",
    "x = np.where(x <= 1e-6, 0, x)\n",
    "print(sum(x < df[\"EME-BI\"][300:350]))\n",
    "print(sum(x > df[\"EME-BI\"][300:350]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyMSOO.MFEA.model import EME_BI\n",
    "\n",
    "# ls_benchmark = []\n",
    "# ls_IndClass = []\n",
    "# name_benchmark = []\n",
    "# ls_tasks = [10]\n",
    "\n",
    "# for i in ls_tasks:\n",
    "#     # t, ic = WCCI22_benchmark.get_complex_benchmark(i)\n",
    "#     t, ic = WCCI22_benchmark.get_50tasks_benchmark(i)\n",
    "#     ls_benchmark.append(t)\n",
    "#     ls_IndClass.append(ic)\n",
    "#     name_benchmark.append(str(i))\n",
    "\n",
    "\n",
    "\n",
    "# smpModel = MultiBenchmark(\n",
    "#     ls_benchmark= ls_benchmark,\n",
    "#     name_benchmark= name_benchmark,\n",
    "#     ls_IndClass= ls_IndClass,\n",
    "#     model= EME_BI\n",
    "# )\n",
    "\n",
    "# smpModel.compile(\n",
    "#     crossover= SBX_Crossover(nc = 2),\n",
    "#     mutation= PolynomialMutation(nm = 5),\n",
    "#     selection= ElitismSelection(),\n",
    "#     # dimension_strategy = DaS_strategy(eta = 3)\n",
    "# )\n",
    "# smpModel.fit(\n",
    "#     nb_generations = 1000,nb_inds_each_task= 100, \n",
    "#     bound_pop= [0, 1], evaluate_initial_skillFactor= True\n",
    "# )\n",
    "# a = smpModel.run(\n",
    "#     nb_run= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: None -- Time: 17m 35.56s   99 % [===================>]  Pop_size: 1.00E+03  ,  Cost: 1.19E+02  2.10E-09  1.20E+02  1.30E-12  5.64E+00  5.12E+03  4.82E+01  1.50E-13  1.02E+02  1.32E-11  1.19E+00  7.38E+03  4.68E+01  5.67E-10  1.15E+02  2.40E-11  8.62E+00  5.41E+03  3.09E+02  2.00E+01  9.74E+01  2.33E-11  2.35E+00  7.70E+03  4.72E+01  2.87E-12  1.00E+02  6.92E-11  6.37E+00  6.32E+03  4.75E+01  7.57E-11  1.59E+02  2.75E-10  5.51E+00  6.43E+03  4.87E+01  2.00E+01  1.35E+02  9.94E-11  6.38E-01  5.05E+03  4.69E+01  3.89E-11  1.24E+02  1.14E-11  1.82E+00  5.44E+03  4.86E+01  2.01E+01  ,  \n",
      "END!\n",
      "Seed: None -- Time: 17m 46.01s  100 % [====================>]  Pop_size: 1.00E+03  ,  Cost: 1.19E+02  2.10E-09  1.19E+02  1.01E-12  5.64E+00  5.12E+03  4.82E+01  7.86E-14  1.01E+02  1.11E-11  1.19E+00  7.38E+03  4.68E+01  5.67E-10  1.14E+02  2.20E-11  8.62E+00  5.41E+03  3.09E+02  2.00E+01  8.93E+01  2.31E-11  2.35E+00  7.70E+03  4.72E+01  2.57E-12  9.23E+01  6.73E-11  6.37E+00  6.32E+03  4.75E+01  7.55E-11  1.41E+02  2.72E-10  5.51E+00  6.43E+03  4.87E+01  2.00E+01  1.32E+02  9.83E-11  6.38E-01  5.05E+03  4.69E+01  3.82E-11  1.20E+02  1.08E-11  1.82E+00  5.44E+03  4.86E+01  2.01E+01  ,  "
     ]
    }
   ],
   "source": [
    "res = []\n",
    "# for i in range(1, 11):\n",
    "t, ic = WCCI22_benchmark.get_50tasks_benchmark(9)\n",
    "baseModel = model()\n",
    "baseModel.compile(\n",
    "    IndClass= ic,\n",
    "    tasks= t,\n",
    "    # crossover = KL_SBXCrossover(nc= 2, k= 100, conf_thres= 1),\n",
    "    crossover= SBX_Crossover(nc = 2),\n",
    "    mutation= PolynomialMutation(nm = 5),\n",
    "    selection= ElitismSelection(),\n",
    "    # dimension_strategy= DaS_strategy()\n",
    ")\n",
    "solve = baseModel.fit(\n",
    "    nb_generations = 1000, nb_inds_each_task= 100, \n",
    "    bound_pop= [0, 1], evaluate_initial_skillFactor= True\n",
    ")\n",
    "\n",
    "# res.append([subpop.getSolveInd().fcost for subpop in baseModel.last_pop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = np.array([subpop.getSolveInd().fcost for subpop in baseModel.last_pop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = np.where(h < 1e-6, 0, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.19332709e+02 0.00000000e+00 1.18894573e+02 0.00000000e+00\n",
      " 5.63568780e+00 5.12286024e+03 4.81605226e+01 0.00000000e+00\n",
      " 1.01421384e+02 0.00000000e+00 1.18984303e+00 7.37960500e+03\n",
      " 4.68279935e+01 0.00000000e+00 1.13625382e+02 0.00000000e+00\n",
      " 8.61583492e+00 5.40961486e+03 3.08511018e+02 1.99848761e+01\n",
      " 8.92349306e+01 0.00000000e+00 2.35393013e+00 7.70491790e+03\n",
      " 4.72076715e+01 0.00000000e+00 9.22279775e+01 0.00000000e+00\n",
      " 6.36707861e+00 6.31764802e+03 4.74683764e+01 0.00000000e+00\n",
      " 1.40387984e+02 0.00000000e+00 5.50802877e+00 6.43279297e+03\n",
      " 4.87159261e+01 1.99722336e+01 1.32008821e+02 0.00000000e+00\n",
      " 6.38473375e-01 5.05431253e+03 4.68672370e+01 0.00000000e+00\n",
      " 1.20272996e+02 0.00000000e+00 1.82315689e+00 5.43768031e+03\n",
      " 4.86259257e+01 2.01062843e+01]\n",
      "[1345.2809961     0.          136.0607488     0.           11.06903917\n",
      " 4493.66155547  295.07901483    0.          132.30275237    0.\n",
      "   12.30391307 4708.67148357  330.7125527     0.          135.2337131\n",
      "    0.           10.8210762  4915.05272457  183.89925843    0.\n",
      "  130.11333477    0.            9.67409147 4295.43882953  638.21655467\n",
      "    0.          168.9823331     0.           10.3730895  5002.4439091\n",
      "  617.3609172     0.          123.6474079     0.           12.52441737\n",
      " 5270.103723    326.2771332     0.          154.46799967    0.\n",
      "   10.2473199  4346.1903906   352.87033697    0.          158.34564103\n",
      "    0.           11.40139753 5028.6126043   129.56774643    0.        ]\n"
     ]
    }
   ],
   "source": [
    "print(h)\n",
    "print(np.array(df[\"EME-BI\"][-100:-50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(h > df[\"EME-BI\"][-100:-50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(h < df[\"EME-BI\"][-100:-50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: None -- Time: 17m 48.00s   99 % [===================>]  Pop_size: 1.00E+03  ,  Cost: 4.68E+01  2.00E+01  1.10E+02  1.54E-11  6.19E+00  5.77E+03  4.52E+01  2.74E-12  1.13E+02  4.55E-12  7.42E-01  7.80E+03  4.91E+01  8.32E-11  3.60E+02  5.27E-11  8.93E+00  5.69E+03  4.92E+01  9.21E-13  9.39E+01  4.23E-12  1.71E+01  6.13E+03  4.51E+01  2.00E+01  9.10E+01  1.14E-10  1.13E+00  6.45E+03  1.63E+02  2.00E+01  8.21E+01  3.18E-10  9.70E+00  5.61E+03  3.31E+02  1.81E-11  1.97E+02  1.12E-11  3.07E+00  3.77E+03  4.56E+01  2.00E+01  1.05E+02  2.96E-12  2.05E+00  6.29E+03  1.43E+02  1.60E-10  ,  \n",
      "END!\n",
      "Seed: None -- Time: 17m 58.19s  100 % [====================>]  Pop_size: 1.00E+03  ,  Cost: 4.68E+01  2.00E+01  1.03E+02  1.39E-11  6.19E+00  5.77E+03  4.52E+01  1.20E-12  1.13E+02  4.29E-12  7.42E-01  7.80E+03  4.91E+01  7.97E-11  3.28E+02  5.24E-11  8.93E+00  5.69E+03  4.92E+01  7.61E-13  8.97E+01  3.84E-12  1.71E+01  6.13E+03  4.51E+01  2.00E+01  8.64E+01  1.11E-10  1.13E+00  6.45E+03  1.63E+02  2.00E+01  8.19E+01  3.18E-10  9.70E+00  5.61E+03  3.23E+02  1.71E-11  1.96E+02  1.06E-11  3.07E+00  3.77E+03  4.56E+01  2.00E+01  1.05E+02  2.63E-12  2.05E+00  6.29E+03  1.43E+02  1.60E-10  ,  "
     ]
    }
   ],
   "source": [
    "res = []\n",
    "# for i in range(1, 11):\n",
    "t, ic = WCCI22_benchmark.get_50tasks_benchmark(9)\n",
    "baseModel = model()\n",
    "baseModel.compile(\n",
    "    IndClass= ic,\n",
    "    tasks= t,\n",
    "    # crossover = KL_SBXCrossover(nc= 2, k= 100, conf_thres= 1),\n",
    "    crossover= SBX_Crossover(nc = 2),\n",
    "    mutation= PolynomialMutation(nm = 5),\n",
    "    selection= ElitismSelection(),\n",
    "    dimension_strategy= DaS_strategy()\n",
    ")\n",
    "solve = baseModel.fit(\n",
    "    nb_generations = 1000, nb_inds_each_task= 100, \n",
    "    bound_pop= [0, 1], evaluate_initial_skillFactor= True\n",
    ")\n",
    "\n",
    "# res.append([subpop.getSolveInd().fcost for subpop in baseModel.last_pop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = np.array([subpop.getSolveInd().fcost for subpop in baseModel.last_pop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = np.where(f < 1e-6, 0, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.68003042e+01 1.99663587e+01 1.03113956e+02 0.00000000e+00\n",
      " 6.19448226e+00 5.76956100e+03 4.52351287e+01 0.00000000e+00\n",
      " 1.12963484e+02 0.00000000e+00 7.41577009e-01 7.80272560e+03\n",
      " 4.91021492e+01 0.00000000e+00 3.24258332e+02 0.00000000e+00\n",
      " 8.92674103e+00 5.69427436e+03 4.91778275e+01 0.00000000e+00\n",
      " 8.97199871e+01 0.00000000e+00 1.71331118e+01 6.12955815e+03\n",
      " 4.51297589e+01 1.99613433e+01 8.63315608e+01 0.00000000e+00\n",
      " 1.12805856e+00 6.45339352e+03 1.62864812e+02 1.99926680e+01\n",
      " 8.19327505e+01 0.00000000e+00 9.70125321e+00 5.60552946e+03\n",
      " 3.22637544e+02 0.00000000e+00 1.95727540e+02 0.00000000e+00\n",
      " 3.06602228e+00 3.77352536e+03 4.56151967e+01 2.00148003e+01\n",
      " 1.05114663e+02 0.00000000e+00 2.04655754e+00 6.29422535e+03\n",
      " 1.43124317e+02 0.00000000e+00]\n",
      "[1345.2809961     0.          136.0607488     0.           11.06903917\n",
      " 4493.66155547  295.07901483    0.          132.30275237    0.\n",
      "   12.30391307 4708.67148357  330.7125527     0.          135.2337131\n",
      "    0.           10.8210762  4915.05272457  183.89925843    0.\n",
      "  130.11333477    0.            9.67409147 4295.43882953  638.21655467\n",
      "    0.          168.9823331     0.           10.3730895  5002.4439091\n",
      "  617.3609172     0.          123.6474079     0.           12.52441737\n",
      " 5270.103723    326.2771332     0.          154.46799967    0.\n",
      "   10.2473199  4346.1903906   352.87033697    0.          158.34564103\n",
      "    0.           11.40139753 5028.6126043   129.56774643    0.        ]\n"
     ]
    }
   ],
   "source": [
    "print(f)\n",
    "print(np.array(df[\"EME-BI\"][400:450]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(f < df[\"EME-BI\"][400:450])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(f > df[\"EME-BI\"][400:450])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(h < f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(h > f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(f < df[\"EME_BI_wo_DaS\"][-50:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df[\"EME_BI_wo_DaS\"][-50:] < df[\"EME-BI\"][-50:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df[\"EME_BI_wo_DaS\"][-50:] > df[\"EME-BI\"][-50:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MFEA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
