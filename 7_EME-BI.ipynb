{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyMSOO.utils.Crossover import *\n",
    "from pyMSOO.utils.Mutation import *\n",
    "from pyMSOO.utils.Selection import *\n",
    "from pyMSOO.utils.DimensionAwareStrategy import *\n",
    "from pyMSOO.MFEA.benchmark.continous import *\n",
    "from pyMSOO.utils.MultiRun.RunMultiTime import * \n",
    "from pyMSOO.utils.MultiRun.RunMultiBenchmark import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tasks, IndClass = CEC17_benchmark.get_2tasks_benchmark(1)\n",
    "# tasks, IndClass = WCCI22_benchmark.get_complex_benchmark(1)\n",
    "tasks, IndClass = CEC17_benchmark.get_10tasks_benchmark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from numba import jit, njit\n",
    "\n",
    "from pyMSOO.MFEA.model import AbstractModel\n",
    "from pyMSOO.utils import Crossover, Mutation, Selection, DimensionAwareStrategy\n",
    "from pyMSOO.utils.EA import *\n",
    "from pyMSOO.utils.numba_utils import numba_randomchoice, numba_random_gauss, numba_random_cauchy, numba_random_uniform\n",
    "from pyMSOO.utils.Search import *\n",
    "\n",
    "class model(AbstractModel.model):\n",
    "    TOLERANCE = 1e-6\n",
    "    INF = 1e8\n",
    "    def compile(self, \n",
    "        IndClass: Type[Individual],\n",
    "        tasks: List[AbstractTask], \n",
    "        crossover: Crossover.SBX_Crossover, \n",
    "        mutation: Mutation.PolynomialMutation, \n",
    "        selection: Selection.ElitismSelection,\n",
    "        dimension_strategy: DimensionAwareStrategy.AbstractDaS = DimensionAwareStrategy.NoDaS(),\n",
    "        *args, **kwargs):\n",
    "        super().compile(IndClass, tasks, crossover, mutation,dimension_strategy, selection, *args, **kwargs)\n",
    "    \n",
    "    def fit(self, nb_generations, \n",
    "            nb_inds_each_task = 100, \n",
    "            nb_inds_max = 100,\n",
    "            nb_inds_min = 20,\n",
    "            evaluate_initial_skillFactor = True, \n",
    "            c = 0.06,\n",
    "            *args, \n",
    "            **kwargs) -> List[Individual]:\n",
    "        super().fit(*args, **kwargs)\n",
    "\n",
    "        # nb_inds_min\n",
    "        if nb_inds_min is not None:\n",
    "            assert nb_inds_each_task >= nb_inds_min\n",
    "        else: \n",
    "            nb_inds_min = nb_inds_each_task\n",
    "\n",
    "        self.rmp = np.full((len(self.tasks), len(self.tasks)), 0.3)\n",
    "        self.learningPhase = [LearningPhase(self.IndClass, self.tasks, t) for t in self.tasks]\n",
    "        \n",
    "        # initialize population\n",
    "        self.population = Population(\n",
    "            self.IndClass,\n",
    "            nb_inds_tasks = [nb_inds_each_task] * len(self.tasks), \n",
    "            dim = self.dim_uss,\n",
    "            list_tasks= self.tasks,\n",
    "            evaluate_initial_skillFactor = evaluate_initial_skillFactor\n",
    "        )\n",
    "\n",
    "        self.nb_inds_tasks = [nb_inds_each_task] * len(self.tasks)\n",
    "\n",
    "        MAXEVALS = nb_generations * nb_inds_each_task * len(self.tasks)\n",
    "        self.max_eval_k = [nb_generations * nb_inds_each_task] * len(self.tasks)\n",
    "        self.eval_k = [0] * len(self.tasks)\n",
    "        epoch = 1\n",
    "        \n",
    "        D0 = self.calculateD(population = np.array([[ind.genes for ind in sub.ls_inds] for sub in self.population]), \n",
    "                            population_fitness = np.array([sub.getFitness() for sub in self.population]),\n",
    "                            best = np.array([sub.__getBestIndividual__.genes for sub in self.population]),)\n",
    "\n",
    "        while sum(self.eval_k) < MAXEVALS:\n",
    "            self.delta = [[[] for _ in range(len(self.tasks))] for _ in range(len(self.tasks))]\n",
    "\n",
    "            self.s_rmp = [[[] for _ in range(len(self.tasks))] for _ in range(len(self.tasks))]\n",
    "\n",
    "            self.population.update_rank()\n",
    "            # print(self.eval_k)\n",
    "            if sum(self.eval_k) >= epoch * nb_inds_each_task * len(self.tasks):\n",
    "                # save history\n",
    "                self.history_cost.append([ind.fcost for ind in self.population.get_solves()])\n",
    "                self.render_process(epoch/nb_generations, ['Pop_size', 'Cost'], [[sum(self.nb_inds_tasks)], self.history_cost[-1]], use_sys= True)\n",
    "                epoch += 1\n",
    "\n",
    "            # offsprings = self.reproduction(sum(self.nb_inds_tasks), self.population)\n",
    "\n",
    "            # self.population = self.population + offsprings\n",
    "            # start = time.time()\n",
    "            matingPool = Population(\n",
    "                self.IndClass,\n",
    "                nb_inds_tasks = [0] * len(self.tasks), \n",
    "                dim = self.dim_uss,\n",
    "                list_tasks= self.tasks,\n",
    "                evaluate_initial_skillFactor = False\n",
    "            )\n",
    "\n",
    "            for idx in range(len(self.tasks)):\n",
    "                \n",
    "                idx_inds = np.argsort([ind.fcost for ind in self.population[idx].ls_inds])\n",
    "                \n",
    "                for i in idx_inds[:int(len(self.population[idx])/2)]:\n",
    "                    matingPool.__addIndividual__(self.population[idx].ls_inds[i])\n",
    "\n",
    "            offsprings = self.reproduction(len(self.population), matingPool)\n",
    "        \n",
    "            # # merge and update rank\n",
    "            self.population = matingPool + offsprings\n",
    "            self.population.update_rank()\n",
    "            # end = time.time()\n",
    "            # print(\"E: \", end - start)\n",
    "            # selection\n",
    "            self.nb_inds_tasks = [int(\n",
    "                int(max((nb_inds_min - nb_inds_max) * (sum(self.eval_k)/MAXEVALS) + nb_inds_max, nb_inds_min))\n",
    "            )] * len(self.tasks)\n",
    "            self.selection(self.population, self.nb_inds_tasks)\n",
    "\n",
    "            # update operators\n",
    "            self.crossover.update(population = self.population)\n",
    "            self.mutation.update(population = self.population)\n",
    "            self.dimension_strategy.update(population = self.population)\n",
    "            # start = time.time()\n",
    "            self.updateRMP(c)\n",
    "            # end = time.time()\n",
    "            # print(\"G: \", end - start)\n",
    "            # start = time.time()\n",
    "            self.phaseTwo(D0)\n",
    "            # end = time.time()\n",
    "            # print(\"G: \", end - start)\n",
    "        # self.phaseTwo(D0)\n",
    "        print('\\nEND!')\n",
    "\n",
    "        #solve \n",
    "        self.render_process(epoch/nb_generations, ['Pop_size', 'Cost'], [[sum(self.nb_inds_tasks)], self.history_cost[-1]], use_sys= True)\n",
    "        self.population.update_rank()\n",
    "        self.last_pop = self.population\n",
    "        return self.last_pop.get_solves()\n",
    "    \n",
    "    def reproduction(self, size: int, mating_pool: Population,) -> Population:\n",
    "        sub_size = int(size/len(self.tasks))\n",
    "       \n",
    "        offsprings = Population(self.IndClass,\n",
    "                                nb_inds_tasks = [0] * len(self.tasks), \n",
    "                                dim = self.dim_uss,\n",
    "                                list_tasks= self.tasks)\n",
    "        counter = np.zeros((len(self.tasks)))  \n",
    "\n",
    "        stopping = False\n",
    "        while not stopping:\n",
    "            pa, pb = mating_pool.__getRandomInds__(2)\n",
    "            ta = pa.skill_factor\n",
    "            tb = pb.skill_factor\n",
    "\n",
    "            if counter[ta] >= sub_size and counter[tb] >= sub_size:\n",
    "                continue\n",
    "\n",
    "            rmpValue = numba_random_gauss(mean = max(self.rmp[ta][tb], self.rmp[tb][ta]), sigma = 0.1)\n",
    "\n",
    "            if ta == tb:\n",
    "                # self.eval_k[ta] += 2\n",
    "\n",
    "                oa, ob = self.crossover(pa, pb)\n",
    "\n",
    "                oa.skill_factor = ta\n",
    "                ob.skill_factor = ta\n",
    "\n",
    "                if self.eval_k[ta] >= self.max_eval_k[ta]:\n",
    "                    oa.fcost = model.INF\n",
    "                else:\n",
    "                    self.eval_k[ta] += 1\n",
    "\n",
    "                offsprings.__addIndividual__(oa)\n",
    "\n",
    "                if self.eval_k[tb] >= self.max_eval_k[tb]:\n",
    "                    ob.fcost = model.INF\n",
    "                else:\n",
    "                    self.eval_k[tb] += 1\n",
    "\n",
    "                offsprings.__addIndividual__(ob)\n",
    "\n",
    "                counter[ta] += 2\n",
    "\n",
    "            elif random.random() <= rmpValue:\n",
    "                off = self.crossover(pa, pb)\n",
    "\n",
    "                for o in off:\n",
    "                    if counter[ta] < sub_size and random.random() < self.rmp[ta][tb]/(self.rmp[ta][tb] + self.rmp[tb][ta]):\n",
    "                        o.skill_factor = ta\n",
    "                        o = self.dimension_strategy(o, tb, pa)\n",
    "                        if self.eval_k[ta] >= self.max_eval_k[ta]:\n",
    "                            o.fcost = model.INF\n",
    "                        else:\n",
    "                            self.eval_k[ta] += 1\n",
    "                            o.fcost = self.tasks[ta](o)\n",
    "\n",
    "                        offsprings.__addIndividual__(o)\n",
    "                        \n",
    "                        counter[ta] += 1\n",
    "                        # self.eval_k[ta] += 1\n",
    "                        \n",
    "                        if pa.fcost > o.fcost:\n",
    "                            self.delta[ta][tb].append(pa.fcost - o.fcost)\n",
    "                            self.s_rmp[ta][tb].append(rmpValue)\n",
    "                    \n",
    "                    elif counter[tb] < sub_size:\n",
    "                        o.skill_factor = tb\n",
    "                        o = self.dimension_strategy(o, ta, pb)\n",
    "        \n",
    "                        if self.eval_k[tb] >= self.max_eval_k[tb]:\n",
    "                            o.fcost = model.INF\n",
    "                        else:\n",
    "                            self.eval_k[tb] += 1\n",
    "                            o.fcost = self.tasks[tb](o)\n",
    "\n",
    "                        offsprings.__addIndividual__(o)\n",
    "                        \n",
    "                        counter[tb] += 1\n",
    "                        # self.eval_k[tb] += 1\n",
    "\n",
    "                        if pb.fcost > o.fcost:\n",
    "                            self.delta[tb][ta].append(pb.fcost - o.fcost)\n",
    "                            self.s_rmp[tb][ta].append(rmpValue)\n",
    "\n",
    "            else:\n",
    "                if counter[ta] < sub_size:\n",
    "                    paa: Individual = self.population[ta].__getRandomItems__()\n",
    "\n",
    "                    # while np.array_equal(paa.genes, pa.genes):\n",
    "                    #     paa: Individual = self.population[ta].__getRandomItems__()\n",
    "                    \n",
    "                    oa, _ = self.crossover(pa, paa)\n",
    "                    oa.skill_factor = ta\n",
    "                    \n",
    "                    if self.eval_k[ta] >= self.max_eval_k[ta]:\n",
    "                        oa.fcost = model.INF\n",
    "                    else:\n",
    "                        self.eval_k[ta] += 1\n",
    "                        oa.fcost = self.tasks[ta](oa)\n",
    "\n",
    "                    offsprings.__addIndividual__(oa)\n",
    "\n",
    "                    counter[ta] += 1\n",
    "                    # self.eval_k[ta] += 1\n",
    "\n",
    "                if counter[tb] < sub_size:\n",
    "                    pbb: Individual = self.population[tb].__getRandomItems__()\n",
    "\n",
    "                    # while np.array_equal(pbb.genes, pb.genes):\n",
    "                    #     pbb: Individual = self.population[tb].__getRandomItems__()\n",
    "                    \n",
    "                    ob, _ = self.crossover(pb, pbb)\n",
    "                    ob.skill_factor = tb\n",
    "\n",
    "                    if self.eval_k[tb] >= self.max_eval_k[tb]:\n",
    "                        ob.fcost = model.INF\n",
    "                    else:\n",
    "                        self.eval_k[tb] += 1\n",
    "                        ob.fcost = self.tasks[tb](ob)\n",
    "\n",
    "                    offsprings.__addIndividual__(ob)\n",
    "                    \n",
    "                    counter[tb] += 1\n",
    "                    # self.eval_k[tb] += 1\n",
    "                    \n",
    "            stopping = sum(counter >= sub_size) == len(self.tasks)\n",
    "\n",
    "        return offsprings\n",
    "\n",
    "    def phaseTwo(self, D0):\n",
    "        fcosts = [sub.getFitness() for sub in self.population]\n",
    "        # start = time.time()\n",
    "        D = self.calculateD(population = np.array([[ind.genes for ind in sub.ls_inds]for sub in self.population]), \n",
    "                            population_fitness = np.array(fcosts),\n",
    "                            best = np.array([sub.__getBestIndividual__.genes for sub in self.population]),\n",
    "                            )\n",
    "        # end = time.time()\n",
    "        # print(\"A: \", end - start)\n",
    "        maxFit = np.max(fcosts, axis=1)\n",
    "        minFit = np.min(fcosts, axis=1)\n",
    "        maxDelta = maxFit - minFit + 1e-99\n",
    "\n",
    "        assert len(D) == len(maxDelta), \"Wrong shape. Got {} and {}\".format(D.shape, maxDelta.shape)\n",
    "        assert len(D) == len(self.tasks), \"Got wrong shape\"\n",
    "\n",
    "        sigma = np.where(D > D0, 0, 1 - D/D0)\n",
    "        nextPop = Population(IndClass = self.IndClass,\n",
    "                            dim = self.dim_uss,\n",
    "                            nb_inds_tasks=[0] * len(self.tasks),\n",
    "                            list_tasks=self.tasks)\n",
    "        # start = time.time()\n",
    "        for i in range(len(self.tasks)):\n",
    "            self.eval_k[i] += self.learningPhase[i].evolve(self.max_eval_k[i] - self.eval_k[i], \n",
    "                                                           self.population[i], \n",
    "                                                           nextPop, \n",
    "                                                           sigma[i], \n",
    "                                                           maxDelta[i])\n",
    "        # end = time.time()\n",
    "        # print(\"B: \", end - start)\n",
    "        self.population = nextPop\n",
    "\n",
    "    def calculateD(self, population: np.array, population_fitness: np.array, best: np.array) -> np.array:\n",
    "        '''\n",
    "        Arguments include:\\n\n",
    "        + `population`: genes of the current population\n",
    "        + `population_fitness`: fitness of the current population\n",
    "        + `best`: the best gene of each subpop\n",
    "        + `nb_tasks`: number of tasks\n",
    "        '''\n",
    "        \n",
    "        D = np.empty((len(self.tasks)))\n",
    "        for i in range(len(self.tasks)):\n",
    "            gene_max = [np.max(population[i], axis = 1).tolist()] * self.dim_uss\n",
    "            gene_min = [np.min(population[i], axis = 1).tolist()] * self.dim_uss\n",
    "\n",
    "            D[i] = self.__class__._calculateD(np.array(gene_max).T, np.array(gene_min).T, population[i], population_fitness[i], best[i], model.TOLERANCE)\n",
    "        return D\n",
    "    \n",
    "    @jit(nopython = True, parallel = True, cache=True)\n",
    "    def _calculateD(gene_max: np.array, gene_min: np.array, subPop: np.array, subPop_fitness: np.array, best: np.array, TOLERANCE: float) -> float:\n",
    "            # gene_max = gene_max.flatten()\n",
    "            # gene_max = np.broadcast_to(gene_max, (subPop.shape[-1], subPop.shape[0])).T\n",
    "            # gene_min = gene_min.flatten()\n",
    "            # gene_min = np.broadcast_to(gene_min, (subPop.shape[-1], subPop.shape[0])).T\n",
    "            \n",
    "            w = np.where(subPop_fitness > TOLERANCE, 1/(subPop_fitness), 1/TOLERANCE)\n",
    "            # w = [1/ind if ind > TOLERANCE else 1/TOLERANCE for ind in population[i]]\n",
    "            # print(subPop.shape)\n",
    "            sum_w = sum(w)\n",
    "            d = (subPop - gene_min)/(gene_max - gene_min)\n",
    "            best = (best - gene_min)/(gene_max - gene_min)\n",
    "            d = np.sum((d - best) ** 2, axis=1)\n",
    "            d = np.sqrt(d)\n",
    "            assert d.shape == w.shape\n",
    "            # d = np.sqrt(np.sum(d, axis=0))\n",
    "            # d = np.sum([np.sqrt(np.sum((d[i] - best) * (d[i] - best))) for i in range(len(subPop))])\n",
    "\n",
    "            return np.sum(w * d/sum_w)\n",
    "    \n",
    "    def updateRMP(self, c: int):\n",
    "        for i in range(len(self.tasks)):\n",
    "            for j in range(len(self.tasks)):\n",
    "                if i == j:\n",
    "                    continue\n",
    "                if len(self.delta[i][j]) > 0:\n",
    "                    self.rmp[i][j] += self.__class__._updateRMP(self.delta[i][j], self.s_rmp[i][j], c)\n",
    "                else:\n",
    "                    self.rmp[i][j] = (1 - c) * self.rmp[i][j]\n",
    "                \n",
    "                self.rmp[i][j] = max(0.1, min(1, self.rmp[i][j]))\n",
    "\n",
    "    @jit(nopython = True, parallel = True, cache= True)\n",
    "    def _updateRMP(delta: List, s_rmp: List, c: float) -> float:\n",
    "        delta = np.array(delta)\n",
    "        s_rmp = np.array(s_rmp)\n",
    "        sum_delta = sum(delta)\n",
    "        tmp = (delta/sum_delta) * s_rmp\n",
    "        meanS = sum(tmp * s_rmp)\n",
    "        \n",
    "        return c * meanS/sum(tmp)\n",
    "    \n",
    "class LearningPhase():\n",
    "    M = 2\n",
    "    H = 10\n",
    "    def __init__(self, IndClass, list_tasks, task) -> None:\n",
    "        self.IndClass = IndClass\n",
    "        self.list_tasks = list_tasks\n",
    "        self.task = task\n",
    "        self.sum_improv = [0.0] * LearningPhase.M\n",
    "        self.consume_fes = [1.0] * LearningPhase.M\n",
    "        self.mem_cr = [0.5] * LearningPhase.H\n",
    "        self.mem_f = [0.5] * LearningPhase.H\n",
    "        self.s_cr = []\n",
    "        self.s_f = []\n",
    "        self.diff_f = []\n",
    "        self.mem_pos = 0\n",
    "        self.gen = 0\n",
    "        self.best_opcode = 1\n",
    "        self.searcher = [self.pbest1, PolynomialMutation(nm = 5).getInforTasks(self.IndClass, self.list_tasks)]\n",
    "\n",
    "    def evolve(self, max_eval: int, subPop: SubPopulation, nextPop: Population, sigma: float, max_delta: float) -> SubPopulation:\n",
    "        self.gen += 1\n",
    "\n",
    "        if self.gen > 1:\n",
    "            # start = time.time()\n",
    "            self.best_opcode = self.__class__.updateOperator(sum_improve = self.sum_improv, \n",
    "                                                             consume_fes = self.consume_fes, \n",
    "                                                             M = LearningPhase.M)\n",
    "\n",
    "            self.sum_improv = [0.0] * LearningPhase.M\n",
    "            self.consume_fes = [1.0] * LearningPhase.M\n",
    "\n",
    "            # end = time.time()\n",
    "            # print(\"C: \", end - start)\n",
    "\n",
    "        # self.updateMemory()\n",
    "        \n",
    "        pbest_size = max(5, int(0.15 * len(subPop)))\n",
    "        # pbest = subPop.__getRandomItems__(size = pbest_size)\n",
    "        idx_inds = np.argsort([ind.fcost for ind in subPop.ls_inds])\n",
    "        pbest =  [subPop.ls_inds[i] for i in idx_inds[:pbest_size]] \n",
    "        # start1 = time.time()\n",
    "        for i, ind in enumerate(subPop):\n",
    "            # start1 = time.time()\n",
    "            # start = time.time()\n",
    "            r = random.randint(0, LearningPhase.M - 1)\n",
    "            cr = numba_random_gauss(self.mem_cr[r], 0.1)\n",
    "            f = numba_random_cauchy(self.mem_f[r], 0.1)\n",
    "            # end = time.time()\n",
    "            # print(\"A: \", end - start)\n",
    "            opcode = random.randint(0, LearningPhase.M)\n",
    "            if opcode == LearningPhase.M:\n",
    "                opcode = self.best_opcode\n",
    "\n",
    "            self.consume_fes[opcode] += 1\n",
    "            \n",
    "            if opcode == 0:\n",
    "                # start = time.time()\n",
    "                child = self.searcher[opcode](ind, subPop, pbest, cr, f)\n",
    "                # end = time.time()\n",
    "                # print(\"C: \", end - start)\n",
    "            elif opcode == 1:\n",
    "                # start = time.time()\n",
    "                child = self.searcher[opcode](ind, return_newInd=True)\n",
    "                # end = time.time()\n",
    "                # print(\"D: \", end - start)\n",
    "\n",
    "            # start = time.time()\n",
    "            child.skill_factor = ind.skill_factor\n",
    "            if i <= max_eval:\n",
    "                child.fcost = self.task(child)\n",
    "            else:\n",
    "                child.fcost = model.INF\n",
    "            \n",
    "            diff = ind.fcost - child.fcost\n",
    "            if diff > 0:\n",
    "                survival = child\n",
    "\n",
    "                self.sum_improv[opcode] += diff\n",
    "\n",
    "                if opcode == 0:\n",
    "                    self.diff_f.append(diff)\n",
    "                    # self.s_cr.append(cr)\n",
    "                    # self.s_f.append(f)\n",
    "                \n",
    "            elif diff == 0 or random.random() <= sigma * np.exp(diff/max_delta):\n",
    "                survival = child\n",
    "            else:\n",
    "                survival = ind\n",
    "            \n",
    "            nextPop.__addIndividual__(survival)\n",
    "            # end = time.time()\n",
    "            # print(\"M: \", end - start)\n",
    "        # end = time.time()\n",
    "        # print(\"F: \", end - start1)\n",
    "        return min(len(subPop), max_eval)\n",
    "    \n",
    "    def pbest1(self, ind: Individual, subPop: SubPopulation, best: List[Individual], cr: float, f: float) -> Individual:\n",
    "        pbest = best[random.randint(0, len(best) - 1)]\n",
    "        \n",
    "        ind_ran1, ind_ran2 = subPop.__getRandomItems__(size = 2, replace= False)\n",
    "        \n",
    "        u = (numba_random_uniform(len(ind.genes)) < cr)\n",
    "        if np.sum(u) == 0:\n",
    "            u = np.zeros(shape= (subPop.dim,))\n",
    "            u[numba_randomchoice(subPop.dim)] = 1\n",
    "\n",
    "        # new_genes = np.where(u, \n",
    "        #     pbest.genes + f * (ind_ran1.genes - ind_ran2.genes),\n",
    "        #     ind.genes\n",
    "        # )\n",
    "        # # new_genes = np.clip(new_genes, ind.genes/2, (ind.genes + 1)/2)\n",
    "        # new_genes = np.where(new_genes < 0, ind.genes/2, np.where(new_genes > 1, (ind.genes + 1)/2, new_genes))\n",
    "\n",
    "        new_genes = self.__class__.produce_inds(ind.genes, pbest.genes, ind_ran1.genes, ind_ran2.genes, f, u)\n",
    "        new_ind = self.IndClass(new_genes)\n",
    "\n",
    "        return new_ind\n",
    "\n",
    "    @jit(nopython=True, parallel = True)\n",
    "    def produce_inds(ind_genes: np.array, best_genes: np.array, ind1_genes: np.array, ind2_genes: np.array, F: float, u: np.array) -> np.array:\n",
    "        new_genes = np.where(u,\n",
    "            best_genes + F * (ind1_genes - ind2_genes),\n",
    "            ind_genes\n",
    "        )\n",
    "        new_genes = np.where(new_genes > 1, (ind_genes + 1)/2, new_genes) \n",
    "        new_genes = np.where(new_genes < 0, (ind_genes + 0)/2, new_genes)\n",
    "\n",
    "        return new_genes\n",
    "\n",
    "    # def updateMemory(self):\n",
    "    #     if len(self.s_cr) > 0:\n",
    "    #         # self.diff_f = np.array(self.diff_f)\n",
    "    #         # self.s_cr = np.array(self.s_cr)\n",
    "    #         # self.s_f = np.array(self.s_f)\n",
    "\n",
    "    #         self.mem_cr[self.mem_pos] = self.__class__.updateMemoryCR(self.diff_f, self.s_cr)\n",
    "    #         self.mem_f[self.mem_pos] = self.__class__.updateMemoryF(self.diff_f, self.s_f)\n",
    "            \n",
    "    #         self.mem_pos = (self.mem_pos + 1) % LearningPhase.H\n",
    "\n",
    "    #         self.s_cr = []\n",
    "    #         self.s_f = []\n",
    "    #         self.diff_f = []\n",
    "\n",
    "    # @jit(nopython = True, parallel = True, cache=True)\n",
    "    # def updateMemoryCR(diff_f: List, s_cr: List) -> float:\n",
    "    #     diff_f = np.array(diff_f)\n",
    "    #     s_cr = np.array(s_cr)\n",
    "\n",
    "    #     sum_diff = sum(diff_f)\n",
    "    #     weight = diff_f/sum_diff\n",
    "    #     tmp_sum_cr = sum(weight * s_cr)\n",
    "    #     mem_cr = sum(weight * s_cr * s_cr)\n",
    "        \n",
    "    #     if tmp_sum_cr == 0 or mem_cr == -1:\n",
    "    #         return -1\n",
    "    #     else:\n",
    "    #         return mem_cr/tmp_sum_cr\n",
    "        \n",
    "    # @jit(nopython = True, parallel = True, cache = True)\n",
    "    # def updateMemoryF(diff_f: List, s_f: List) -> float:\n",
    "    #     diff_f = np.array(diff_f)\n",
    "    #     s_f = np.array(s_f)\n",
    "\n",
    "    #     sum_diff = sum(diff_f)\n",
    "    #     weight = diff_f/sum_diff\n",
    "    #     tmp_sum_f = sum(weight * s_f)\n",
    "    #     return sum(weight * (s_f ** 2)) / tmp_sum_f\n",
    "\n",
    "    @jit(nopython = True, parallel = True)\n",
    "    def updateOperator(sum_improve: List, consume_fes: List, M: int) -> int:\n",
    "        sum_improve = np.array(sum_improve)\n",
    "        consume_fes = np.array(consume_fes)\n",
    "        eta = sum_improve / consume_fes\n",
    "        best_rate = max(eta)\n",
    "        best_op = np.argmax(eta)\n",
    "        if best_rate > 0:\n",
    "            return best_op\n",
    "        else:\n",
    "            return random.randint(0, M - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking...\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Anaconda\\Anaconda\\envs\\MFEA\\lib\\site-packages\\numba\\core\\ir_utils.py:2147: NumbaPendingDeprecationWarning: \u001b[1m\n",
      "Encountered the use of a type that is scheduled for deprecation: type 'reflected list' found for argument 'delta' of function 'model._updateRMP'.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-reflection-for-list-and-set-types\n",
      "\u001b[1m\n",
      "File \"C:\\Users\\Acer\\AppData\\Local\\Temp\\ipykernel_16676\\2371826582.py\", line 342:\u001b[0m\n",
      "\u001b[1m    @jit(nopython = True, parallel = True, cache= True)\n",
      "\u001b[1m    def _updateRMP(delta: List, s_rmp: List, c: float) -> float:\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(NumbaPendingDeprecationWarning(msg, loc=loc))\n",
      "f:\\Anaconda\\Anaconda\\envs\\MFEA\\lib\\site-packages\\numba\\core\\ir_utils.py:2147: NumbaPendingDeprecationWarning: \u001b[1m\n",
      "Encountered the use of a type that is scheduled for deprecation: type 'reflected list' found for argument 's_rmp' of function 'model._updateRMP'.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-reflection-for-list-and-set-types\n",
      "\u001b[1m\n",
      "File \"C:\\Users\\Acer\\AppData\\Local\\Temp\\ipykernel_16676\\2371826582.py\", line 342:\u001b[0m\n",
      "\u001b[1m    @jit(nopython = True, parallel = True, cache= True)\n",
      "\u001b[1m    def _updateRMP(delta: List, s_rmp: List, c: float) -> float:\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(NumbaPendingDeprecationWarning(msg, loc=loc))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: None -- Time: 00m 8.90s    0 % [>                   ]  Pop_size: 9.90E+02  ,  Cost: 8.79E+04  2.52E+05  2.30E+05  2.92E+01  2.45E+09  2.13E+01  7.99E+01  1.64E+04  5.65E+01  5.82E+04  ,  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Anaconda\\Anaconda\\envs\\MFEA\\lib\\site-packages\\numba\\core\\ir_utils.py:2147: NumbaPendingDeprecationWarning: \u001b[1m\n",
      "Encountered the use of a type that is scheduled for deprecation: type 'reflected list' found for argument 'consume_fes' of function 'LearningPhase.updateOperator'.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-reflection-for-list-and-set-types\n",
      "\u001b[1m\n",
      "File \"C:\\Users\\Acer\\AppData\\Local\\Temp\\ipykernel_16676\\2371826582.py\", line 521:\u001b[0m\n",
      "\u001b[1m    @jit(nopython = True, parallel = True)\n",
      "\u001b[1m    def updateOperator(sum_improve: List, consume_fes: List, M: int) -> int:\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(NumbaPendingDeprecationWarning(msg, loc=loc))\n",
      "f:\\Anaconda\\Anaconda\\envs\\MFEA\\lib\\site-packages\\numba\\core\\ir_utils.py:2147: NumbaPendingDeprecationWarning: \u001b[1m\n",
      "Encountered the use of a type that is scheduled for deprecation: type 'reflected list' found for argument 'sum_improve' of function 'LearningPhase.updateOperator'.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-reflection-for-list-and-set-types\n",
      "\u001b[1m\n",
      "File \"C:\\Users\\Acer\\AppData\\Local\\Temp\\ipykernel_16676\\2371826582.py\", line 521:\u001b[0m\n",
      "\u001b[1m    @jit(nopython = True, parallel = True)\n",
      "\u001b[1m    def updateOperator(sum_improve: List, consume_fes: List, M: int) -> int:\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(NumbaPendingDeprecationWarning(msg, loc=loc))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: None -- Time: 03m 1.69s   99 % [===================>]  Pop_size: 2.00E+02  ,  Cost: 0.00E+00  1.29E-26  0.00E+00  0.00E+00  1.27E-25  4.31E-14  0.00E+00  6.36E-04  0.00E+00  2.59E+01  ,   \n",
      "END!\n",
      "Seed: None -- Time: 03m 3.37s  100 % [====================>]  Pop_size: 2.00E+02  ,  Cost: 0.00E+00  1.13E-26  0.00E+00  0.00E+00  1.06E-25  4.31E-14  0.00E+00  6.36E-04  0.00E+00  2.59E+01  ,  "
     ]
    }
   ],
   "source": [
    "baseModel = model()\n",
    "# from pyMSOO.MFEA.model import EME_BI\n",
    "# baseModel = EME_BI.model()\n",
    "baseModel.compile(\n",
    "    IndClass= IndClass,\n",
    "    tasks= tasks,\n",
    "    # crossover = KL_SBXCrossover(nc= 2, k= 100, conf_thres= 1),\n",
    "    crossover= SBX_Crossover(nc = 2),\n",
    "    mutation= PolynomialMutation(nm = 5),\n",
    "    selection= ElitismSelection(),\n",
    "    # dimension_strategy= DimensionAwareStrategy.DaS_strategy()\n",
    ")\n",
    "solve = baseModel.fit(\n",
    "    nb_generations = 1000, nb_inds_each_task= 100, \n",
    "    bound_pop= [0, 1], evaluate_initial_skillFactor= True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(baseModel.population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[100000,\n",
       " 100000,\n",
       " 100000,\n",
       " 100000,\n",
       " 100000,\n",
       " 100000,\n",
       " 100000,\n",
       " 100000,\n",
       " 100000,\n",
       " 100000]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseModel.eval_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 1, 0, 0, 1, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "print([lp.best_opcode for lp in baseModel.learningPhase])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: None -- Time: 00m 1.96s    0 % [>                   ]  Pop_size: 9.90E+02  ,  Cost: 1.02E+05  2.32E+05  2.40E+05  3.47E+01  2.87E+09  2.13E+01  7.91E+01  1.56E+04  5.74E+01  6.42E+04  ,  "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 11\u001b[0m\n\u001b[0;32m      1\u001b[0m baseModel \u001b[39m=\u001b[39m model()\n\u001b[0;32m      2\u001b[0m baseModel\u001b[39m.\u001b[39mcompile(\n\u001b[0;32m      3\u001b[0m     IndClass\u001b[39m=\u001b[39m IndClass,\n\u001b[0;32m      4\u001b[0m     tasks\u001b[39m=\u001b[39m tasks,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m     dimension_strategy\u001b[39m=\u001b[39m DaS_strategy()\n\u001b[0;32m     10\u001b[0m )\n\u001b[1;32m---> 11\u001b[0m solve \u001b[39m=\u001b[39m baseModel\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m     12\u001b[0m     nb_generations \u001b[39m=\u001b[39;49m \u001b[39m1000\u001b[39;49m, nb_inds_each_task\u001b[39m=\u001b[39;49m \u001b[39m100\u001b[39;49m, \n\u001b[0;32m     13\u001b[0m     bound_pop\u001b[39m=\u001b[39;49m [\u001b[39m0\u001b[39;49m, \u001b[39m1\u001b[39;49m], evaluate_initial_skillFactor\u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m\n\u001b[0;32m     14\u001b[0m )\n",
      "Cell \u001b[1;32mIn[34], line 117\u001b[0m, in \u001b[0;36mmodel.fit\u001b[1;34m(self, nb_generations, nb_inds_each_task, nb_inds_max, nb_inds_min, evaluate_initial_skillFactor, c, *args, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdimension_strategy\u001b[39m.\u001b[39mupdate(population \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpopulation)\n\u001b[0;32m    112\u001b[0m     \u001b[39m# start = time.time()\u001b[39;00m\n\u001b[0;32m    113\u001b[0m     \u001b[39m# self.updateRMP(c)\u001b[39;00m\n\u001b[0;32m    114\u001b[0m     \u001b[39m# end = time.time()\u001b[39;00m\n\u001b[0;32m    115\u001b[0m     \u001b[39m# print(\"G: \", end - start)\u001b[39;00m\n\u001b[0;32m    116\u001b[0m     \u001b[39m# start = time.time()\u001b[39;00m\n\u001b[1;32m--> 117\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mphaseTwo(D0)\n\u001b[0;32m    118\u001b[0m     \u001b[39m# end = time.time()\u001b[39;00m\n\u001b[0;32m    119\u001b[0m     \u001b[39m# print(\"G: \", end - start)\u001b[39;00m\n\u001b[0;32m    120\u001b[0m \u001b[39m# self.phaseTwo(D0)\u001b[39;00m\n\u001b[0;32m    121\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mEND!\u001b[39m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[34], line 282\u001b[0m, in \u001b[0;36mmodel.phaseTwo\u001b[1;34m(self, D0)\u001b[0m\n\u001b[0;32m    280\u001b[0m \u001b[39m# start = time.time()\u001b[39;00m\n\u001b[0;32m    281\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtasks)):\n\u001b[1;32m--> 282\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meval_k[i] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlearningPhase[i]\u001b[39m.\u001b[39;49mevolve(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpopulation[i], nextPop, sigma[i], maxDelta[i])\n\u001b[0;32m    283\u001b[0m \u001b[39m# end = time.time()\u001b[39;00m\n\u001b[0;32m    284\u001b[0m \u001b[39m# print(\"B: \", end - start)\u001b[39;00m\n\u001b[0;32m    285\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpopulation \u001b[39m=\u001b[39m nextPop\n",
      "Cell \u001b[1;32mIn[34], line 404\u001b[0m, in \u001b[0;36mLearningPhase.evolve\u001b[1;34m(self, subPop, nextPop, sigma, max_delta)\u001b[0m\n\u001b[0;32m    400\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconsume_fes[opcode] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    402\u001b[0m \u001b[39mif\u001b[39;00m opcode \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    403\u001b[0m     \u001b[39m# start = time.time()\u001b[39;00m\n\u001b[1;32m--> 404\u001b[0m     child \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msearcher[opcode](ind, subPop, pbest, cr, f)\n\u001b[0;32m    405\u001b[0m     \u001b[39m# end = time.time()\u001b[39;00m\n\u001b[0;32m    406\u001b[0m     \u001b[39m# print(\"C: \", end - start)\u001b[39;00m\n\u001b[0;32m    407\u001b[0m \u001b[39melif\u001b[39;00m opcode \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    408\u001b[0m     \u001b[39m# start = time.time()\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[34], line 457\u001b[0m, in \u001b[0;36mLearningPhase.pbest1\u001b[1;34m(self, ind, subPop, best, cr, f)\u001b[0m\n\u001b[0;32m    448\u001b[0m     u[numba_randomchoice(subPop\u001b[39m.\u001b[39mdim)] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    450\u001b[0m \u001b[39m# new_genes = np.where(u, \u001b[39;00m\n\u001b[0;32m    451\u001b[0m \u001b[39m#     pbest.genes + f * (ind_ran1.genes - ind_ran2.genes),\u001b[39;00m\n\u001b[0;32m    452\u001b[0m \u001b[39m#     ind.genes\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \u001b[39m# )\u001b[39;00m\n\u001b[0;32m    454\u001b[0m \u001b[39m# # new_genes = np.clip(new_genes, ind.genes/2, (ind.genes + 1)/2)\u001b[39;00m\n\u001b[0;32m    455\u001b[0m \u001b[39m# new_genes = np.where(new_genes < 0, ind.genes/2, np.where(new_genes > 1, (ind.genes + 1)/2, new_genes))\u001b[39;00m\n\u001b[1;32m--> 457\u001b[0m new_genes \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__class__\u001b[39;49m\u001b[39m.\u001b[39;49mproduce_inds(ind\u001b[39m.\u001b[39;49mgenes, pbest\u001b[39m.\u001b[39;49mgenes, ind_ran1\u001b[39m.\u001b[39;49mgenes, ind_ran2\u001b[39m.\u001b[39;49mgenes, f, u)\n\u001b[0;32m    458\u001b[0m new_ind \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mIndClass(new_genes)\n\u001b[0;32m    460\u001b[0m \u001b[39mreturn\u001b[39;00m new_ind\n",
      "File \u001b[1;32mf:\\Anaconda\\Anaconda\\envs\\MFEA\\lib\\site-packages\\numba\\core\\serialize.py:29\u001b[0m, in \u001b[0;36m_numba_unpickle\u001b[1;34m(address, bytedata, hashed)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[39m# Keep unpickled object via `numba_unpickle` alive.\u001b[39;00m\n\u001b[0;32m     26\u001b[0m _unpickled_memo \u001b[39m=\u001b[39m {}\n\u001b[1;32m---> 29\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_numba_unpickle\u001b[39m(address, bytedata, hashed):\n\u001b[0;32m     30\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Used by `numba_unpickle` from _helperlib.c\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \n\u001b[0;32m     32\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[39m        unpickled object\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m     43\u001b[0m     key \u001b[39m=\u001b[39m (address, hashed)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "baseModel = model()\n",
    "baseModel.compile(\n",
    "    IndClass= IndClass,\n",
    "    tasks= tasks,\n",
    "    # crossover = KL_SBXCrossover(nc= 2, k= 100, conf_thres= 1),\n",
    "    crossover= SBX_Crossover(nc = 2),\n",
    "    mutation= PolynomialMutation(nm = 5),\n",
    "    selection= ElitismSelection(),\n",
    "    dimension_strategy= DaS_strategy()\n",
    ")\n",
    "solve = baseModel.fit(\n",
    "    nb_generations = 1000, nb_inds_each_task= 100, \n",
    "    bound_pop= [0, 1], evaluate_initial_skillFactor= True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r\"F:\\BTVN\\DSAI\\Optimization Lab\\Paper\\Efficient knowledge transfer\\history_cost_summaries_EME_BI_woDaS.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>EME-BI</th>\n",
       "      <th>EME_BI_wo_DaS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>450</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.649250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>451</td>\n",
       "      <td>153.862380</td>\n",
       "      <td>140.877084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>452</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>453</td>\n",
       "      <td>10.890937</td>\n",
       "      <td>23.687499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>454</td>\n",
       "      <td>5022.383910</td>\n",
       "      <td>6610.532774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>455</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.183991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>456</td>\n",
       "      <td>112.875490</td>\n",
       "      <td>159.721696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>457</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>458</td>\n",
       "      <td>12.390112</td>\n",
       "      <td>21.295734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>459</td>\n",
       "      <td>4979.867545</td>\n",
       "      <td>6728.074941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>460</td>\n",
       "      <td>0.029993</td>\n",
       "      <td>16.883884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>461</td>\n",
       "      <td>128.012455</td>\n",
       "      <td>158.884861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>462</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>463</td>\n",
       "      <td>12.684814</td>\n",
       "      <td>21.087148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>464</td>\n",
       "      <td>5050.060552</td>\n",
       "      <td>5754.026860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>465</td>\n",
       "      <td>2.065367</td>\n",
       "      <td>15.545684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>466</td>\n",
       "      <td>136.240922</td>\n",
       "      <td>152.131004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>467</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>468</td>\n",
       "      <td>13.519725</td>\n",
       "      <td>20.299626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>469</td>\n",
       "      <td>4481.177414</td>\n",
       "      <td>6285.306503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>470</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.651320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>471</td>\n",
       "      <td>134.383059</td>\n",
       "      <td>162.881150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>472</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>473</td>\n",
       "      <td>9.980170</td>\n",
       "      <td>19.615759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>474</td>\n",
       "      <td>4404.093869</td>\n",
       "      <td>5303.187592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>475</td>\n",
       "      <td>0.685091</td>\n",
       "      <td>9.460654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>476</td>\n",
       "      <td>132.202483</td>\n",
       "      <td>166.484685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>477</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>478</td>\n",
       "      <td>11.444059</td>\n",
       "      <td>20.868381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>479</td>\n",
       "      <td>4755.577797</td>\n",
       "      <td>6082.033661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>480</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.058803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>481</td>\n",
       "      <td>152.043308</td>\n",
       "      <td>159.299178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>482</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>483</td>\n",
       "      <td>11.106148</td>\n",
       "      <td>24.428280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>484</td>\n",
       "      <td>4991.372559</td>\n",
       "      <td>6248.724829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>485</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.896160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>486</td>\n",
       "      <td>136.426152</td>\n",
       "      <td>169.301769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>487</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>488</td>\n",
       "      <td>10.483358</td>\n",
       "      <td>23.299838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>489</td>\n",
       "      <td>5397.686649</td>\n",
       "      <td>6405.145432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>490</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.494818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>491</td>\n",
       "      <td>147.769146</td>\n",
       "      <td>143.050375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>492</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.000493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>493</td>\n",
       "      <td>10.471335</td>\n",
       "      <td>20.319466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>494</td>\n",
       "      <td>5181.970735</td>\n",
       "      <td>6202.968885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>495</td>\n",
       "      <td>0.686529</td>\n",
       "      <td>15.653057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>496</td>\n",
       "      <td>113.118472</td>\n",
       "      <td>179.197397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>497</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>498</td>\n",
       "      <td>10.452321</td>\n",
       "      <td>21.174398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>499</td>\n",
       "      <td>4659.249712</td>\n",
       "      <td>5410.368813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0       EME-BI  EME_BI_wo_DaS\n",
       "450         450     0.000000       0.649250\n",
       "451         451   153.862380     140.877084\n",
       "452         452     0.000000       0.000329\n",
       "453         453    10.890937      23.687499\n",
       "454         454  5022.383910    6610.532774\n",
       "455         455     0.000000       8.183991\n",
       "456         456   112.875490     159.721696\n",
       "457         457     0.000000       0.000000\n",
       "458         458    12.390112      21.295734\n",
       "459         459  4979.867545    6728.074941\n",
       "460         460     0.029993      16.883884\n",
       "461         461   128.012455     158.884861\n",
       "462         462     0.000000       0.000904\n",
       "463         463    12.684814      21.087148\n",
       "464         464  5050.060552    5754.026860\n",
       "465         465     2.065367      15.545684\n",
       "466         466   136.240922     152.131004\n",
       "467         467     0.000000       0.000000\n",
       "468         468    13.519725      20.299626\n",
       "469         469  4481.177414    6285.306503\n",
       "470         470     0.000000       0.651320\n",
       "471         471   134.383059     162.881150\n",
       "472         472     0.000000       0.000247\n",
       "473         473     9.980170      19.615759\n",
       "474         474  4404.093869    5303.187592\n",
       "475         475     0.685091       9.460654\n",
       "476         476   132.202483     166.484685\n",
       "477         477     0.000000       0.000000\n",
       "478         478    11.444059      20.868381\n",
       "479         479  4755.577797    6082.033661\n",
       "480         480     0.000000       4.058803\n",
       "481         481   152.043308     159.299178\n",
       "482         482     0.000000       0.000493\n",
       "483         483    11.106148      24.428280\n",
       "484         484  4991.372559    6248.724829\n",
       "485         485     0.000000      10.896160\n",
       "486         486   136.426152     169.301769\n",
       "487         487     0.000000       0.000000\n",
       "488         488    10.483358      23.299838\n",
       "489         489  5397.686649    6405.145432\n",
       "490         490     0.000000      11.494818\n",
       "491         491   147.769146     143.050375\n",
       "492         492     0.000247       0.000493\n",
       "493         493    10.471335      20.319466\n",
       "494         494  5181.970735    6202.968885\n",
       "495         495     0.686529      15.653057\n",
       "496         496   113.118472     179.197397\n",
       "497         497     0.000000       0.000000\n",
       "498         498    10.452321      21.174398\n",
       "499         499  4659.249712    5410.368813"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyMSOO.MFEA.model import EME_BI\n",
    "\n",
    "# ls_benchmark = []\n",
    "# ls_IndClass = []\n",
    "# name_benchmark = []\n",
    "# ls_tasks = [10]\n",
    "\n",
    "# for i in ls_tasks:\n",
    "#     # t, ic = WCCI22_benchmark.get_complex_benchmark(i)\n",
    "#     t, ic = WCCI22_benchmark.get_50tasks_benchmark(i)\n",
    "#     ls_benchmark.append(t)\n",
    "#     ls_IndClass.append(ic)\n",
    "#     name_benchmark.append(str(i))\n",
    "\n",
    "\n",
    "\n",
    "# smpModel = MultiBenchmark(\n",
    "#     ls_benchmark= ls_benchmark,\n",
    "#     name_benchmark= name_benchmark,\n",
    "#     ls_IndClass= ls_IndClass,\n",
    "#     model= EME_BI\n",
    "# )\n",
    "\n",
    "# smpModel.compile(\n",
    "#     crossover= SBX_Crossover(nc = 2),\n",
    "#     mutation= PolynomialMutation(nm = 5),\n",
    "#     selection= ElitismSelection(),\n",
    "#     # dimension_strategy = DaS_strategy(eta = 3)\n",
    "# )\n",
    "# smpModel.fit(\n",
    "#     nb_generations = 1000,nb_inds_each_task= 100, \n",
    "#     bound_pop= [0, 1], evaluate_initial_skillFactor= True\n",
    "# )\n",
    "# a = smpModel.run(\n",
    "#     nb_run= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: None -- Time: 17m 35.56s   99 % [===================>]  Pop_size: 1.00E+03  ,  Cost: 1.19E+02  2.10E-09  1.20E+02  1.30E-12  5.64E+00  5.12E+03  4.82E+01  1.50E-13  1.02E+02  1.32E-11  1.19E+00  7.38E+03  4.68E+01  5.67E-10  1.15E+02  2.40E-11  8.62E+00  5.41E+03  3.09E+02  2.00E+01  9.74E+01  2.33E-11  2.35E+00  7.70E+03  4.72E+01  2.87E-12  1.00E+02  6.92E-11  6.37E+00  6.32E+03  4.75E+01  7.57E-11  1.59E+02  2.75E-10  5.51E+00  6.43E+03  4.87E+01  2.00E+01  1.35E+02  9.94E-11  6.38E-01  5.05E+03  4.69E+01  3.89E-11  1.24E+02  1.14E-11  1.82E+00  5.44E+03  4.86E+01  2.01E+01  ,  \n",
      "END!\n",
      "Seed: None -- Time: 17m 46.01s  100 % [====================>]  Pop_size: 1.00E+03  ,  Cost: 1.19E+02  2.10E-09  1.19E+02  1.01E-12  5.64E+00  5.12E+03  4.82E+01  7.86E-14  1.01E+02  1.11E-11  1.19E+00  7.38E+03  4.68E+01  5.67E-10  1.14E+02  2.20E-11  8.62E+00  5.41E+03  3.09E+02  2.00E+01  8.93E+01  2.31E-11  2.35E+00  7.70E+03  4.72E+01  2.57E-12  9.23E+01  6.73E-11  6.37E+00  6.32E+03  4.75E+01  7.55E-11  1.41E+02  2.72E-10  5.51E+00  6.43E+03  4.87E+01  2.00E+01  1.32E+02  9.83E-11  6.38E-01  5.05E+03  4.69E+01  3.82E-11  1.20E+02  1.08E-11  1.82E+00  5.44E+03  4.86E+01  2.01E+01  ,  "
     ]
    }
   ],
   "source": [
    "res = []\n",
    "# for i in range(1, 11):\n",
    "t, ic = WCCI22_benchmark.get_50tasks_benchmark(9)\n",
    "baseModel = model()\n",
    "baseModel.compile(\n",
    "    IndClass= ic,\n",
    "    tasks= t,\n",
    "    # crossover = KL_SBXCrossover(nc= 2, k= 100, conf_thres= 1),\n",
    "    crossover= SBX_Crossover(nc = 2),\n",
    "    mutation= PolynomialMutation(nm = 5),\n",
    "    selection= ElitismSelection(),\n",
    "    # dimension_strategy= DaS_strategy()\n",
    ")\n",
    "solve = baseModel.fit(\n",
    "    nb_generations = 1000, nb_inds_each_task= 100, \n",
    "    bound_pop= [0, 1], evaluate_initial_skillFactor= True\n",
    ")\n",
    "\n",
    "# res.append([subpop.getSolveInd().fcost for subpop in baseModel.last_pop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = np.array([subpop.getSolveInd().fcost for subpop in baseModel.last_pop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = np.where(h < 1e-6, 0, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.19332709e+02 0.00000000e+00 1.18894573e+02 0.00000000e+00\n",
      " 5.63568780e+00 5.12286024e+03 4.81605226e+01 0.00000000e+00\n",
      " 1.01421384e+02 0.00000000e+00 1.18984303e+00 7.37960500e+03\n",
      " 4.68279935e+01 0.00000000e+00 1.13625382e+02 0.00000000e+00\n",
      " 8.61583492e+00 5.40961486e+03 3.08511018e+02 1.99848761e+01\n",
      " 8.92349306e+01 0.00000000e+00 2.35393013e+00 7.70491790e+03\n",
      " 4.72076715e+01 0.00000000e+00 9.22279775e+01 0.00000000e+00\n",
      " 6.36707861e+00 6.31764802e+03 4.74683764e+01 0.00000000e+00\n",
      " 1.40387984e+02 0.00000000e+00 5.50802877e+00 6.43279297e+03\n",
      " 4.87159261e+01 1.99722336e+01 1.32008821e+02 0.00000000e+00\n",
      " 6.38473375e-01 5.05431253e+03 4.68672370e+01 0.00000000e+00\n",
      " 1.20272996e+02 0.00000000e+00 1.82315689e+00 5.43768031e+03\n",
      " 4.86259257e+01 2.01062843e+01]\n",
      "[1345.2809961     0.          136.0607488     0.           11.06903917\n",
      " 4493.66155547  295.07901483    0.          132.30275237    0.\n",
      "   12.30391307 4708.67148357  330.7125527     0.          135.2337131\n",
      "    0.           10.8210762  4915.05272457  183.89925843    0.\n",
      "  130.11333477    0.            9.67409147 4295.43882953  638.21655467\n",
      "    0.          168.9823331     0.           10.3730895  5002.4439091\n",
      "  617.3609172     0.          123.6474079     0.           12.52441737\n",
      " 5270.103723    326.2771332     0.          154.46799967    0.\n",
      "   10.2473199  4346.1903906   352.87033697    0.          158.34564103\n",
      "    0.           11.40139753 5028.6126043   129.56774643    0.        ]\n"
     ]
    }
   ],
   "source": [
    "print(h)\n",
    "print(np.array(df[\"EME-BI\"][-100:-50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(h > df[\"EME-BI\"][-100:-50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(h < df[\"EME-BI\"][-100:-50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: None -- Time: 17m 48.00s   99 % [===================>]  Pop_size: 1.00E+03  ,  Cost: 4.68E+01  2.00E+01  1.10E+02  1.54E-11  6.19E+00  5.77E+03  4.52E+01  2.74E-12  1.13E+02  4.55E-12  7.42E-01  7.80E+03  4.91E+01  8.32E-11  3.60E+02  5.27E-11  8.93E+00  5.69E+03  4.92E+01  9.21E-13  9.39E+01  4.23E-12  1.71E+01  6.13E+03  4.51E+01  2.00E+01  9.10E+01  1.14E-10  1.13E+00  6.45E+03  1.63E+02  2.00E+01  8.21E+01  3.18E-10  9.70E+00  5.61E+03  3.31E+02  1.81E-11  1.97E+02  1.12E-11  3.07E+00  3.77E+03  4.56E+01  2.00E+01  1.05E+02  2.96E-12  2.05E+00  6.29E+03  1.43E+02  1.60E-10  ,  \n",
      "END!\n",
      "Seed: None -- Time: 17m 58.19s  100 % [====================>]  Pop_size: 1.00E+03  ,  Cost: 4.68E+01  2.00E+01  1.03E+02  1.39E-11  6.19E+00  5.77E+03  4.52E+01  1.20E-12  1.13E+02  4.29E-12  7.42E-01  7.80E+03  4.91E+01  7.97E-11  3.28E+02  5.24E-11  8.93E+00  5.69E+03  4.92E+01  7.61E-13  8.97E+01  3.84E-12  1.71E+01  6.13E+03  4.51E+01  2.00E+01  8.64E+01  1.11E-10  1.13E+00  6.45E+03  1.63E+02  2.00E+01  8.19E+01  3.18E-10  9.70E+00  5.61E+03  3.23E+02  1.71E-11  1.96E+02  1.06E-11  3.07E+00  3.77E+03  4.56E+01  2.00E+01  1.05E+02  2.63E-12  2.05E+00  6.29E+03  1.43E+02  1.60E-10  ,  "
     ]
    }
   ],
   "source": [
    "res = []\n",
    "# for i in range(1, 11):\n",
    "t, ic = WCCI22_benchmark.get_50tasks_benchmark(9)\n",
    "baseModel = model()\n",
    "baseModel.compile(\n",
    "    IndClass= ic,\n",
    "    tasks= t,\n",
    "    # crossover = KL_SBXCrossover(nc= 2, k= 100, conf_thres= 1),\n",
    "    crossover= SBX_Crossover(nc = 2),\n",
    "    mutation= PolynomialMutation(nm = 5),\n",
    "    selection= ElitismSelection(),\n",
    "    dimension_strategy= DaS_strategy()\n",
    ")\n",
    "solve = baseModel.fit(\n",
    "    nb_generations = 1000, nb_inds_each_task= 100, \n",
    "    bound_pop= [0, 1], evaluate_initial_skillFactor= True\n",
    ")\n",
    "\n",
    "# res.append([subpop.getSolveInd().fcost for subpop in baseModel.last_pop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = np.array([subpop.getSolveInd().fcost for subpop in baseModel.last_pop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = np.where(f < 1e-6, 0, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.68003042e+01 1.99663587e+01 1.03113956e+02 0.00000000e+00\n",
      " 6.19448226e+00 5.76956100e+03 4.52351287e+01 0.00000000e+00\n",
      " 1.12963484e+02 0.00000000e+00 7.41577009e-01 7.80272560e+03\n",
      " 4.91021492e+01 0.00000000e+00 3.24258332e+02 0.00000000e+00\n",
      " 8.92674103e+00 5.69427436e+03 4.91778275e+01 0.00000000e+00\n",
      " 8.97199871e+01 0.00000000e+00 1.71331118e+01 6.12955815e+03\n",
      " 4.51297589e+01 1.99613433e+01 8.63315608e+01 0.00000000e+00\n",
      " 1.12805856e+00 6.45339352e+03 1.62864812e+02 1.99926680e+01\n",
      " 8.19327505e+01 0.00000000e+00 9.70125321e+00 5.60552946e+03\n",
      " 3.22637544e+02 0.00000000e+00 1.95727540e+02 0.00000000e+00\n",
      " 3.06602228e+00 3.77352536e+03 4.56151967e+01 2.00148003e+01\n",
      " 1.05114663e+02 0.00000000e+00 2.04655754e+00 6.29422535e+03\n",
      " 1.43124317e+02 0.00000000e+00]\n",
      "[1345.2809961     0.          136.0607488     0.           11.06903917\n",
      " 4493.66155547  295.07901483    0.          132.30275237    0.\n",
      "   12.30391307 4708.67148357  330.7125527     0.          135.2337131\n",
      "    0.           10.8210762  4915.05272457  183.89925843    0.\n",
      "  130.11333477    0.            9.67409147 4295.43882953  638.21655467\n",
      "    0.          168.9823331     0.           10.3730895  5002.4439091\n",
      "  617.3609172     0.          123.6474079     0.           12.52441737\n",
      " 5270.103723    326.2771332     0.          154.46799967    0.\n",
      "   10.2473199  4346.1903906   352.87033697    0.          158.34564103\n",
      "    0.           11.40139753 5028.6126043   129.56774643    0.        ]\n"
     ]
    }
   ],
   "source": [
    "print(f)\n",
    "print(np.array(df[\"EME-BI\"][400:450]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(f < df[\"EME-BI\"][400:450])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(f > df[\"EME-BI\"][400:450])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(h < f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(h > f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(f < df[\"EME_BI_wo_DaS\"][-50:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df[\"EME_BI_wo_DaS\"][-50:] < df[\"EME-BI\"][-50:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df[\"EME_BI_wo_DaS\"][-50:] > df[\"EME-BI\"][-50:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MFEA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
