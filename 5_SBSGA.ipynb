{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyMSOO.MFEA.model import SBSGA\n",
    "from pyMSOO.utils.Crossover import *\n",
    "from pyMSOO.utils.Mutation import *\n",
    "from pyMSOO.utils.Selection import *\n",
    "from pyMSOO.utils.DimensionAwareStrategy import *\n",
    "from pyMSOO.MFEA.benchmark.continous import *\n",
    "from pyMSOO.utils.MultiRun.RunMultiTime import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from functools import reduce\n",
    "import numba as nb\n",
    "import copy\n",
    "\n",
    "from pyMSOO.MFEA.model import AbstractModel\n",
    "from pyMSOO.utils import Crossover, Mutation, Selection, DimensionAwareStrategy\n",
    "from pyMSOO.utils.EA import *\n",
    "from pyMSOO.utils.numba_utils import numba_randomchoice\n",
    "\n",
    "class model(AbstractModel.model):\n",
    "    def compile(self, \n",
    "        IndClass: Type[Individual],\n",
    "        tasks: List[AbstractTask], \n",
    "        crossover: Crossover.SBX_Crossover, \n",
    "        mutation: Mutation.PolynomialMutation, \n",
    "        selection: Selection.ElitismSelection,\n",
    "        dimension_strategy: DimensionAwareStrategy.AbstractDaS = DimensionAwareStrategy.NoDaS(),\n",
    "        *args, **kwargs):\n",
    "        super().compile(IndClass, tasks, crossover, mutation,dimension_strategy, selection, *args, **kwargs)\n",
    "    \n",
    "    def fit(self, nb_generations, B = 0.25, H = 0.5, nb_inds_each_task = 100, evaluate_initial_skillFactor = True, *args, **kwargs) -> List[Individual]:\n",
    "        super().fit(*args, **kwargs)\n",
    "\n",
    "        # initialize population\n",
    "        self.population = Population(\n",
    "            self.IndClass,\n",
    "            nb_inds_tasks = [nb_inds_each_task] * len(self.tasks), \n",
    "            dim = self.dim_uss,\n",
    "            list_tasks= self.tasks,\n",
    "            evaluate_initial_skillFactor = evaluate_initial_skillFactor\n",
    "        )\n",
    "        self.B = B\n",
    "        self.H = H\n",
    "\n",
    "        self.M = np.ones((len(self.tasks), len(self.tasks)))\n",
    "        self.N = np.ones((len(self.tasks), len(self.tasks)))\n",
    "        self.C = np.ones((len(self.tasks), len(self.tasks)))\n",
    "        self.O = np.ones((len(self.tasks), len(self.tasks)))\n",
    "        self.P = np.ones((len(self.tasks), len(self.tasks)))\n",
    "        self.A = np.ones((len(self.tasks), len(self.tasks)))\n",
    "        self.R = np.ones((len(self.tasks), len(self.tasks)))\n",
    "        \n",
    "        # save history\n",
    "        self.history_cost.append([ind.fcost for ind in self.population.get_solves()])\n",
    "        \n",
    "        self.render_process(0, ['Cost'], [self.history_cost[-1]], use_sys= True)\n",
    "\n",
    "        for epoch in range(nb_generations):\n",
    "\n",
    "            offsprings = Population(\n",
    "                self.IndClass,\n",
    "                nb_inds_tasks = [0] * len(self.tasks), \n",
    "                dim = self.dim_uss,\n",
    "                list_tasks= self.tasks,\n",
    "            )\n",
    "\n",
    "            copy_offsprings = Population(\n",
    "                self.IndClass,\n",
    "                nb_inds_tasks = [0] * len(self.tasks), \n",
    "                dim = self.dim_uss,\n",
    "                list_tasks= self.tasks,\n",
    "            )\n",
    "\n",
    "            subPop = [0] * len(self.tasks)\n",
    "            other_task = [0] * len(self.tasks)\n",
    "\n",
    "            # Generate offsprings\n",
    "            for i in range(len(self.tasks)):\n",
    "                offs = Population(\n",
    "                    self.IndClass,\n",
    "                    nb_inds_tasks = [0] * len(self.tasks), \n",
    "                    dim = self.dim_uss,\n",
    "                    list_tasks= self.tasks,\n",
    "                )\n",
    "                while len(offs) < nb_inds_each_task:\n",
    "                    # choose parent \n",
    "                    pa, pb = self.population[i].__getRandomItems__(2)\n",
    "                    # intra crossover\n",
    "                    oa, ob = self.crossover(pa, pb, i, i)\n",
    "                    # mutate\n",
    "                    oa = self.mutation(oa, return_newInd= True)\n",
    "                    oa.skill_factor = pa.skill_factor\n",
    "\n",
    "                    ob = self.mutation(ob, return_newInd= True)    \n",
    "                    ob.skill_factor = pb.skill_factor\n",
    "                    \n",
    "                    offs.__addIndividual__(oa)\n",
    "                    offs.__addIndividual__(ob)\n",
    "\n",
    "                offsprings += offs\n",
    "                copy_offsprings += offs\n",
    "            \n",
    "            # Inter task\n",
    "\n",
    "            # np.fill_diagonal(self.R, -1)\n",
    "            # R_i = np.max(self.R, axis = 1)\n",
    "            # task_i = list(np.where(np.random.rand() < R_i)[0])\n",
    "            # task_j = list(np.argmax(self.R[task_i], axis = 1))\n",
    "            # # S_i = np.min(np.max((R_i[t] * nb_inds_each_task).astype(int), 0), nb_inds_each_task)\n",
    "            # S_i = np.clip((R_i[task_i] * nb_inds_each_task).astype(int), 0, nb_inds_each_task)\n",
    "            # # print(task_j)\n",
    "            # # print(S_i)\n",
    "            # S_i = np.clip((R_i[task_i] * nb_inds_each_task).astype(int), 0, nb_inds_each_task)\n",
    "            # # subPop[t] = [self.IndClass(off.genes, skill_factor=i, fcost=t(off.genes)) for off in copy_offsprings[task_j][0: S_i]]\n",
    "            # # subPop = [[self.IndClass(off.genes, skill_factor=i, fcost=self.tasks[i](off.genes)) for off in copy_offsprings[i][0: S_i[i]]] for i in task_j]\n",
    "            # # offsprings[t][nb_inds_each_task - S_i: nb_inds_each_task] = subPop[t]\n",
    "            # for i, j in zip(task_i, task_j):\n",
    "            #     subPop[i] = [self.IndClass(off.genes, skill_factor=i, fcost=self.tasks[i](off.genes)) for off in copy_offsprings[j][0: S_i[i]]]\n",
    "            #     offsprings[i][nb_inds_each_task - S_i[i]: nb_inds_each_task] = subPop[i]\n",
    "            # offsprings.update_rank()\n",
    "            # copy_offsprings.update_rank()\n",
    "\n",
    "            for i, t in enumerate(self.tasks):\n",
    "                self.R[i][i] = -1\n",
    "                R_i = max(self.R[i])\n",
    "                if random.random() < R_i:\n",
    "                    \n",
    "                    task_j = np.argmax(self.R[i])\n",
    "                    S_i = min(max(int(R_i * nb_inds_each_task), 0), nb_inds_each_task)\n",
    "                    other_task[i] = task_j\n",
    "\n",
    "                    subPop[i] = [self.dimension_strategy(off, task_j, self.population[i].__getRandomItems__()) \n",
    "                                 for off in copy_offsprings[task_j][0: S_i]]\n",
    "                    subPop[i] = [self.IndClass(off.genes, skill_factor=i, fcost = t(off.genes)) for off in subPop[i]]\n",
    "                    \n",
    "                    offsprings[i][nb_inds_each_task - S_i: nb_inds_each_task] = subPop[i]\n",
    "                    \n",
    "                    # tmp = []\n",
    "                    # for k in np.where(copy_offsprings[task_j].factorial_rank <= S_i)[0]:\n",
    "                    #     off = copy_offsprings[task_j][k]\n",
    "                    #     tmp.append(self.dimension_strategy(off, task_j, self.population[i].__getRandomItems__()))\n",
    "                    \n",
    "                    # subPop[i] = tmp\n",
    "                    # # subPop[i] = [self.dimension_strategy(off, task_j, self.population[i].__getRandomItems__()) \n",
    "                    # #              for off in [copy_offsprings[task_j][k] for k in np.where(copy_offsprings[task_j].factorial_rank < S_i)[0]]]\n",
    "                    # subPop[i] = [self.IndClass(off.genes, skill_factor=i, fcost = t(off.genes)) for off in subPop[i]]\n",
    "                    \n",
    "                    # for idx ,k in enumerate(np.where(offsprings[i].factorial_rank > nb_inds_each_task - S_i)[0]):\n",
    "                    #     offsprings[i][k] = subPop[i][idx]\n",
    "\n",
    "            # merge and update rank\n",
    "            self.population = self.population + offsprings\n",
    "            self.population.update_rank()\n",
    "\n",
    "            # selection\n",
    "            self.selection(self.population, [nb_inds_each_task] * len(self.tasks))\n",
    "\n",
    "            # update symbiosis and rate\n",
    "            self.update_symbiosis(subPop, other_task)\n",
    "            # self.update_rate()\n",
    "            self.R = self.__class__.update_rate(self.M, self.O, self.P, self.A, self.C, len(self.tasks))\n",
    "\n",
    "            # update operators\n",
    "            self.crossover.update(population = self.population)\n",
    "            self.mutation.update(population = self.population)\n",
    "            self.dimension_strategy.update(population = self.population)\n",
    "\n",
    "            # save history\n",
    "            self.history_cost.append([ind.fcost for ind in self.population.get_solves()])\n",
    "\n",
    "            #print\n",
    "            self.render_process((epoch+1)/nb_generations, ['Cost'], [self.history_cost[-1]], use_sys= True)\n",
    "        \n",
    "        print('\\nEND!')\n",
    "\n",
    "        #solve \n",
    "        self.last_pop = self.population\n",
    "        return self.last_pop.get_solves()\n",
    "\n",
    "    # def update_rate(self):\n",
    "    #     for t in range(len(self.tasks)):\n",
    "    #         T_pos = self.M[t] + self.O[t] + self.P[t]\n",
    "    #         T_neg = self.A[t] + self.C[t]\n",
    "    #         T_neu = self.M[t]\n",
    "    #         self.R[t] = T_pos/(T_pos + T_neg + T_neu)\n",
    "    #         self.R[t][t] = -1\n",
    "\n",
    "    @jit(nopython = True)\n",
    "    def update_rate(M, O, P, A, C, nb_tasks):\n",
    "        R = np.zeros((nb_tasks, nb_tasks))\n",
    "        for t in range(nb_tasks):\n",
    "            T_pos = M[t] + O[t] + P[t]\n",
    "            T_neg = A[t] + C[t]\n",
    "            T_neu = M[t]\n",
    "            R[t] = T_pos/(T_pos + T_neg + T_neu)\n",
    "            R[t][t] = -1\n",
    "        return R\n",
    "\n",
    "    def update_symbiosis(self, subpop: List[Individual], other_task):\n",
    "        for i in range(len(self.tasks)):\n",
    "            if isinstance(subpop[i], list):\n",
    "                for o in subpop[i]:\n",
    "                    j = other_task[i]\n",
    "                    if i != j:\n",
    "                        r_i = self.rank(o, i)\n",
    "                        r_j = self.rank(o, j)\n",
    "                        # r_i = self.__class__.rank(self.tasks[i](o), nb.typed.List(self.population[i].getFitness()))\n",
    "                        # r_j = self.__class__.rank(self.tasks[j](o), nb.typed.List(self.population[j].getFitness()))\n",
    "                        if (self.isBenefit(r_i) and self.isBenefit(r_j)):\n",
    "                            self.M[i][j] += 1\n",
    "                        elif (self.isNeural(r_i) and self.isNeural(r_j)):\n",
    "                            self.N[i][j] += 1\n",
    "                        elif (self.isHarmful(r_i) and self.isHarmful(r_j)):\n",
    "                            self.C[i][j] += 1\n",
    "                        elif (self.isBenefit(r_i) and self.isNeural(r_j)):\n",
    "                            self.O[i][j] += 1\n",
    "                        elif (self.isBenefit(r_i) and self.isHarmful(r_j)): \n",
    "                            self.P[i][j] += 1\n",
    "                        elif (self.isNeural(r_i) and self.isHarmful(r_j)):\n",
    "                            self.A[i][j] += 1\n",
    "\n",
    "    def rank(self, off: Individual, task):\n",
    "        fitness = self.tasks[task](off)\n",
    "        rank = np.searchsorted(self.population[task].getFitness(), fitness)\n",
    "        return rank/len(self.population[task])\n",
    "    \n",
    "    # @jit(nopython = True)\n",
    "    # def rank(off_fitness, subPop_fitness):\n",
    "    #     # fitness = self.tasks[task](off)\n",
    "    #     # print(self.population[task].getFitness())\n",
    "    #     rank = np.searchsorted(subPop_fitness, off_fitness)\n",
    "    #     return rank/len(subPop_fitness)\n",
    "    \n",
    "    def isBenefit(self, r):\n",
    "        if (r <= self.B):\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def isHarmful(self, r) :\n",
    "        if (r > self.H) :\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def isNeural(self, r) :\n",
    "        return (r > self.B and r <= self.H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tasks, IndClass = CEC17_benchmark.get_2tasks_benchmark(1)\n",
    "# tasks, IndClass = WCCI22_benchmark.get_complex_benchmark(1)\n",
    "tasks, IndClass = CEC17_benchmark.get_10tasks_benchmark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: None -- Time: 01m 34.59s  100 % [====================>]  Cost: 3.50E-06  5.89E-07  1.39E-16  0.00E+00  4.68E-04  1.90E-04  5.47E-07  6.38E-04  6.84E-14  3.98E+00  ,  \n",
      "END!\n"
     ]
    }
   ],
   "source": [
    "baseModel = SBSGA.model()\n",
    "baseModel.compile(\n",
    "    IndClass= IndClass,\n",
    "    tasks= tasks,\n",
    "    # crossover = KL_SBXCrossover(nc= 2, k= 100, conf_thres= 1),\n",
    "    crossover= SBX_Crossover(nc = 2),\n",
    "    mutation= PolynomialMutation(nm = 5),\n",
    "    selection= ElitismSelection(),\n",
    "    dimension_strategy=DaS_strategy(eta= 3)\n",
    ")\n",
    "solve = baseModel.fit(\n",
    "    nb_generations = 1000, rmp = 0.5, nb_inds_each_task= 100, \n",
    "    bound_pop= [0, 1], evaluate_initial_skillFactor= True\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MUltitime Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseModel = MultiTimeModel(model= model)\n",
    "baseModel.compile(\n",
    "    IndClass= IndClass,\n",
    "    tasks= tasks,\n",
    "    # crossover = KL_SBXCrossover(nc= 2, k= 100, conf_thres= 1),\n",
    "    crossover= SBX_Crossover(nc = 2),\n",
    "    mutation= PolynomialMutation(nm = 5),\n",
    "    selection= ElitismSelection(),\n",
    "    dimension_strategy= NoDaS(),\n",
    ")\n",
    "solve = baseModel.fit(\n",
    "    nb_generations = 1000,nb_inds_each_task= 100, \n",
    "    bound_pop= [0, 1], evaluate_initial_skillFactor= True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 0 -- Time: 01m 21.29s  100 % [====================>]  Cost: 1.92E-06  2.73E-07  1.79E-10  0.00E+00  2.59E-04  1.66E-04  1.68E-03  6.39E-04  3.48E-08  1.67E+01  ,  \n",
      "END!\n",
      "Seed: 1 -- Time: 01m 17.42s  100 % [====================>]  Cost: 1.91E-06  2.89E-07  1.78E-08  0.00E+00  2.51E-04  1.72E-04  7.43E-03  6.38E-04  4.25E-08  2.11E+01  ,  \n",
      "END!\n",
      "Seed: 2 -- Time: 01m 18.05s  100 % [====================>]  Cost: 1.10E-06  2.70E-07  1.96E-10  0.00E+00  1.64E-04  1.48E-04  2.02E-03  6.38E-04  2.52E-08  3.47E+01  ,  \n",
      "END!\n",
      "Seed: 3 -- Time: 01m 21.33s  100 % [====================>]  Cost: 2.84E-06  3.02E-07  1.18E-10  0.00E+00  4.72E-04  1.69E-04  1.61E-03  6.38E-04  4.23E-08  2.30E+01  ,  \n",
      "END!\n",
      "Seed: 4 -- Time: 01m 13.80s   92 % [==================> ]  Cost: 9.49E-06  1.69E-06  4.16E-09  0.00E+00  1.12E-03  3.76E-04  3.97E-03  6.49E-04  9.89E-08  2.15E+01  ,  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\BTVN\\DSAI\\Optimization Lab\\pyMSOO\\pyMSOO\\utils\\MultiRun\\RunMultiTime.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  result = np.array(result[:][:min([len(his) for his in result])][:])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "functions : <generator object stream_list at 0x0000015A6ECA8900>, <class 'generator'> cannot saved in process_save_dict function\n",
      "attributes : <generator object stream_list at 0x0000015A6ECA8970>, <class 'generator'> cannot saved in process_save_dict function\n",
      "globals : <generator object stream_list at 0x0000015A6ECA89E0>, <class 'generator'> cannot saved in process_save_dict function\n",
      "functions : <generator object stream_list at 0x0000015A6ECA8A50>, <class 'generator'> cannot saved in process_save_dict function\n",
      "attributes : <generator object stream_list at 0x0000015A6ECA8AC0>, <class 'generator'> cannot saved in process_save_dict function\n",
      "globals : <generator object stream_list at 0x0000015A6ECA8B30>, <class 'generator'> cannot saved in process_save_dict function\n",
      "functions : <generator object stream_list at 0x0000015A6ECA8BA0>, <class 'generator'> cannot saved in process_save_dict function\n",
      "attributes : <generator object stream_list at 0x0000015A6ECA8C10>, <class 'generator'> cannot saved in process_save_dict function\n",
      "globals : <generator object stream_list at 0x0000015A6ECA8C80>, <class 'generator'> cannot saved in process_save_dict function\n",
      "functions : <generator object stream_list at 0x0000015A6ECA8CF0>, <class 'generator'> cannot saved in process_save_dict function\n",
      "attributes : <generator object stream_list at 0x0000015A6ECA8D60>, <class 'generator'> cannot saved in process_save_dict function\n",
      "globals : <generator object stream_list at 0x0000015A6ECA8DD0>, <class 'generator'> cannot saved in process_save_dict function\n",
      "functions : <generator object stream_list at 0x0000015A6ECA8E40>, <class 'generator'> cannot saved in process_save_dict function\n",
      "attributes : <generator object stream_list at 0x0000015A6ECA8EB0>, <class 'generator'> cannot saved in process_save_dict function\n",
      "globals : <generator object stream_list at 0x0000015A6ECA8F20>, <class 'generator'> cannot saved in process_save_dict function\n",
      "functions : <generator object stream_list at 0x0000015A6ECA8F90>, <class 'generator'> cannot saved in process_save_dict function\n",
      "attributes : <generator object stream_list at 0x0000015A73B94040>, <class 'generator'> cannot saved in process_save_dict function\n",
      "globals : <generator object stream_list at 0x0000015A73B940B0>, <class 'generator'> cannot saved in process_save_dict function\n",
      "functions : <generator object stream_list at 0x0000015A73B94120>, <class 'generator'> cannot saved in process_save_dict function\n",
      "attributes : <generator object stream_list at 0x0000015A73B94190>, <class 'generator'> cannot saved in process_save_dict function\n",
      "globals : <generator object stream_list at 0x0000015A73B94200>, <class 'generator'> cannot saved in process_save_dict function\n",
      "functions : <generator object stream_list at 0x0000015A73B94270>, <class 'generator'> cannot saved in process_save_dict function\n",
      "attributes : <generator object stream_list at 0x0000015A73B942E0>, <class 'generator'> cannot saved in process_save_dict function\n",
      "globals : <generator object stream_list at 0x0000015A73B94350>, <class 'generator'> cannot saved in process_save_dict function\n",
      "functions : <generator object stream_list at 0x0000015A73B943C0>, <class 'generator'> cannot saved in process_save_dict function\n",
      "attributes : <generator object stream_list at 0x0000015A73B94430>, <class 'generator'> cannot saved in process_save_dict function\n",
      "globals : <generator object stream_list at 0x0000015A73B944A0>, <class 'generator'> cannot saved in process_save_dict function\n",
      "functions : <generator object stream_list at 0x0000015A73BAB7B0>, <class 'generator'> cannot saved in process_save_dict function\n",
      "attributes : <generator object stream_list at 0x0000015A73BAB820>, <class 'generator'> cannot saved in process_save_dict function\n",
      "globals : <generator object stream_list at 0x0000015A73BAB890>, <class 'generator'> cannot saved in process_save_dict function\n",
      "functions : <generator object stream_list at 0x0000015A6ECA8900>, <class 'generator'> cannot saved in process_save_dict function\n",
      "attributes : <generator object stream_list at 0x0000015A6ECA8970>, <class 'generator'> cannot saved in process_save_dict function\n",
      "globals : <generator object stream_list at 0x0000015A6ECA89E0>, <class 'generator'> cannot saved in process_save_dict function\n",
      "functions : <generator object stream_list at 0x0000015A6ECA8A50>, <class 'generator'> cannot saved in process_save_dict function\n",
      "attributes : <generator object stream_list at 0x0000015A6ECA8AC0>, <class 'generator'> cannot saved in process_save_dict function\n",
      "globals : <generator object stream_list at 0x0000015A6ECA8B30>, <class 'generator'> cannot saved in process_save_dict function\n",
      "functions : <generator object stream_list at 0x0000015A6ECA8BA0>, <class 'generator'> cannot saved in process_save_dict function\n",
      "attributes : <generator object stream_list at 0x0000015A6ECA8C10>, <class 'generator'> cannot saved in process_save_dict function\n",
      "globals : <generator object stream_list at 0x0000015A6ECA8C80>, <class 'generator'> cannot saved in process_save_dict function\n",
      "functions : <generator object stream_list at 0x0000015A6ECA8CF0>, <class 'generator'> cannot saved in process_save_dict function\n",
      "attributes : <generator object stream_list at 0x0000015A6ECA8D60>, <class 'generator'> cannot saved in process_save_dict function\n",
      "globals : <generator object stream_list at 0x0000015A6ECA8DD0>, <class 'generator'> cannot saved in process_save_dict function\n",
      "functions : <generator object stream_list at 0x0000015A6ECA8E40>, <class 'generator'> cannot saved in process_save_dict function\n",
      "attributes : <generator object stream_list at 0x0000015A6ECA8EB0>, <class 'generator'> cannot saved in process_save_dict function\n",
      "globals : <generator object stream_list at 0x0000015A6ECA8F20>, <class 'generator'> cannot saved in process_save_dict function\n",
      "functions : <generator object stream_list at 0x0000015A6ECA8F90>, <class 'generator'> cannot saved in process_save_dict function\n",
      "attributes : <generator object stream_list at 0x0000015A73B94040>, <class 'generator'> cannot saved in process_save_dict function\n",
      "globals : <generator object stream_list at 0x0000015A73B940B0>, <class 'generator'> cannot saved in process_save_dict function\n",
      "functions : <generator object stream_list at 0x0000015A73B94120>, <class 'generator'> cannot saved in process_save_dict function\n",
      "attributes : <generator object stream_list at 0x0000015A73B94190>, <class 'generator'> cannot saved in process_save_dict function\n",
      "globals : <generator object stream_list at 0x0000015A73B94200>, <class 'generator'> cannot saved in process_save_dict function\n",
      "functions : <generator object stream_list at 0x0000015A73B94270>, <class 'generator'> cannot saved in process_save_dict function\n",
      "attributes : <generator object stream_list at 0x0000015A73B942E0>, <class 'generator'> cannot saved in process_save_dict function\n",
      "globals : <generator object stream_list at 0x0000015A73B94350>, <class 'generator'> cannot saved in process_save_dict function\n",
      "functions : <generator object stream_list at 0x0000015A73B943C0>, <class 'generator'> cannot saved in process_save_dict function\n",
      "attributes : <generator object stream_list at 0x0000015A73B94430>, <class 'generator'> cannot saved in process_save_dict function\n",
      "globals : <generator object stream_list at 0x0000015A73B944A0>, <class 'generator'> cannot saved in process_save_dict function\n",
      "functions : <generator object stream_list at 0x0000015A73BAB7B0>, <class 'generator'> cannot saved in process_save_dict function\n",
      "attributes : <generator object stream_list at 0x0000015A73BAB820>, <class 'generator'> cannot saved in process_save_dict function\n",
      "globals : <generator object stream_list at 0x0000015A73BAB890>, <class 'generator'> cannot saved in process_save_dict function\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "baseModel.run(\n",
    "    nb_run= 30,\n",
    "    # save_path= './RESULTS/MFEA_cec17.mso'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MFEA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
